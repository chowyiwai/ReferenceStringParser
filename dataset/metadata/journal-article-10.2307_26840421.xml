<?xml version="1.0" encoding="UTF-8"?>

<article xmlns:mml="http://www.w3.org/1998/Math/MathML"
         xmlns:xlink="http://www.w3.org/1999/xlink"
         dtd-version="1.0"
         article-type="research-article">
   <front>
      <journal-meta>
         <journal-id journal-id-type="jstor">j50019980</journal-id>
         <journal-id journal-id-type="jcode">saeintejengi</journal-id>
         <journal-title-group>
            <journal-title>SAE International Journal of Engines</journal-title>
         </journal-title-group>
         <issn pub-type="ppub">19463936</issn>
         <issn pub-type="epub">19463944</issn>
         <publisher>
            <publisher-name specific-use="jstor-licensing-publisher">SAE International</publisher-name>
         </publisher>
      </journal-meta>
      <article-meta>
         <article-id pub-id-type="jstor">26840421</article-id>
         <title-group>
            <article-title>Extending the Range of Data-Based Empirical Models Used for Diesel Engine Calibration by Using Physics to Transform Feature Space</article-title>
         </title-group>
         <contrib-group>
            <contrib contrib-type="author">
               <string-name>
                  <surname>Brahma</surname>
                  <given-names>Indranil</given-names>
               </string-name>
            </contrib>
         </contrib-group>

         <pub-date xmlns:oasis="http://docs.oasis-open.org/ns/oasis-exchange/table">
            <day>1</day>
            <month>1</month>
            <year>2019</year>
            <string-date>2019</string-date>
         </pub-date>
         <volume>12</volume>
         <issue>2</issue>
         <issue-id>e26840415</issue-id>
         <fpage>185</fpage>
         <lpage>202</lpage>
         <permissions>
            <copyright-statement>Copyright © 2019 Bucknell University</copyright-statement>
         </permissions>
         <self-uri xlink:href="https://www.jstor.org/stable/26840421"/>
         <abstract xml:lang="eng">
            <p>A new method that allows data-enabled (empirical) models, commonly used for automotive engine calibration, to extrapolate beyond the range of training data has been developed. This method used a physics-based system-level one-dimensional model to improve interpolation and allow extrapolation for three data-based algorithms, by modifying the model input (feature) space. Neural network, regression, and k-nearest neighbor predictions of engine emissions and volumetric efficiency were greatly improved by generating 736,281 artificial feature spaces and then performing feature selection to choose feature spaces (feature selection) so that extrapolations in the original feature space were interpolations in the new feature space. A novel feature selection method was developed that used a two-stage search process to uniquely select the best feature spaces for every prediction. The selected feature spaces also improved interpolation significantly, suggesting that they were advantageous in terms of local data density and gradients. Results were found to be relatively insensitive to the geometrical parameters and calibration of the one-dimensional physical model. Hence a “Toy Model” concept is proposed, where if physical knowledge is incomplete or computationally prohibitive, the insufficient physical model is used as a transfer function to reformulate the learning task, by transforming the feature space.</p>
         </abstract>
         <custom-meta-group>
            <custom-meta>
               <meta-name>lang</meta-name>
               <meta-value>eng</meta-value>
            </custom-meta>
         </custom-meta-group>
      </article-meta>
   </front>
   <back>
      <ref-list content-type="unparsed-citations">
         <title>References</title>
         <ref id="r1">
            <label>1.</label>
            <mixed-citation id="c1">Röpke, K., Baumann, W., Köhler, B.U., Schaum, S. et al., “Engine Calibration Using Nonlinear Dynamic Modeling,”. In: Identification for Automotive Systems. (London, Springer, 2012), 165-182.</mixed-citation>
         </ref>
         <ref id="r2">
            <label>2.</label>
            <mixed-citation id="c2">Atkinson, C.M., Allain, M., and Zhang, H., “Using Model- Based Rapid Transient Calibration to Reduce Fuel Consumption and Emissions in Diesel Engines,” SAE Technical Paper 2008-01-1365, 2008, doi:10.4271/2008-01-1365.</mixed-citation>
         </ref>
         <ref id="r3">
            <label>3.</label>
            <mixed-citation id="c3">Atkinson, C.M. and Mott, G., “Dynamic Model-Based Calibration Optimization: An introduction and Application to Diesel Engines,” SAE Technical Paper 2005-01-0026, 2005, doi:10.4271/2005-01-0026.</mixed-citation>
         </ref>
         <ref id="r4">
            <label>4.</label>
            <mixed-citation id="c4">Burke, R.D., Baumann, W., Akehurst, S., and Brace, C.J., “Dynamic Modelling of Diesel Engine Emissions Using the Parametric Volterra Series,” Proceedings of the Institution of Mechanical Engineers, Part D: Journal of Automobile Engineering 228(2):164-179, 2014.</mixed-citation>
         </ref>
         <ref id="r5">
            <label>5.</label>
            <mixed-citation id="c5">Millo, F., Arya, P., and Mallamo, F., “Optimization of Automotive Diesel Engine Calibration Using Genetic Algorithm Techniques,” Energy, 2018.</mixed-citation>
         </ref>
         <ref id="r6">
            <label>6.</label>
            <mixed-citation id="c6">Lee, T. and Reitz, R.D., “Response Surface Method Optimization of a High-Speed Direct-Injection Diesel Engine Equipped with a Common Rail Injection System,” Journal of Engineering for Gas Turbines and Power 125:541-546, Apr. 2003.</mixed-citation>
         </ref>
         <ref id="r7">
            <label>7.</label>
            <mixed-citation id="c7">Liu, Y., Reitz, R.D., and Lu, F., “Development and Application of a Non-Gradient Step-Controlled Search Algorithm for Engine Combustion Optimization,” SAE Technical Paper 2006-01-0239, 2006, doi:10.4271/2006-01-0239.</mixed-citation>
         </ref>
         <ref id="r8">
            <label>8.</label>
            <mixed-citation id="c8">Brahma, I. and Rutland, C.J., “Optimization of Diesel Engine Operating Parameters Using Neural Networks,” SAE Technical Paper 2003-01-3228, 2003, doi:10.4271/2003-01-3228.</mixed-citation>
         </ref>
         <ref id="r9">
            <label>9.</label>
            <mixed-citation id="c9">Benz, M., Hehn, M., Onder, C.H., and Guzzella, L., “Model- Based Actuator Trajectories Optimization for a Diesel Engine Using Direct Method,” Journal of Engineering for Gas Turbines and Power 133:032806, 2011.</mixed-citation>
         </ref>
         <ref id="r10">
            <label>10.</label>
            <mixed-citation id="c10">Malikopoulos, A.A., Assanis, D.N., and Papalambros, P.Y., “Real-Time Self-Learning Optimization of Diesel Engine Calibration,” Journal of Engineering for Gas Turbines and Power 131:022803, 2009.</mixed-citation>
         </ref>
         <ref id="r11">
            <label>11.</label>
            <mixed-citation id="c11">Brahma, I., Sharp, M.C., Richter, I.B., and Frazier, T.R., “Development of the Nearest Neighbor Multivariate Localized Regression Modeling Technique for Steady State Engine Calibration and Comparison With Neural Networks and Global Regression,” International Journal of Engine Research 9(4):297-323(27), 2008.</mixed-citation>
         </ref>
         <ref id="r12">
            <label>12.</label>
            <mixed-citation id="c12">GT-Power software version 7.0, Gamma Technologies, LLC, https://www.gtisoft.com/gt-suite-applications/propulsionsystems/ gt-power-engine-simulation-software/.</mixed-citation>
         </ref>
         <ref id="r13">
            <label>13.</label>
            <mixed-citation id="c13">Brahma, I., “Advantages and Applications of Transforming Empirical Model Input Space with Dimensional Models,” International Journal of Engine Research 15(7):877-894, 2014.</mixed-citation>
         </ref>
         <ref id="r14">
            <label>14.</label>
            <mixed-citation id="c14">Scholkopf, B. and Smola, A.J., Learning with Kernels: Support Vector Machines, Regularization, Optimization and Beyond (MIT Press, 2001).</mixed-citation>
         </ref>
         <ref id="r15">
            <label>15.</label>
            <mixed-citation id="c15">Wood, S.N., “Fast Stable Direct Fitting and Smoothness Selection for Generalized Additive Models,” Journal of the Royal Statistical Society: Series B (Statistical Methodology) 70:495-518, 2008.</mixed-citation>
         </ref>
         <ref id="r16">
            <label>16.</label>
            <mixed-citation id="c16">Barrios, J.A., Torres-Alvarado, M., Cavazos, A., and Leduc, L., “Neural and Neural Gray-Box Modeling for Entry Temperature Prediction in a Hot Strip Mill,” Journal of Materials Engineering and Performance 20(7):1128-1139, 2011.</mixed-citation>
         </ref>
         <ref id="r17">
            <label>17.</label>
            <mixed-citation id="c17">Brahma, I., He, Y., and Rutland, C.J., “Improvement of Neural Network Accuracy for Engine Simulations,” SAE Technical Paper 2003-01-3227, 2003, doi:10.4271/2003-01-3227.</mixed-citation>
         </ref>
         <ref id="r18">
            <label>18.</label>
            <mixed-citation id="c18">Braun, J.E. and Chaturvedi, N., “An Inverse Gray-Box Model for Transient Building Load Prediction,” HVAC&amp;R Research 8(1):73-99, 2002.</mixed-citation>
         </ref>
         <ref id="r19">
            <label>19.</label>
            <mixed-citation id="c19">Masoudinejad, M., Kamat, M., Emmerich, J., ten Hompel, M. et al., “A Gray Box Modeling of a Photovoltaic Cell under Low Illumination in Materials Handling Application,” in Renewable and Sustainable Energy Conference (IRSEC), 2015 3rd International, December 2015, IEEE, 1-6.</mixed-citation>
         </ref>
         <ref id="r20">
            <label>20.</label>
            <mixed-citation id="c20">Aghmasheh, R., Rashtchi, V., and Rahimpour, E., “Gray Box Modeling of Power Transformer Windings for Transient Studies,” IEEE Transactions on Power Delivery, 2017.</mixed-citation>
         </ref>
         <ref id="r21">
            <label>21.</label>
            <mixed-citation id="c21">Drioli, C. and Foresti, G.L., “Data-Driven Vocal Folds Models for the Representation of Both Acoustic and High Speed Video Data,” in Neural Networks (IJCNN), 2015 International Joint Conference on, July 2015, IEEE, 1-6.</mixed-citation>
         </ref>
         <ref id="r22">
            <label>22.</label>
            <mixed-citation id="c22">Greenwood, E. and Schmitz, F.H., “A Parameter Identification Method for Helicopter Noise Source Identification and Physics-Based Semi-Empirical Modeling,” 2010.</mixed-citation>
         </ref>
         <ref id="r23">
            <label>23.</label>
            <mixed-citation id="c23">Limber, P.W. et al., “Unraveling the Dynamics that Scale Cross-Shore Headland Relief on Rocky Coastlines: 1. Model Development,” Journal of Geophysical Research: Earth Surface 119:4, 854-873, 2014.</mixed-citation>
         </ref>
         <ref id="r24">
            <label>24.</label>
            <mixed-citation id="c24">Kristensen, N.R., Madsen, H., and Jørgensen, S.B., “Parameter Estimation in Stochastic Grey-Box Models,” Automatica 40(2):225-237, 2004.</mixed-citation>
         </ref>
         <ref id="r25">
            <label>25.</label>
            <mixed-citation id="c25">Raue, A., Steiert, B., Schelker, M., Kreutz, C. et al., “Data2Dynamics: A Modeling Environment Tailored to Parameter Estimation in Dynamical Systems,” Bioinformatics, 2015.</mixed-citation>
         </ref>
         <ref id="r26">
            <label>26.</label>
            <mixed-citation id="c26">Tan, K.C. and Li, Y., “Grey-Box Model Identification via Evolutionary Computing,” Control Engineering Practice 10(7):673-684, 2002.</mixed-citation>
         </ref>
         <ref id="r27">
            <label>27.</label>
            <mixed-citation id="c27">Van Can, H.J.L., Hellinga, C., Luyben, K., Ch, A.M. et al., “Strategy for Dynamic Process Modeling Based on Neural Networks in Macroscopic Balances,” AIChE Journal 42:3403-3418, 1996, doi:10.1002/aic.690421211.</mixed-citation>
         </ref>
         <ref id="r28">
            <label>28.</label>
            <mixed-citation id="c28">Wang, J.X., Wu, J.L., and Xiao, H., “Physics-Informed Machine Learning Approach for Reconstructing Reynolds Stress Modeling Discrepancies Based on DNS Data,” Physical Review Fluids 2(3):034603, 2017.</mixed-citation>
         </ref>
         <ref id="r29">
            <label>29.</label>
            <mixed-citation id="c29">Parish, E.J. and Duraisamy, K., “A Paradigm for Data-Driven Predictive Modeling Using Field Inversion and Machine Learning,” Journal of Computational Physics 305:758-774, 2016.</mixed-citation>
         </ref>
         <ref id="r30">
            <label>30.</label>
            <mixed-citation id="c30">Corzo, G.A., Solomatine, D.P., Wit, M.D., Werner, M. et al., “Combining Semi-Distributed Process-Based and Data- Driven Models in Flow Simulation: A Case Study of the Meuse River Basin,” Hydrology and Earth System Sciences 13(9):1619-1634, 2009.</mixed-citation>
         </ref>
         <ref id="r31">
            <label>31.</label>
            <mixed-citation id="c31">Tinoco, R.O., Goldstein, E.B., and Coco, G., “A Data-Driven Approach to Develop Physically Sound Predictors: Application to Depth-Averaged Velocities on Flows Through Submerged Arrays of Rigid Cylinders,” Water Resources Research 51(2):1247-1263, 2015.</mixed-citation>
         </ref>
         <ref id="r32">
            <label>32.</label>
            <mixed-citation id="c32">Goldstein, E.B., Coco, G., and Murray, A.B., “Prediction of Wave Ripple Characteristics Using Genetic Programming,” Continental Shelf Research 71:1-15, 2013.</mixed-citation>
         </ref>
         <ref id="r33">
            <label>33.</label>
            <mixed-citation id="c33">Limber, P.W., Brad Murray, A., Adams, P.N., and Goldstein, E.B., “Unraveling the Dynamics that Scale Cross-Shore Headland Relief on Rocky Coastlines: 1. Model Development,” Journal of Geophysical Research: Earth Surface 119(4):854-873, 2014.</mixed-citation>
         </ref>
         <ref id="r34">
            <label>34.</label>
            <mixed-citation id="c34">Limber, P.W. and Murray, A.B., “Unraveling the Dynamics that Scale Cross-Shore Headland Relief on Rocky Coastlines: 2. Model Predictions and Initial Tests,” Journal of Geophysical Research: Earth Surface 119(4):874-891, 2014.</mixed-citation>
         </ref>
         <ref id="r35">
            <label>35.</label>
            <mixed-citation id="c35">Raissi, M., Perdikaris, P., and Karniadakis, G.E., “Physics Informed Deep Learning (Part I): Data-Driven Solutions of Nonlinear Partial Differential Equations,” arXiv preprint arXiv:1711.10561, 2017.</mixed-citation>
         </ref>
         <ref id="r36">
            <label>36.</label>
            <mixed-citation id="c36">Raissi, M., Perdikaris, P., and Karniadakis, G.E., “Physics Informed Deep Learning (Part II): Data-Driven Discovery of Nonlinear Partial Differential Equations,” arXiv preprint arXiv:1711.10566, 2017.</mixed-citation>
         </ref>
         <ref id="r37">
            <label>37.</label>
            <mixed-citation id="c37">Raissi, M. and Karniadakis, G.E., “Hidden Physics Models: Machine Learning of Nonlinear Partial Differential Equations,” Journal of Computational Physics 357:125-141, 2018.</mixed-citation>
         </ref>
         <ref id="r38">
            <label>38.</label>
            <mixed-citation id="c38">Weymouth, G.D. and Yue, D.K., “Physics-Based Learning Models for Ship Hydrodynamics,” Journal of Ship Research 57(1):1-12, 2013.</mixed-citation>
         </ref>
         <ref id="r39">
            <label>39.</label>
            <mixed-citation id="c39">Hess, D.E., Faller, W.E., Fu, T.C., and Ammeen, E.S., “Development of an Advanced Ship Simulation &amp; Control System Using Neural Networks,” in Proceedings of the 13th International Conference on, Intelligent Systems Application to Power Systems, Arlington, VA, 2005, doi:10.1109/ ISAP.2005.1599272.</mixed-citation>
         </ref>
         <ref id="r40">
            <label>40.</label>
            <mixed-citation id="c40">Brahma, I., Rutland, C.J., Foster, D.E., and He, Y., “A New Approach to System Level Soot Modeling,” SAE Technical Paper 2005-01-1122, 2005, doi:10.4271/2005-01-1122.</mixed-citation>
         </ref>
      </ref-list>
   </back>
   <floats-group>
      <fig>
         <label>FIGURE 1</label>
         <caption id="ca-1">
            <p>Neural network predictions of NOx, opacity, and volumetric efficiency (VE) over the interpolation dataset (top subplots) and one of the extrapolation datasets (bottom plots). © 2019 Bucknell University</p>
         </caption>
      </fig>
      <fig>
         <label>FIGURE 2</label>
         <caption id="ca-2">
            <p>Each of the six features of the original experimental feature space plotted against NOₓ for one of the six “extrapolation datasets” produced by creating training and testing subsets of the data. In this example, the lowest fuel mass injected in the testing dataset exceeds the highest value in the training dataset. Six such “extrapolation datasets” were created. © 2019 Bucknell University</p>
         </caption>
      </fig>
      <fig>
         <label>FIGURE 3</label>
         <caption id="ca-3">
            <p>GT-Power model predictions of NOₓ, brake-specific diesel particulate matter (BSDPM), and VE (top subplots) and three mean-value variables (bottom subplots). The approach undertaken in this work is to not use predictions of local variables (top subplots) but to utilize the mean-value variables (bottom subplots) to assist the empirical prediction of local variables by modifying the model inputs (feature space) of the empirical (data-based) models. Note that GT-Power does not predict opacity; hence, BSDPM was used as a surrogate (middle subplot top row). © 2019 Bucknell University</p>
         </caption>
      </fig>
      <fig>
         <label>FIGURE 4</label>
         <caption id="ca-4">
            <p>The same data presented in Figure 2 (original experimental feature space) is plotted in the modified feature space generated by GT-Power. The test data does not exceed the bounds of the training data for any feature in the new feature space. Hence the extrapolations in the original feature space are interpolations in the new feature space. Mean statistical leverage of the test data in the original experimental feature space is 0.032 but only 0.005 in the new space. This particular feature space was the best ranked for the k-NN algorithm when predicting NOₓ emissions. Note that it includes engine speed and EGR fraction, which were also part of the original feature space. Also note the reduced dimensionality. © 2019 Bucknell University</p>
         </caption>
      </fig>
      <fig>
         <label>FIGURE 5</label>
         <caption id="ca-5">
            <p>The general configuration of the parallel hybrid model. The output is a weighted linear combination. © 2019 Bucknell University</p>
         </caption>
      </fig>
      <fig>
         <label>FIGURE 6</label>
         <caption id="ca-6">
            <p>The empirical model is used to predict parameters within the physical model in the series configuration. © 2019 Bucknell University</p>
         </caption>
      </fig>
      <fig>
         <label>FIGURE 7</label>
         <caption id="ca-7">
            <p>The empirical model is a sub-model of a larger physical model, for example, an empirically predicted term that is used in a larger computational fluid dynamics (CFD) model. © 2019 Bucknell University</p>
         </caption>
      </fig>
      <fig>
         <label>FIGURE 8</label>
         <caption id="ca-8">
            <p>A visual representation of the central idea represented by Equations 1 and 2. For the data and model used in the current work, M = 6, N = 30, and <inline-formula> 
                  <mml:math display="inline">
                     <mml:mrow>
                        <mml:msup>
                           <mml:mi>N</mml:mi>
                           <mml:mrow>
                              <mml:mover accent="true">
                                 <mml:mi>η</mml:mi>
                                 <mml:mo stretchy="true">→</mml:mo>
                              </mml:mover>
                           </mml:mrow>
                        </mml:msup>
                        <mml:mo>=</mml:mo>
                        <mml:mn>736</mml:mn>
                        <mml:mo>,</mml:mo>
                        <mml:mn>281</mml:mn>
                     </mml:mrow>
                  </mml:math>
               </inline-formula>. © 2019 Bucknell University</p>
         </caption>
      </fig>
      <fig>
         <label>FIGURE 9</label>
         <caption id="ca-9">
            <p>A visual illustration of the central idea. The subplots on the right show one of the LVs (opacity) plotted against the principal components of one of the best-ranked MVV vectors generated by the one-dimensional model, while the left subplots show the corresponding surface for the original experimental feature space. Bottom figures show contours of the respective gradients. It can be seen that the artificial feature space has reorganized the response surface by reducing and redistributing peaks and high gradients along the peripheries. Principle components have been used to aid visualization, because the dimensionality of both <inline-formula> 
                  <mml:math display="inline">
                     <mml:mrow>
                        <mml:mover accent="true">
                           <mml:mi>x</mml:mi>
                           <mml:mo stretchy="true">→</mml:mo>
                        </mml:mover>
                     </mml:mrow>
                  </mml:math>
               </inline-formula> and <inline-formula> 
                  <mml:math display="inline">
                     <mml:mrow>
                        <mml:mover accent="true">
                           <mml:mi>η</mml:mi>
                           <mml:mo stretchy="true">→</mml:mo>
                        </mml:mover>
                     </mml:mrow>
                  </mml:math>
               </inline-formula> is six. The LV numbers are averages of all data points existing at that grid point. It is possible to increase grid resolution so that no averaging is required, but this makes visualization difficult. © 2019 Bucknell University</p>
         </caption>
      </fig>
      <fig>
         <label>TABLE 1</label>
         <caption id="ca-10">
            <p>Test results for interpolation dataset. © 2019 Bucknell University</p>
         </caption>
      </fig>
      <fig>
         <label>TABLE 2</label>
         <caption id="ca-11">
            <p>Test results for extrapolation dataset. © 2019 Bucknell University</p>
         </caption>
      </fig>
      <fig>
         <label>TABLE 3</label>
         <caption id="ca-12">
            <p>Fraction of data points in the extrapolation dataset that are extrapolations in the best-ranked space. © 2019 Bucknell University</p>
         </caption>
      </fig>
      <fig>
         <label>FIGURE 10</label>
         <caption id="ca-13">
            <p>Minimum variance committee (MVCT) predictions over the extrapolation dataset, for neural networks (top subplot) and k-NN (bottom subplot). Predictions are qualitatively and quantitatively of the same quality when compared to each other as well as predictions over interpolation data shown by top subplots of Figure 1, hence the claim that “MVCT enables extrapolation.” © 2019 Bucknell University</p>
         </caption>
      </fig>
      <fig>
         <label>FIGURE 11</label>
         <caption id="ca-14">
            <p>MVCT predictions over the interpolation dataset, for neural networks (top subplot) and k-NN (bottom subplot). Predictions between the two algorithms are qualitatively and quantitatively similar, hence the claim that MVCT equalized the performance of the three algorithms investigated. © 2019 Bucknell University</p>
         </caption>
      </fig>
      <fig>
         <label>FIGURE 12</label>
         <caption id="ca-15">
            <p>Comparison of the k-NN algorithm VE predictions with and without MVCT over the interpolation dataset. Large improvements in interpolation can be seen by comparing the first and last rows of Table 1, particularly for regression and k-NN. This suggests that the artificially generated feature spaces enhance interpolation possibly with higher data density and lower gradients in the proximity of every prediction. Note that VCT chooses unique feature spaces for every prediction. © 2019 Bucknell University</p>
         </caption>
      </fig>
      <fig>
         <label>FIGURE 13</label>
         <caption id="ca-16">
            <p>Baseline model outputs (x-axis) plotted against outputs of modified uncalibrated model (y-axis). The bigger subplot on the right is the LV prediction, while the rest of the subplots are MVVs for the best-ranked <inline-formula> 
                  <mml:math display="inline">
                     <mml:mrow>
                        <mml:mover accent="true">
                           <mml:mi>η</mml:mi>
                           <mml:mo stretchy="true">→</mml:mo>
                        </mml:mover>
                     </mml:mrow>
                  </mml:math>
               </inline-formula> vector for k-NN. © 2019 Bucknell University</p>
         </caption>
      </fig>
      <fig>
         <label>TABLE 4</label>
         <caption id="ca-17">
            <p>Results over interpolation dataset obtained by using MVVs from uncalibrated physical model. © 2019 Bucknell University</p>
         </caption>
      </fig>
      <fig>
         <label>TABLE 5</label>
         <caption id="ca-18">
            <p>Results over extrapolation dataset obtained by using MVVs from uncalibrated physical model. © 2019 Bucknell University</p>
         </caption>
      </fig>
      <fig>
         <label>TABLE 6</label>
         <caption id="ca-19">
            <p>Results for bootstrap aggregation. © 2019 Bucknell University</p>
         </caption>
      </fig>
      <fig>
         <label>TABLE A.1</label>
         <caption id="ca-20">
            <p>The 30 MVV predictions made by the physical model are listed below. The original feature space <inline-formula> 
                  <mml:math display="inline">
                     <mml:mrow>
                        <mml:mover accent="true">
                           <mml:mi>x</mml:mi>
                           <mml:mo stretchy="true">→</mml:mo>
                        </mml:mover>
                     </mml:mrow>
                  </mml:math>
               </inline-formula> comprised MVVs numbered 1 through 6. © 2019 Bucknell University</p>
         </caption>
      </fig>
      <fig>
         <label>TABLE A.2</label>
         <caption id="ca-21">
            <p>Top ten feature spaces ranked by training data for NOₓ, for all three empirical models. Number refers to MVV code in Table A.1. © 2019 Bucknell University</p>
         </caption>
      </fig>
      <fig>
         <label>TABLE A.3</label>
         <caption id="ca-22">
            <p>Results over interpolation dataset obtained by using MVVs predicted by physical model with modified geometrical parameters. The compression ratio (CR) of the model was 25% higher than the CR of the engine used to generate the experimental data. © 2019 Bucknell University</p>
         </caption>
      </fig>
      <fig>
         <label>TABLE A.4</label>
         <caption id="ca-23">
            <p>Results over extrapolation dataset obtained by using MVVs predicted by physical model with modified geometrical parameters. The compression ratio (CR) of the model was 25% higher than the CR of the engine used to generate the experimental data. © 2019 Bucknell University</p>
         </caption>
      </fig>
      <fig>
         <label>TABLE A.5</label>
         <caption id="ca-24">
            <p>Results over interpolation dataset obtained by using MVVs predicted by physical model with modified geometrical parameters. The compression ratio (CR) of the model was 25% lower than the CR of the engine used to generate the experimental data. © 2019 Bucknell University</p>
         </caption>
      </fig>
      <fig>
         <label>TABLE A.6</label>
         <caption id="ca-25">
            <p>Results over extrapolation dataset obtained by using MVVs predicted by physical model with modified geometrical parameters. The compression ratio (CR) of the model was 25% lower than the CR of the engine used to generate the experimental data. © 2019 Bucknell University</p>
         </caption>
      </fig>
   </floats-group>
</article>
