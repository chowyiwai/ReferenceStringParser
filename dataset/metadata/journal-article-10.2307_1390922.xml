<?xml version="1.0" encoding="UTF-8"?>

<article xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xmlns:xlink="http://www.w3.org/1999/xlink"
         xmlns:mml="http://www.w3.org/1998/Math/MathML"
         dtd-version="1.0"
         article-type="research-article">
   <front>
      <journal-meta>
         <journal-id journal-id-type="jstor">jcompgrapstat</journal-id>
         <journal-id journal-id-type="jstor">j100879</journal-id>
         <journal-title-group>
            <journal-title>Journal of Computational and Graphical Statistics</journal-title>
         </journal-title-group>
         
         <publisher>
            <publisher-name>American Statistical Association, Institute of Mathematical Statistics, and Interface Foundation of North America</publisher-name>
         </publisher>
         <issn pub-type="ppub">10618600</issn>
         <custom-meta-group/>
      </journal-meta>
      <article-meta>
         <volume xmlns:oasis="http://docs.oasis-open.org/ns/oasis-exchange/table">8</volume>
         <issue xmlns:oasis="http://docs.oasis-open.org/ns/oasis-exchange/table">1</issue>
         <issue-id>i260283</issue-id>
         <article-id pub-id-type="doi">10.2307/1390922</article-id>
         
         <title-group>
            <article-title>Hypothesis Tests of Convergence in Markov Chain Monte Carlo</article-title>
          </title-group>
         <contrib-group>
            <contrib contrib-type="author">
              <string-name>
                  <given-names>Angelo J.</given-names>
                  <surname>Canty</surname>
              </string-name>
            </contrib>
          </contrib-group>
         <pub-date pub-type="ppub">
            <day>1</day>
            <month>3</month>
            <year>1999</year>
         </pub-date>
         <fpage>93</fpage>
         <lpage>108</lpage>
         <page-range>93-108</page-range>
         <permissions>
            <copyright-statement>Copyright 1999 American Statistical Association, Institute of Mathematical Statistics, and Interface Foundation of North America</copyright-statement>
         </permissions>
         <self-uri xlink:href="https://www.jstor.org/stable/1390922"/>
         
         
         <abstract>
            <p>Deciding when a Markov chain has reached its stationary distribution is a major problem in applications of Markov Chain Monte Carlo methods. Many methods have been proposed ranging from simple graphical methods to complicated numerical methods. Most such methods require a lot of user interaction with the chain which can be very tedious and time-consuming for a slowly mixing chain. This article describes a system to reduce the burden on the user in assessing convergence. The method uses simple nonparametric hypothesis testing techniques to examine the output of several independent chains and so determines whether there is any evidence against the hypothesis of convergence. We illustrate the proposed method on some examples from the literature.</p>
          </abstract>
         <kwd-group>
            <kwd>Convergence diagnostic</kwd>
            <kwd>Gibbs sampler</kwd>
            <kwd>Nonparametric test</kwd>
            <kwd>Permutation test</kwd>
          </kwd-group>
         <custom-meta-group>
            <custom-meta>
              <meta-name>lang</meta-name>
              <meta-value>eng</meta-value>
            </custom-meta>
          </custom-meta-group>
      </article-meta>
   </front>
   <back>
        
         <ref-list>
            <title>References</title>
            <ref id="d821936e135a1310">
               
               <mixed-citation id="d821936e139" publication-type="book">
Best, N., Cowles, M. K., and Vines, K. (1995), CODA: Convergence Diagnosis and Output Analysis Software
for Gibbs Sampling Output (Ver. 0.3), Cambridge: MRC Biostatistics Unit.<person-group>
                     <string-name>
                     <surname>Best</surname>
                  </string-name>
                  </person-group>
               <source>CODA: Convergence Diagnosis and Output Analysis Software for Gibbs Sampling Output</source>
               <year>1995</year>
            </mixed-citation>
            </ref>
            <ref id="d821936e164a1310">
               
               <mixed-citation id="d821936e168" publication-type="book">
Box, G.E.P., Hunter, W.G., and Hunter, J.S. (1978), Statistics for Experimenters, New York: Wiley.<person-group>
                     <string-name>
                     <surname>Box</surname>
                  </string-name>
                  </person-group>
               <source>Statistics for Experimenters</source>
               <year>1978</year>
            </mixed-citation>
            </ref>
            <ref id="d821936e190a1310">
               
               <mixed-citation id="d821936e194" publication-type="journal">
Brooks, S.P. (1998), "Markov Chain Monte Carlo Method and its Application," The Statistician, 47, 69-100.<object-id pub-id-type="jstor">10.2307/2988428</object-id>
               <fpage>69</fpage>
            </mixed-citation>
            </ref>
            <ref id="d821936e207a1310">
               
               <mixed-citation id="d821936e211" publication-type="journal">
Brooks, S.P., and Gelman, A. (1998), "General Methods for Monitoring Convergence of Iterative Simulations,"
Journal of Computational and Graphical Statistics, 7, 434-455.<object-id pub-id-type="doi">10.2307/1390675</object-id>
               <fpage>434</fpage>
            </mixed-citation>
            </ref>
            <ref id="d821936e228a1310">
               
               <mixed-citation id="d821936e232" publication-type="journal">
Brooks, S.P., and Roberts, G. 0. (in press), "Assessing Convergence of Markov Chain Monte Carlo Algo-
rithms," Statistics and Computing.<person-group>
                     <string-name>
                     <surname>Brooks</surname>
                  </string-name>
                  </person-group>
               <source>Statistics and Computing</source>
            </mixed-citation>
            </ref>
            <ref id="d821936e254a1310">
               
               <mixed-citation id="d821936e258" publication-type="book">
Canty, A. J. (1995), "A System to Test for Convergence of the Gibbs Sampler," unpublished Ph.D. thesis,
University of Toronto, Department of Statistics.<person-group>
                     <string-name>
                     <surname>Canty</surname>
                  </string-name>
                  </person-group>
               <source>A System to Test for Convergence of the Gibbs Sampler</source>
               <year>1995</year>
            </mixed-citation>
            </ref>
            <ref id="d821936e283a1310">
               
               <mixed-citation id="d821936e287" publication-type="journal">
Cowles, M.K., and Carlin, B.P. (1996), "Markov Chain Monte Carlo Convergence Diagnostics: A Comparative
Review," Journal of the American Statistical Association, 91, 883-904.<object-id pub-id-type="doi">10.2307/2291683</object-id>
               <fpage>883</fpage>
            </mixed-citation>
            </ref>
            <ref id="d821936e303a1310">
               
               <mixed-citation id="d821936e307" publication-type="journal">
Cui, L., Tanner, M.A., Sinha, D., and Hall, W.J. (1992), "Comment: Monitoring Convergence of the Gibbs
Sampler: Further Experience with the Gibbs Stopper," Statistical Science, 7, 483-486.<object-id pub-id-type="jstor">10.2307/2246095</object-id>
               <fpage>483</fpage>
            </mixed-citation>
            </ref>
            <ref id="d821936e323a1310">
               
               <mixed-citation id="d821936e327" publication-type="journal">
Gelfand, A.E., and Smith, A.F.M. (1990), "Sampling-Based Approaches to Calculating Marginal Densities,"
Journal of the American Statistical Association, 85, 398-409.<object-id pub-id-type="doi">10.2307/2289776</object-id>
               <fpage>398</fpage>
            </mixed-citation>
            </ref>
            <ref id="d821936e343a1310">
               
               <mixed-citation id="d821936e347" publication-type="book">
Gelman, A., Carlin, J.B., Stem, H.S., and Rubin, D.B. (1995), Bayesian Data Analysis, London: Chapman
and Hall.<person-group>
                     <string-name>
                     <surname>Gelman</surname>
                  </string-name>
                  </person-group>
               <source>Bayesian Data Analysis</source>
               <year>1995</year>
            </mixed-citation>
            </ref>
            <ref id="d821936e373a1310">
               
               <mixed-citation id="d821936e377" publication-type="journal">
Gelman, A., and Rubin, D.B. (1992a), "Inferences from Iterative Simulation using Multiple Sequences,"
Statistical Science, 7, 457-472.<object-id pub-id-type="jstor">10.2307/2246093</object-id>
               <fpage>457</fpage>
            </mixed-citation>
            </ref>
            <ref id="d821936e393a1310">
               
               <mixed-citation id="d821936e397" publication-type="book">
(1992b), "A Single Series from the Gibbs Sampler Provides a False Sense of Security," in Bayesian
Statistics 4, eds. J. M. Bemardo, J. 0. Berger, A. P. Dawid, and A. F. M. Smith, Oxford: Oxford University
Press, pp. 625-631.<person-group>
                     <string-name>
                     <surname>Gelman</surname>
                  </string-name>
                  </person-group>
               <comment content-type="section">A Single Series from the Gibbs Sampler Provides a False Sense of Security</comment>
               <fpage>625</fpage>
               <source>Bayesian Statistics 4</source>
               <year>1992</year>
            </mixed-citation>
            </ref>
            <ref id="d821936e432a1310">
               
               <mixed-citation id="d821936e436" publication-type="journal">
Geyer, C.J. (1992), "Practical Markov Chain Monte Carlo" (with discussion), Statistical Science, 7, 473-511.<object-id pub-id-type="jstor">10.2307/2246094</object-id>
               <fpage>473</fpage>
            </mixed-citation>
            </ref>
            <ref id="d821936e449a1310">
               
               <mixed-citation id="d821936e453" publication-type="book">
Gilks, W.R., Richardson, S., and Spiegelhalter, D.J. (eds.) (1996), Markov Chain Monte Carlo in Practice,
London: Chapman and Hall.<person-group>
                     <string-name>
                     <surname>Gilks</surname>
                  </string-name>
                  </person-group>
               <source>Markov Chain Monte Carlo in Practice</source>
               <year>1996</year>
            </mixed-citation>
            </ref>
            <ref id="d821936e478a1310">
               
               <mixed-citation id="d821936e482" publication-type="book">
Good, P. (1994), Permutation Tests. A Practical Guide to Resampling Methods for Testing Hypotheses, New
York: Springer-Verlag.<person-group>
                     <string-name>
                     <surname>Good</surname>
                  </string-name>
                  </person-group>
               <source>Permutation Tests. A Practical Guide to Resampling Methods for Testing Hypotheses</source>
               <year>1994</year>
            </mixed-citation>
            </ref>
            <ref id="d821936e507a1310">
               
               <mixed-citation id="d821936e511" publication-type="journal">
Matthews, P. (1993), "A Slowly Mixing Markov Chain With Implications for Gibbs Sampling," Statistics and
Probability Letters, 17, 213-236.<person-group>
                     <string-name>
                     <surname>Matthews</surname>
                  </string-name>
                  </person-group>
               <fpage>213</fpage>
               <volume>17</volume>
               <source>Statistics and Probability Letters</source>
               <year>1993</year>
            </mixed-citation>
            </ref>
            <ref id="d821936e544a1310">
               
               <mixed-citation id="d821936e548" publication-type="journal">
Meyn, S.P., and Tweedie, R.L. (1994), "Computable Bounds for Geometric Convergence Rates of Markov
Chains," Annals of Applied Probability, 4, 981-1011.<object-id pub-id-type="jstor">10.2307/2245077</object-id>
               <fpage>981</fpage>
            </mixed-citation>
            </ref>
            <ref id="d821936e564a1310">
               
               <mixed-citation id="d821936e568" publication-type="book">
Noreen, E.W. (1989), Computer Intensive Methods for Testing Hypotheses, New York: Wiley.<person-group>
                     <string-name>
                     <surname>Noreen</surname>
                  </string-name>
                  </person-group>
               <source>Computer Intensive Methods for Testing Hypotheses</source>
               <year>1989</year>
            </mixed-citation>
            </ref>
            <ref id="d821936e590a1310">
               
               <mixed-citation id="d821936e594" publication-type="journal">
Rosenthal, J.S. (1995a), "Minorization Conditions and Convergence Rates for Markov Chain Monte Carlo,"
Journal of the American Statistical Association, 90, 558-566.<object-id pub-id-type="doi">10.2307/2291067</object-id>
               <fpage>558</fpage>
            </mixed-citation>
            </ref>
            <ref id="d821936e610a1310">
               
               <mixed-citation id="d821936e614" publication-type="journal">
(1995b), "Rates of Convergence for Gibbs Sampling for Variance Component Models," The Annals of
Statistics, 23, 740-761.<object-id pub-id-type="jstor">10.2307/2242419</object-id>
               <fpage>740</fpage>
            </mixed-citation>
            </ref>
            <ref id="d821936e630a1310">
               
               <mixed-citation id="d821936e634" publication-type="journal">
Smith, A.F.M., and Roberts, G. 0. (1993), "Bayesian Computation via the Gibbs Sampler and Related Markov
- Chain Monte Carlo Methods," Journal of the Royal Statistical Society, Ser. B, 55, 3-23.<person-group>
                     <string-name>
                     <surname>Smith</surname>
                  </string-name>
                  </person-group>
               <fpage>3</fpage>
               <volume>55</volume>
               <source>Journal of the Royal Statistical Society, Ser. B</source>
               <year>1993</year>
            </mixed-citation>
            </ref>
            <ref id="d821936e666a1310">
               
               <mixed-citation id="d821936e670" publication-type="book">
Tierney, L. (1990), Lisp-Stat: An Object-Oriented Environment for Statistical Computing and Dynamic Graphics,
New York: Wiley.<person-group>
                     <string-name>
                     <surname>Tierney</surname>
                  </string-name>
                  </person-group>
               <source>Lisp-Stat: An Object-Oriented Environment for Statistical Computing and Dynamic Graphics</source>
               <year>1990</year>
            </mixed-citation>
            </ref>
            <ref id="d821936e696a1310">
               
               <mixed-citation id="d821936e700" publication-type="journal">
(1994), "Markov Chains for Exploring Posterior Distributions" (with discussion), The Annals of Statis-
tics, 22, 1701-1762.<object-id pub-id-type="jstor">10.2307/2242477</object-id>
               <fpage>1701</fpage>
            </mixed-citation>
            </ref>
         </ref-list>
      
      </back>
</article>
