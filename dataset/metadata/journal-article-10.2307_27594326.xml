<?xml version="1.0" encoding="UTF-8"?>


<article dtd-version="1.0" article-type="research-article">
  <front>
      <journal-meta>
         <journal-id xmlns:xlink="http://www.w3.org/1999/xlink" journal-id-type="jstor">jcompgrapstat</journal-id>
         <journal-id xmlns:xlink="http://www.w3.org/1999/xlink" journal-id-type="jstor">j100879</journal-id>
         <journal-title-group xmlns:xlink="http://www.w3.org/1999/xlink">
            <journal-title>Journal of Computational and Graphical Statistics</journal-title>
         </journal-title-group>
      
         <publisher>
            <publisher-name>American Statistical Association, Institute of Mathematical Statistics, and Interface Foundation of North America</publisher-name>
         </publisher>
         <issn xmlns:xlink="http://www.w3.org/1999/xlink" pub-type="ppub">10618600</issn>
         <custom-meta-group xmlns:xlink="http://www.w3.org/1999/xlink"/>
      </journal-meta>
      <article-meta xmlns:xlink="http://www.w3.org/1999/xlink">
         <volume xmlns:mml="http://www.w3.org/1998/Math/MathML"
                 xmlns:oasis="http://docs.oasis-open.org/ns/oasis-exchange/table">17</volume>
         <issue xmlns:mml="http://www.w3.org/1998/Math/MathML"
                xmlns:oasis="http://docs.oasis-open.org/ns/oasis-exchange/table">3</issue>
         <issue-id>i27594322</issue-id>
         <article-id pub-id-type="jstor">27594326</article-id>
         <article-id pub-id-type="pub-doi">10.1198/106186008X341462</article-id>
         <article-categories>
            <subj-group>
               <subject>Machine Learning and Classification</subject>
            </subj-group>
         </article-categories>
         <title-group>
            <article-title>A Method for Dimension Reduction in Quadratic Classification Problems</article-title>
         </title-group>
         <contrib-group>
            <contrib>
               <string-name>
                  <given-names>Santiago</given-names>
                  <surname>Velilla</surname>
               </string-name>
            </contrib>
         </contrib-group>
         <pub-date pub-type="ppub">
            <day>1</day>
            <month>9</month>
            <year>2008</year>
         </pub-date>
         <fpage>572</fpage>
         <lpage>589</lpage>
         <permissions>
            <copyright-statement>Copyright 2008 American Statistical Association, the Institute of Mathematical Statistics, and the Interface Foundation of North America</copyright-statement>
         </permissions>
      
         <self-uri xlink:href="https://www.jstor.org/stable/27594326"/>
      
      
         <abstract>
            <p>This article presents a dimension-reduction method in quadratic discriminant analysis (QDA). The procedure is inspired by the geometric relation that exists between the subspaces used in sliced inverse regression (SIR) and sliced average variance estimation (SAVE). A new set of directions is constructed to improve the properties of the directions associated with the eigenvectors of the matrices usually considered for dimension reduction in QDA. Illustrative examples of application with real and simulated data are discussed.</p>
         </abstract>
         <kwd-group>
            <kwd>Canonical coordinates</kwd>
            <kwd>Dimension-reduction subspaces</kwd>
            <kwd>Fisher—Rao criterion</kwd>
            <kwd>Linear and quadratic class separation</kwd>
            <kwd>SIRII</kwd>
         </kwd-group>
         <custom-meta-group>
            <custom-meta>
               <meta-name>lang</meta-name>
               <meta-value>eng</meta-value>
            </custom-meta>
         </custom-meta-group>
      </article-meta>
  </front>
  <back>
    
      <ref-list>
        <title>References</title>
        <ref id="d774216e146a1310">
          
            <mixed-citation id="d774216e150" publication-type="other">
Chang, W. C. (1987), "A Graph for Two Training Samples in a Discriminant Analysis," Applied Statistics, 36,
82–91.</mixed-citation>
        </ref>
        <ref id="d774216e160a1310">
          
            <mixed-citation id="d774216e164" publication-type="other">
Cook, R.D., and Critchley, F. (2000), "Identifying Outliers and Regression Mixtures Graphically," Journal of the
American Statistical Association, 95, 781–794.</mixed-citation>
        </ref>
        <ref id="d774216e174a1310">
          
            <mixed-citation id="d774216e178" publication-type="other">
Cook, R.D., and Lee, H. (1999), "Dimension Reduction with a Binary Response," Journal of the American Sta-
tistical Association, 94, 1187–1200.</mixed-citation>
        </ref>
        <ref id="d774216e188a1310">
          
            <mixed-citation id="d774216e192" publication-type="other">
Cook, R.D., and Weisberg, S. (1991), Discussion of "Sliced Inverse Regression for Dimension Reduction" by Li,
Journal of the American Statistical Association, 86, 328–332.</mixed-citation>
        </ref>
        <ref id="d774216e203a1310">
          
            <mixed-citation id="d774216e207" publication-type="other">
Cook, R. D., and Yin, X. (2001), "Dimension Reduction and Visualization in Discriminant Analysis" (with dis-
cussion), Australian and New Zealand Journal of Statistics, 43, 147–199.</mixed-citation>
        </ref>
        <ref id="d774216e217a1310">
          
            <mixed-citation id="d774216e221" publication-type="other">
Decell, H. P., Odell, P. L., and Coberly, W. A. (1981), "Linear Dimension Reduction and Bayes Classification,"
Pattern Recognition, 13, 241–243.</mixed-citation>
        </ref>
        <ref id="d774216e231a1310">
          
            <mixed-citation id="d774216e235" publication-type="other">
Flury, L., Boukai, B., and Flury, B. D. (1997), "The Discrimination Subspace Model," Journal of the American
Statistical Association, 92, 758–766.</mixed-citation>
        </ref>
        <ref id="d774216e245a1310">
          
            <mixed-citation id="d774216e249" publication-type="other">
Hastie, T., Tibshirani, R., and Friedman, J. (2001), The Elements of Statistical Learning: Data Mining, Inference
and Prediction, New York: Springer Verlag.</mixed-citation>
        </ref>
        <ref id="d774216e259a1310">
          
            <mixed-citation id="d774216e263" publication-type="other">
Hastie, T., and Zhu, M. (2001), Discussion of "Dimension Reduction and Visualization in Discriminant Analysis"
by Cook and Yin, Australian and New Zealand Journal of Statistics, 43, 179–185.</mixed-citation>
        </ref>
        <ref id="d774216e273a1310">
          
            <mixed-citation id="d774216e277" publication-type="other">
Kent, J. T. (1991), Discussion of "Sliced Inverse Regression for Dimension Reduction" by Li, Journal of the
American Statistical Association, 86, 336–337.</mixed-citation>
        </ref>
        <ref id="d774216e288a1310">
          
            <mixed-citation id="d774216e292" publication-type="other">
Li, K.C. (1991), "Sliced Inverse Regression for Dimension Reduction" (with discussion), Journal of the American
Statistical Association, 86, 316–342.</mixed-citation>
        </ref>
        <ref id="d774216e302a1310">
          
            <mixed-citation id="d774216e306" publication-type="other">
—(2000), "High Dimensional Data Analysis Via the SIR/PHD Approach," unpublished manuscript dated
April 6, 2000 available at www.stat.ucla.edu/~kcli/sir-PHD.pdf.</mixed-citation>
        </ref>
        <ref id="d774216e316a1310">
          
            <mixed-citation id="d774216e320" publication-type="other">
McLachlan, G. J. (1992). Discriminant Analysis and Statistical Pattern Recognition, New York: John Wiley.</mixed-citation>
        </ref>
        <ref id="d774216e327a1310">
          
            <mixed-citation id="d774216e331" publication-type="other">
Merz, C. J., and Murphy, P. M. (1996), UCI Repository of Machine Learning Databases, University of California,
Irvine, CA: Dept. of Information and Computer Science.</mixed-citation>
        </ref>
        <ref id="d774216e341a1310">
          
            <mixed-citation id="d774216e345" publication-type="other">
Schott, J. R. (1993), "Dimensionality Reduction in Quadratic Discriminant Analysis," Computational Statistics
and Data Analysis, 16, 161–174.</mixed-citation>
        </ref>
        <ref id="d774216e355a1310">
          
            <mixed-citation id="d774216e359" publication-type="other">
Ye, Z., and Weiss, R. E. (2003), "Using the Bootstrap to Select One of a New Class of Dimension Reduction
Methods," Journal of the American Statistical Association, 98, 968–979.</mixed-citation>
        </ref>
        <ref id="d774216e370a1310">
          
            <mixed-citation id="d774216e374" publication-type="other">
Young, D. M., Marco, V. R., and Odell, P. L. (1987), "Quadratic Discrimination: Some Results on Optimal Low-
Dimensional Representation," Journal of Statistical Planning and Inference, 17, 307–319.</mixed-citation>
        </ref>
        <ref id="d774216e384a1310">
          
            <mixed-citation id="d774216e388" publication-type="other">
Zhu, M., and Hastie, T. (2003), "Feature Extraction for Nonparametric Discriminant Analysis," Journal of Com-
putational and Graphical Statistics, 12, 101–120.</mixed-citation>
        </ref>
      </ref-list>
    
  </back>
</article>


