

<book xmlns:mml="http://www.w3.org/1998/Math/MathML"
      xmlns:oasis="http://docs.oasis-open.org/ns/oasis-exchange/table"
      xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
      xmlns:xlink="http://www.w3.org/1999/xlink"
      dtd-version="0.2"
      xml:lang="eng">
   <collection-meta>
      <collection-id collection-id-type="jstor">books</collection-id>
   </collection-meta>
   <book-meta>
      <book-id book-id-type="doi">10.2307/j.ctv1ghv45t</book-id>
      <subj-group subj-group-type="discipline">
         <subject>Computer Science</subject>
         <subject>Engineering</subject>
         <subject>Business</subject>
      </subj-group>
      <book-title-group>
         <book-title>The Atlas of AI</book-title>
         <subtitle>Power, Politics, and the Planetary Costs of Artificial Intelligence</subtitle>
      </book-title-group>
      <contrib-group>
         <contrib contrib-type="author" id="contrib1">
            <name name-style="western">
               <surname>CRAWFORD</surname>
               <given-names>KATE</given-names>
            </name>
         </contrib>
      </contrib-group>
      <pub-date>
         <day>06</day>
         <month>04</month>
         <year>2021</year>
      </pub-date>
      <isbn content-type="ppub">9780300209570</isbn>
      <isbn content-type="epub">9780300252392</isbn>
      <publisher>
         <publisher-name>Yale University Press</publisher-name>
         <publisher-loc>New Haven; London</publisher-loc>
      </publisher>
      <permissions>
         <copyright-year>2021</copyright-year>
         <copyright-holder>Kate Crawford</copyright-holder>
      </permissions>
      <self-uri xlink:href="https://www.jstor.org/stable/j.ctv1ghv45t"/>
      <abstract abstract-type="short">
         <p>
&lt;strong&gt;The hidden costs of artificial intelligence, from natural
resources and labor to privacy and freedom&lt;/strong&gt; What happens
when artificial intelligence saturates political life and depletes
the planet? How is AI shaping our understanding of ourselves and
our societies? In this book Kate Crawford reveals how this
planetary network is fueling a shift toward undemocratic governance
and increased inequality. Drawing on more than a decade of
research, award-winning science, and technology, Crawford reveals
how AI is a technology of extraction: from the energy and minerals
needed to build and sustain its infrastructure, to the exploited
workers behind "automated" services, to the data AI collects from
us. Rather than taking a narrow focus on code and algorithms,
Crawford offers us a political and a material perspective on what
it takes to make artificial intelligence and where it goes wrong.
While technical systems present a veneer of objectivity, they are
always systems of power. This is an urgent account of what is at
stake as technology companies use artificial intelligence to
reshape the world.
</p>
      </abstract>
      <counts>
         <page-count count="288"/>
      </counts>
      <custom-meta-group>
         <custom-meta>
            <meta-name>
                    lang
                </meta-name>
            <meta-value>eng</meta-value>
         </custom-meta>
      </custom-meta-group>
   </book-meta>
   <body>
      <book-part book-part-type="book-toc-page-order" indexed="yes">
         <body>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctv1ghv45t.1</book-part-id>
                  <title-group>
                     <title>Front Matter</title>
                  </title-group>
                  <fpage>[i]</fpage>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctv1ghv45t.2</book-part-id>
                  <title-group>
                     <title>Table of Contents</title>
                  </title-group>
                  <fpage>[vii]</fpage>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctv1ghv45t.3</book-part-id>
                  <title-group>
                     <title>Introduction</title>
                  </title-group>
                  <fpage>1</fpage>
                  <abstract>
                     <p>At the end of the nineteenth century, Europe was captivated by a horse called Hans. “Clever Hans” was nothing less than a marvel: he could solve math problems, tell time, identify days on a calendar, differentiate musical tones, and spell out words and sentences. People flocked to watch the German stallion tap out answers to complex problems with his hoof and consistently arrive at the right answer. “What is two plus three?” Hans would diligently tap his hoof on the ground five times. “What day of the week is it?” The horse would then tap his hoof to indicate each</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctv1ghv45t.4</book-part-id>
                  <title-group>
                     <label>1</label>
                     <title>Earth</title>
                  </title-group>
                  <fpage>23</fpage>
                  <abstract>
                     <p>The Boeing 757 banks right over San Jose on its final approach to San Francisco International Airport. The left wing drops as the plane lines up with the runway, revealing an aerial view of the tech sector’s most iconic location. Below are the great empires of Silicon Valley. The gigantic black circle of Apple’s headquarters is laid out like an uncapped camera lens, glistening in the sun. Then there’s Google’s head office, nestled close to NASA’s Moffett Federal Airfield. This was once a key site for the U.S. Navy during World War II and the Korean War, but now Google</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctv1ghv45t.5</book-part-id>
                  <title-group>
                     <label>2</label>
                     <title>Labor</title>
                  </title-group>
                  <fpage>53</fpage>
                  <abstract>
                     <p>When I enter Amazon’s vast fulfillment center in Robbinsville, New Jersey, the first thing I see is a large sign that reads “Time Clock.” It juts out from one of the bright yellow concrete pylons spanning across the vast factory space of 1.2 million square feet. This is a major distribution warehouse for smaller objects—a central distribution node for the Northeastern United States. It presents a dizzying spectacle of contemporary logistics and standardization, designed to accelerate the delivery of packages. Dozens of time-clock signs appear at regular intervals along the entryway. Every second of work is being monitored and</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctv1ghv45t.6</book-part-id>
                  <title-group>
                     <label>3</label>
                     <title>Data</title>
                  </title-group>
                  <fpage>89</fpage>
                  <abstract>
                     <p>A young woman gazes upward, eyes focused on something outside the frame, as though she is refusing to acknowledge the camera. In the next photograph, her eyes are locked on the middle distance. Another image shows her with disheveled hair and a downcast expression. Over the sequence of photos we see her aging over time, and the lines around her mouth turn down and deepen. In the final frame she appears injured and dispirited. These are mug shots of a woman across multiple arrests over many years of her life. Her images are contained in a collection known as NIST</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctv1ghv45t.7</book-part-id>
                  <title-group>
                     <label>4</label>
                     <title>Classification</title>
                  </title-group>
                  <fpage>123</fpage>
                  <abstract>
                     <p>I am surrounded by human skulls. This room contains almost five hundred, collected in the early decades of the 1800s. All are varnished, with numbers inscribed in black ink on the frontal bone. Delicate calligraphic circles mark out areas of the skull associated in phrenology with particular qualities, including “Benevolence” and “Veneration.” Some bear descriptions in capital letters, with words like “Dutchman,” “Peruvian of the Inca Race,” or “Lunatic.” Each was painstakingly weighed, measured, and labeled by the American craniologist Samuel Morton. Morton was a physician, natural historian, and member of the Academy of Natural Sciences of Philadelphia. He gathered</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctv1ghv45t.8</book-part-id>
                  <title-group>
                     <label>5</label>
                     <title>Affect</title>
                  </title-group>
                  <fpage>151</fpage>
                  <abstract>
                     <p>In a remote outpost in the mountainous highlands of Papua New Guinea, a young American psychologist named Paul Ekman arrived with a collection of flashcards and a new theory.¹ It was 1967, and Ekman had heard that the Fore people of Okapa were so isolated from the wider world that they would be his ideal test subjects. Like many Western researchers before him, Ekman had come to Papua New Guinea to extract data from the indigenous community. He was gathering evidence to bolster a controversial hypothesis: that all humans exhibit a small number of universal emotions or affects that are</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctv1ghv45t.9</book-part-id>
                  <title-group>
                     <label>6</label>
                     <title>State</title>
                  </title-group>
                  <fpage>181</fpage>
                  <abstract>
                     <p>I’m sitting in front of an air-gapped laptop on the tenth floor of a warehouse building in New York. On the screen is a software program normally used for digital forensics, a tool for investigating evidence and validating information held on hard drives. I’m here to research an archive that contains some of the most specific details about how machine learning began to be used in the intelligence sector, as led by some of the wealthiest governments in the world. This is the Snowden archive: all the documents, PowerPoint presentations, internal memos, newsletters, and technical manuals that former NSA contractor</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctv1ghv45t.10</book-part-id>
                  <title-group>
                     <title>Conclusion.</title>
                     <subtitle>Power</subtitle>
                  </title-group>
                  <fpage>211</fpage>
                  <abstract>
                     <p>Artificial intelligence is not an objective, universal, or neutral computational technique that makes determinations without human direction. Its systems are embedded in social, political, cultural, and economic worlds, shaped by humans, institutions, and imperatives that determine what they do and how they do it. They are designed to discriminate, to amplify hierarchies, and to encode narrow classifications. When applied in social contexts such as policing, the court system, health care, and education, they can reproduce, optimize, and amplify existing structural inequalities. This is no accident: AI systems are built to see and intervene in the world in ways that primarily</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctv1ghv45t.11</book-part-id>
                  <title-group>
                     <title>Coda.</title>
                     <subtitle>Space</subtitle>
                  </title-group>
                  <fpage>229</fpage>
                  <abstract>
                     <p>A countdown begins. File footage starts rolling. Engines at the base of a towering Saturn V ignite, and the rocket begins liftoff. We hear the voice of Jeff Bezos: “Ever since I was five years old—that’s when Neil Armstrong stepped onto the surface of the moon—I’ve been passionate about space, rockets, rocket engines, space travel.” A parade of inspirational images appears: mountain climbers at summits, explorers descending into canyons, an ocean diver swimming through a shoal of fish.</p>
                     <p>Cut to Bezos in a control room during a launch, adjusting his headset. His voiceover continues: “This is the most</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctv1ghv45t.12</book-part-id>
                  <title-group>
                     <title>Acknowledgments</title>
                  </title-group>
                  <fpage>239</fpage>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctv1ghv45t.13</book-part-id>
                  <title-group>
                     <title>Notes</title>
                  </title-group>
                  <fpage>245</fpage>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctv1ghv45t.14</book-part-id>
                  <title-group>
                     <title>Bibliography</title>
                  </title-group>
                  <fpage>269</fpage>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctv1ghv45t.15</book-part-id>
                  <title-group>
                     <title>Index</title>
                  </title-group>
                  <fpage>315</fpage>
               </book-part-meta>
            </book-part>
         </body>
      </book-part>
   </body>
</book>
