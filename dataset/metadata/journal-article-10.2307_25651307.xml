<?xml version="1.0" encoding="UTF-8"?>


<article dtd-version="1.0" article-type="research-article">
  <front>
      <journal-meta>
         <journal-id xmlns:xlink="http://www.w3.org/1999/xlink" journal-id-type="jstor">jcompgrapstat</journal-id>
         <journal-id xmlns:xlink="http://www.w3.org/1999/xlink" journal-id-type="jstor">j100879</journal-id>
         <journal-title-group xmlns:xlink="http://www.w3.org/1999/xlink">
            <journal-title>Journal of Computational and Graphical Statistics</journal-title>
         </journal-title-group>
      
         <publisher>
            <publisher-name>JCGS Management Committee of the American Statistical Association, Institute of Mathematical Statistics, and Interface Foundation of North America</publisher-name>
         </publisher>
         <issn xmlns:xlink="http://www.w3.org/1999/xlink" pub-type="ppub">10618600</issn>
         <custom-meta-group xmlns:xlink="http://www.w3.org/1999/xlink"/>
      </journal-meta>
      <article-meta xmlns:xlink="http://www.w3.org/1999/xlink">
         <volume xmlns:mml="http://www.w3.org/1998/Math/MathML"
                 xmlns:oasis="http://docs.oasis-open.org/ns/oasis-exchange/table">19</volume>
         <issue xmlns:mml="http://www.w3.org/1998/Math/MathML"
                xmlns:oasis="http://docs.oasis-open.org/ns/oasis-exchange/table">1</issue>
         <issue-id>i25651294</issue-id>
         <article-id pub-id-type="jstor">25651307</article-id>
         <title-group>
            <article-title>An Exact Least Trimmed Squares Algorithm for a Range of Coverage Values</article-title>
         </title-group>
         <contrib-group>
            <contrib>
               <string-name>
                  <given-names>Marc</given-names>
                  <surname>Hofmann</surname>
               </string-name>
            </contrib>
            <contrib>
               <string-name>
                  <given-names>Cristian</given-names>
                  <surname>Gatu</surname>
               </string-name>
            </contrib>
            <contrib>
               <string-name>
                  <given-names>Erricos John</given-names>
                  <surname>Kontoghiorghes</surname>
               </string-name>
            </contrib>
         </contrib-group>
         <pub-date pub-type="ppub">
            <day>1</day>
            <month>3</month>
            <year>2010</year>
         </pub-date>
         <fpage>191</fpage>
         <lpage>204</lpage>
      
      
      
      
      
      
      
      
      
         <permissions>
            <copyright-statement>Â© 2010 The American Statistical Association, the Institute of Mathematical Statistics, and the Interface Foundation of North America</copyright-statement>
         </permissions>
      
         <self-uri xlink:href="https://www.jstor.org/stable/25651307"/>
      
      
         <abstract>
            <p>A new algorithm to solve exact least trimmed squares (LTS) regression is presented. The adding row algorithm (ARA) extends existing methods that compute the LTS estimator for a given coverage. It employs a tree-based strategy to compute a set of LTS regressors for a range of coverage values. Thus, prior knowledge of the optimal coverage is not required. New nodes in the regression tree are generated by updating the QR decomposition of the data matrix after adding one observation to the regression model. The ARA is enhanced by employing a branch and bound strategy. The branch and bound algorithm is an exhaustive algorithm that uses a cutting test to prune nonoptimal subtrees. It significantly improves over the ARA in computational performance. Observation preordering throughout the traversal of the regression tree is investigated. A computationally efficient and numerically stable calculation of the bounds using Givens rotations is designed around the QR decomposition, avoiding the need to explicitly update the triangular factor when an observation is added. This reduces the overall computational load of the preordering device by approximately half. A solution is proposed to allow preordering when the model is underdetermined. It employs pseudo-orthogonal rotations to downdate the QR decomposition. The strategies are illustrated by example. Experimental results confirm the computational efficiency of the proposed algorithms. Supplemental materials (R package and formal proofs) are available online.</p>
         </abstract>
         <custom-meta-group>
            <custom-meta>
               <meta-name>lang</meta-name>
               <meta-value>eng</meta-value>
            </custom-meta>
         </custom-meta-group>
      </article-meta>
  </front>
  <back>
    
      <ref-list>
        <title>References</title>
        <ref id="d265078e231a1310">
          
            <mixed-citation id="d265078e235" publication-type="other">
Agullo, J. (2001), "New Algorithms for Computing the Least Trimmed Squares Regression Estimator," Compu-
tational Statistics and Data Analysis, 36, 425-439. [192,194,198,201,203]</mixed-citation>
        </ref>
        <ref id="d265078e245a1310">
          
            <mixed-citation id="d265078e249" publication-type="other">
Alexander, S. T., Pan, C.-T., and Plemmons, R. J. (1988), "Analysis of a Recursive Least Squares Hyperbolic
Rotation Algorithm for Signal Processing," Linear Algebra and Its Applications, 98, 3-40. [199]</mixed-citation>
        </ref>
        <ref id="d265078e259a1310">
          
            <mixed-citation id="d265078e263" publication-type="other">
Atkinson, A. C, and Cheng, T.-C. (1999), "Computing Least Trimmed Squares Regression With the Forward
Search," Statistics and Computing, 9, 251-263. [195,196]</mixed-citation>
        </ref>
        <ref id="d265078e273a1310">
          
            <mixed-citation id="d265078e277" publication-type="other">
Belsley, D. A., Kuh, A. E., and Welsch, R. E. (1980), Regression Diagnostics: Identifying Influential Data and
Sources of Collinearity, New York: Wiley. [193]</mixed-citation>
        </ref>
        <ref id="d265078e288a1310">
          
            <mixed-citation id="d265078e292" publication-type="other">
Bjorck, A., Park, H., and Elden, L. (1994), "Accurate Downdating of Least Squares Solutions," SIAM Journal on
Matrix Analysis and Applications, 15 (2), 549-568. [194]</mixed-citation>
        </ref>
        <ref id="d265078e302a1310">
          
            <mixed-citation id="d265078e306" publication-type="other">
Burks, A. W., Warren, D. W., and Wright, J. B. (1954), "An Analysis of a Logical Machine Using Parenthesis-Free
Notation," Mathematical Tables and Other Aids to Computation, 8 (46), 53-57. [195]</mixed-citation>
        </ref>
        <ref id="d265078e316a1310">
          
            <mixed-citation id="d265078e320" publication-type="other">
Dongarra, J. J., Bunch, J. R., Moler, C. B., and Stewart, G. W. (1979), UNPACK Users' Guide, Philadelphia:
SIAM. [194]</mixed-citation>
        </ref>
        <ref id="d265078e330a1310">
          
            <mixed-citation id="d265078e334" publication-type="other">
Donoho, D. L., and Huber, P. J. (1983), "The Notion of Breakdown Point," in A Festschrift for Erich L. Lehmann
in Honor of His Sixty-Fifth Birthday, eds. P. J. Bickel, K. A. Doksum, E. L. Lehman, and J. L. Hodges, CRC
Press. [192]</mixed-citation>
        </ref>
        <ref id="d265078e347a1310">
          
            <mixed-citation id="d265078e351" publication-type="other">
Furnival, G., and Wilson, R. (1974), "Regression by Leaps and Bounds," Technometrics, 16, 499-511. [193]</mixed-citation>
        </ref>
        <ref id="d265078e358a1310">
          
            <mixed-citation id="d265078e362" publication-type="other">
Gatu, C, and Kontoghiorghes, E. J. (2003), "Parallel Algorithms for Computing All Possible Subset Regression
Models Using the QR Decomposition," Parallel Computing, 29 (4), 505-521. [193]</mixed-citation>
        </ref>
        <ref id="d265078e373a1310">
          
            <mixed-citation id="d265078e377" publication-type="other">
- (2006), "Branch-and-Bound Algorithms for Computing the Best Subset Regression Models," Journal of
Computational and Graphical Statistics, 15, 139-156. [193,202]</mixed-citation>
        </ref>
        <ref id="d265078e387a1310">
          
            <mixed-citation id="d265078e391" publication-type="other">
Gatu, C, Yanev, P., and Kontoghiorghes, E. J. (2007), "A Graph Approach to Generate All Possible Regression
Submodels," Computational Statistics and Data Analysis, 52, 799-815. [193]</mixed-citation>
        </ref>
        <ref id="d265078e401a1310">
          
            <mixed-citation id="d265078e405" publication-type="other">
Gill, P. E., Golub, G. H., Murray, W., and Saunders, M. A. (1974), "Methods for Modifying Matrix Factoriza-
tions," Mathematics of Computations, 28, 505-535. [194,198]</mixed-citation>
        </ref>
        <ref id="d265078e415a1310">
          
            <mixed-citation id="d265078e419" publication-type="other">
Golub, G. H., and Van Loan, C. F. (1996), Matrix Computations. Johns Hopkins Studies in the Mathematical
Sciences (3rd ed.), Baltimore, MD: Johns Hopkins University Press. [194,198,199]</mixed-citation>
        </ref>
        <ref id="d265078e429a1310">
          
            <mixed-citation id="d265078e433" publication-type="other">
Hawkins, D. M. (1994), "The Feasible Solution Algorithm for Least Trimmed Squares Regression," Computa-
tional Statistics and Data Analysis, 17, 185-196. [192]</mixed-citation>
        </ref>
        <ref id="d265078e443a1310">
          
            <mixed-citation id="d265078e447" publication-type="other">
Hawkins, D. M., and Olive, D. J. (1999), "Improved Feasible Solution Algorithms for High Breakdown Estima-
tion," Computational Statistics and Data Analysis, 30, 1-11. [192]</mixed-citation>
        </ref>
        <ref id="d265078e458a1310">
          
            <mixed-citation id="d265078e462" publication-type="other">
Hofmann, M., Gatu, C, and Kontoghiorghes, E. J. (2007), "Efficient Algorithms for Computing the Best-Subset
Regression Models for Large-Scale Problems," Computational Statistics and Data Analysis, 52, 16-29. [195,
200]</mixed-citation>
        </ref>
        <ref id="d265078e475a1310">
          
            <mixed-citation id="d265078e479" publication-type="other">
Hossjer, O. (1995), "Exact Computation of the Least Trimmed Squares Estimate in Simple Linear Regression,"
Computational Statistics and Data Analysis, 19 (3), 265-282. [192]</mixed-citation>
        </ref>
        <ref id="d265078e489a1310">
          
            <mixed-citation id="d265078e493" publication-type="other">
Morgenthaler, S. (1991), "A Note on Efficient Regression Estimators With Positive Breakdown Point," Statistics
and Probability Letters, 11,469-472. [193]</mixed-citation>
        </ref>
        <ref id="d265078e503a1310">
          
            <mixed-citation id="d265078e507" publication-type="other">
Narendra, P. M., and Fukunaga, K. (1977), "A Branch and Bound Algorithm for Feature Subset Selection," IEEE
Transactions on Computers, 26 (9), 917-922. [194]</mixed-citation>
        </ref>
        <ref id="d265078e517a1310">
          
            <mixed-citation id="d265078e521" publication-type="other">
Newell, A., and Shaw, J. C. (1957), "Programming the Logic Theory Machine" in Proceedings of the Western
Joint Computer Conference, Institute of Radio Engineers, pp. 230-240. [195]</mixed-citation>
        </ref>
        <ref id="d265078e531a1310">
          
            <mixed-citation id="d265078e535" publication-type="other">
Rousseeuw, P. J. (1984), "Least Median of Squares Regression," Journal of the American Statistical Association,
19, 871-880. [192]</mixed-citation>
        </ref>
        <ref id="d265078e546a1310">
          
            <mixed-citation id="d265078e550" publication-type="other">
- (1997), "Introduction to Positive-Breakdown Methods," in Handbook of Statistics, Vol. 15, eds. G. S.
Maddala and C. R. Rao, Elsevier, pp. 101-121. [192,193]</mixed-citation>
        </ref>
        <ref id="d265078e560a1310">
          
            <mixed-citation id="d265078e564" publication-type="other">
Rousseeuw, P. J., and Leroy, A. M. (1987), Robust Regression and Outlier Detection, Wiley. [192]</mixed-citation>
        </ref>
        <ref id="d265078e571a1310">
          
            <mixed-citation id="d265078e575" publication-type="other">
Rousseeuw, P. J., and Van Driessen, K. (2006), "Computing LTS Regression for Large Data Sets," Data Mining
and Knowledge Discovery, 12, 29-45. [192,196,200]</mixed-citation>
        </ref>
        <ref id="d265078e585a1310">
          
            <mixed-citation id="d265078e589" publication-type="other">
Smith, D. M., and Bremner, J. M. (1989), "All Possible Subset Regressions Using the QR Decomposition,"
Computational Statistics and Data Analysis, 7 (3), 217-235. [193]</mixed-citation>
        </ref>
        <ref id="d265078e599a1310">
          
            <mixed-citation id="d265078e603" publication-type="other">
Stefanski, L. A. (1991), "A Note on High-Breakdown Estimators," Statistics and Probability Letters, 11,353-358.
[193]</mixed-citation>
        </ref>
      </ref-list>
    
  </back>
</article>


