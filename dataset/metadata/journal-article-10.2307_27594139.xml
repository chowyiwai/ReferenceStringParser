<?xml version="1.0" encoding="UTF-8"?>


<article dtd-version="1.0" article-type="research-article">
  <front>
      <journal-meta>
         <journal-id xmlns:xlink="http://www.w3.org/1999/xlink" journal-id-type="jstor">jcompgrapstat</journal-id>
         <journal-id xmlns:xlink="http://www.w3.org/1999/xlink" journal-id-type="jstor">j100879</journal-id>
         <journal-title-group xmlns:xlink="http://www.w3.org/1999/xlink">
            <journal-title>Journal of Computational and Graphical Statistics</journal-title>
         </journal-title-group>
      
         <publisher>
            <publisher-name>American Statistical Association, Institute of Mathematical Statistics, and Interface Foundation of North America</publisher-name>
         </publisher>
         <issn xmlns:xlink="http://www.w3.org/1999/xlink" pub-type="ppub">10618600</issn>
         <custom-meta-group xmlns:xlink="http://www.w3.org/1999/xlink"/>
      </journal-meta>
      <article-meta xmlns:xlink="http://www.w3.org/1999/xlink">
         <volume xmlns:mml="http://www.w3.org/1998/Math/MathML"
                 xmlns:oasis="http://docs.oasis-open.org/ns/oasis-exchange/table">14</volume>
         <issue xmlns:mml="http://www.w3.org/1998/Math/MathML"
                xmlns:oasis="http://docs.oasis-open.org/ns/oasis-exchange/table">3</issue>
         <issue-id>i27594128</issue-id>
         <article-id pub-id-type="jstor">27594139</article-id>
         <article-id pub-id-type="pub-doi">10.1198/106186005X59630</article-id>
         <title-group>
            <article-title>The Design and Analysis of Benchmark Experiments</article-title>
         </title-group>
         <contrib-group>
            <contrib>
               <string-name>
                  <given-names>Torsten</given-names>
                  <surname>Hothorn</surname>
               </string-name>
            </contrib>
            <contrib>
               <string-name>
                  <given-names>Friedrich</given-names>
                  <surname>Leisch</surname>
               </string-name>
            </contrib>
            <contrib>
               <string-name>
                  <given-names>Achim</given-names>
                  <surname>Zeileis</surname>
               </string-name>
            </contrib>
            <contrib>
               <string-name>
                  <given-names>Kurt</given-names>
                  <surname>Hornik</surname>
               </string-name>
            </contrib>
         </contrib-group>
         <pub-date pub-type="ppub">
            <day>1</day>
            <month>9</month>
            <year>2005</year>
         </pub-date>
         <fpage>675</fpage>
         <lpage>699</lpage>
         <permissions>
            <copyright-statement>Copyright 2005 American Statistical Association, the Institute of Mathematical Statistics, and the Interface Foundation of North America</copyright-statement>
         </permissions>
         <self-uri xlink:href="https://www.jstor.org/stable/27594139"/>
      
      
         <abstract>
            <p>The assessment of the performance of learners by means of benchmark experiments is an established exercise. In practice, benchmark studies are a tool to compare the performance of several competing algorithms for a certain learning problem. Cross-validation or resampling techniques are commonly used to derive point estimates of the performances which are compared to identify algorithms with good properties. For several benchmarking problems, test procedures taking the variability of those point estimates into account have been suggested. Most of the recently proposed inference procedures are based on special variance estimators for the cross-validated performance. We introduce a theoretical framework for inference problems in benchmark experiments and show that standard statistical test procedures can be used to test for differences in the performances. The theory is based on well-defined distributions of performance measures which can be compared with established tests. To demonstrate the usefulness in practice, the theoretical results are applied to regression and classification benchmark studies based on artificial and real world data.</p>
         </abstract>
         <kwd-group>
            <kwd>Bootstrap</kwd>
            <kwd>Cross-validation</kwd>
            <kwd>Hypothesis testing</kwd>
            <kwd>Model comparison</kwd>
            <kwd>Performance</kwd>
         </kwd-group>
         <custom-meta-group>
            <custom-meta>
               <meta-name>lang</meta-name>
               <meta-value>eng</meta-value>
            </custom-meta>
         </custom-meta-group>
      </article-meta>
  </front>
  <back>
    
      <ref-list>
        <title>References</title>
        <ref id="d706166e171a1310">
          
            <mixed-citation id="d706166e175" publication-type="other">
Alpaydin, E. (1999), "Combined 5 x 2 cv F Test for Comparing Supervised Classification Learning Algorithms,"
Neural Computation, 11, 1885–1892.</mixed-citation>
        </ref>
        <ref id="d706166e185a1310">
          
            <mixed-citation id="d706166e189" publication-type="other">
Bartlett, P. L., Boucheron, S., and Lugosi, G. (2002), "Model Selection and Error Estimation," Machine Learning,
48,85–113.</mixed-citation>
        </ref>
        <ref id="d706166e199a1310">
          
            <mixed-citation id="d706166e203" publication-type="other">
Bauer, E., and Kohavi, R. (1999), "An Empirical Comparison of Voting Classification Algorithms: Bagging,
Boosting, and Variants," Machine Learning, 36, 105–139.</mixed-citation>
        </ref>
        <ref id="d706166e213a1310">
          
            <mixed-citation id="d706166e217" publication-type="other">
Berger, V. W. (2000), "Pros and Cons of Permutation Tests in Clinical Trials," Statistics in Medicine, 19, 1319–
1328.</mixed-citation>
        </ref>
        <ref id="d706166e228a1310">
          
            <mixed-citation id="d706166e232" publication-type="other">
Berger, V. W., Lunneborg, C., Ernst, M. D., and Levine, J. G. (2002), "Parametric Analyses in Randomized Clinical
Trials," Journal of Modern Applied Statistical Methods, 1, 74–82.</mixed-citation>
        </ref>
        <ref id="d706166e242a1310">
          
            <mixed-citation id="d706166e246" publication-type="other">
Blake, C. L., and Merz, C. J. (1998), "UCI Repository of Machine Learning Databases," http://www.ics.uci.edu/
~mlearn/MLRepository.html.</mixed-citation>
        </ref>
        <ref id="d706166e256a1310">
          
            <mixed-citation id="d706166e260" publication-type="other">
Blocked, H., and Struyf, J. (2002), "Efficient Algorithms for Decision Tree Cross-Validation," Journal of Machine
Learning Research, 3, 621–650.</mixed-citation>
        </ref>
        <ref id="d706166e270a1310">
          
            <mixed-citation id="d706166e274" publication-type="other">
Breiman, L. (1996a), "Bagging Predictors," Machine Learning, 24, 123–140.</mixed-citation>
        </ref>
        <ref id="d706166e281a1310">
          
            <mixed-citation id="d706166e285" publication-type="other">
—(1996b), "Out-of-Bag Estimation," Technical report, Statistics Department, University of California
Berkeley, Berkeley CA 94708, ftp://ftp.stat.berkeley.edu/pub/users/breiman/.</mixed-citation>
        </ref>
        <ref id="d706166e295a1310">
          
            <mixed-citation id="d706166e299" publication-type="other">
—(2001a), "Random Forests," Machine Learning, 45, 5–32.</mixed-citation>
        </ref>
        <ref id="d706166e307a1310">
          
            <mixed-citation id="d706166e311" publication-type="other">
—(2001b), "Statistical Modeling: The Two Cultures" (with discussion), Statistical Science, 16, 199–231.</mixed-citation>
        </ref>
        <ref id="d706166e318a1310">
          
            <mixed-citation id="d706166e322" publication-type="other">
Breiman, L., and Friedman, J. H. (1985), "Estimating Optimal Transformations for Multiple Regression and
Correlation," Journal of the American Statistical Association, 80, 580–598.</mixed-citation>
        </ref>
        <ref id="d706166e332a1310">
          
            <mixed-citation id="d706166e336" publication-type="other">
Bylander, T. (2002), "Estimating Generalization Error on Two-Class Datasets Using Out-of-Bag Estimates,"
Machine Learning, 48, 287–297.</mixed-citation>
        </ref>
        <ref id="d706166e346a1310">
          
            <mixed-citation id="d706166e350" publication-type="other">
Bühlmann, P. (2002), "Bootstraps for Time Series," Statistical Science, 17, 52–72.</mixed-citation>
        </ref>
        <ref id="d706166e357a1310">
          
            <mixed-citation id="d706166e361" publication-type="other">
Chang, C.-C, and Lin, C.-J. (2001), LIBSVM: A Library for Support Vector Machines, Department of Com-
puter Science and Information Engineering, National Taiwan University, http://www.csie.ntu.edu.tw/~cjlin/
libsvm.</mixed-citation>
        </ref>
        <ref id="d706166e374a1310">
          
            <mixed-citation id="d706166e378" publication-type="other">
Dietterich, T. G. (1998), "Approximate Statistical Tests for Comparing Supervised Classification Learning Algo-
rithms," Neural Computation, 10, 1895–1923.</mixed-citation>
        </ref>
        <ref id="d706166e389a1310">
          
            <mixed-citation id="d706166e393" publication-type="other">
—(2000), "An Experimental Comparison of Three Methods for Constructing Ensembles of Decision Trees:
Bagging, Boosting, and Randomization," Machine Learning, 40, 139–157.</mixed-citation>
        </ref>
        <ref id="d706166e403a1310">
          
            <mixed-citation id="d706166e407" publication-type="other">
Dimitriadou, E., Hornik, K., Leisch, F., Meyer, D., and Weingessel, A. (2004), e1071: Mise Functions of the
Department of Statistics (e1071), TU Wien, R package version 1.5-1, http://CRAN.R-project.org.</mixed-citation>
        </ref>
        <ref id="d706166e417a1310">
          
            <mixed-citation id="d706166e421" publication-type="other">
Dudoit, S., and van der Laan, M. J. (2005), "Asymptotics of Cross-Validated Risk Estimation in Estimator Selection
and Performance Assessment," Statistical Methodology, 2, 131–154.</mixed-citation>
        </ref>
        <ref id="d706166e431a1310">
          
            <mixed-citation id="d706166e435" publication-type="other">
Efron, B. (1983), "Estimating the Error Rate of a Prediction Rule: Improvements on Cross-Validation," Journal
of the American Statistical Association, 78, 316–331.</mixed-citation>
        </ref>
        <ref id="d706166e445a1310">
          
            <mixed-citation id="d706166e449" publication-type="other">
—(1986), "How Biased is the Apparent Error Rate of a Prediction Rule?" Journal of the American Statistical
Association, 81, 461–470.</mixed-citation>
        </ref>
        <ref id="d706166e459a1310">
          
            <mixed-citation id="d706166e463" publication-type="other">
Efron, B., and Tibshirani, R. J. (1993), An Introduction to the Bootstrap, New York: Chapman &amp;amp; Hall.</mixed-citation>
        </ref>
        <ref id="d706166e471a1310">
          
            <mixed-citation id="d706166e475" publication-type="other">
—(1997), "Improvements on Cross-Validation: The .632+ Bootstrap Method," Journal of the American
Statistical Association, 92, 548–560.</mixed-citation>
        </ref>
        <ref id="d706166e485a1310">
          
            <mixed-citation id="d706166e489" publication-type="other">
Freund, Y., and Schapire, R. E. (1996), "Experiments with a New Boosting Algorithm," in Machine Learning:
Proceedings of the Thirteenth International Conference, ed. L. Saitta, San Francisco: Morgan Kaufmann,
pp. 148–156.</mixed-citation>
        </ref>
        <ref id="d706166e502a1310">
          
            <mixed-citation id="d706166e506" publication-type="other">
Friedman, J. H. (1991), "Multivariate Adaptive Regression Splines," The Annals of Statistics, 19, 1–67.</mixed-citation>
        </ref>
        <ref id="d706166e513a1310">
          
            <mixed-citation id="d706166e517" publication-type="other">
George, E. I. (2000), "The Variable Selection Problem," Journal of the American Statistical Association, 95,
1304–1308.</mixed-citation>
        </ref>
        <ref id="d706166e527a1310">
          
            <mixed-citation id="d706166e531" publication-type="other">
Gu, C., and Xiang, D. (2001), "Cross-Validating Non-Gaussian Data: Generalized Approximate Cross-Validation
Revisited," Journal of Computational and Graphical Statistics, 10, 581–591.</mixed-citation>
        </ref>
        <ref id="d706166e541a1310">
          
            <mixed-citation id="d706166e545" publication-type="other">
Hájek, J., Sidák, Z., and Sen, P. K. (1999), Theory of Rank Tests (2nd ed.), London: Academic Press.</mixed-citation>
        </ref>
        <ref id="d706166e553a1310">
          
            <mixed-citation id="d706166e557" publication-type="other">
Hastie, T., Tibshirani, R., and Friedman, J. (2001), The Elements of Statistical Learning (Data Mining, Inference
and Prediction), New York: Springer Verlag.</mixed-citation>
        </ref>
        <ref id="d706166e567a1310">
          
            <mixed-citation id="d706166e571" publication-type="other">
Hochberg, Y., and Tamhane, A. C. (1987), Multiple Comparison Procedures, New York: Wiley.</mixed-citation>
        </ref>
        <ref id="d706166e578a1310">
          
            <mixed-citation id="d706166e582" publication-type="other">
Hothorn, T. (2003), "Bundling Classifiers with an Application to Glaucoma Diagnosis," Ph.D. thesis, Department
of Statistics, University of Dortmund, Germany, http://eldorado.uni-dortmund.de:8080/FB5/ls7/forschung/
2003/Hothorn.</mixed-citation>
        </ref>
        <ref id="d706166e595a1310">
          
            <mixed-citation id="d706166e599" publication-type="other">
Hothorn, T., and Lausen, B. (2003), "Double-Bagging: Combining Classifiers by Bootstrap Aggregation," Pattern
Recognition, 36, 1303–1309.</mixed-citation>
        </ref>
        <ref id="d706166e609a1310">
          
            <mixed-citation id="d706166e613" publication-type="other">
—(2005), "Bundling Classifiers by Bagging Trees," Computational Statistics &amp;amp; Data Analysis, 49, 1068–
1075.</mixed-citation>
        </ref>
        <ref id="d706166e623a1310">
          
            <mixed-citation id="d706166e627" publication-type="other">
Ihaka, R., and Gentleman, R. (1996), "R: A Language for Data Analysis and Graphics," Journal of Computational
and Graphical Statistics, 5, 299–314.</mixed-citation>
        </ref>
        <ref id="d706166e638a1310">
          
            <mixed-citation id="d706166e642" publication-type="other">
Kim, H., and Loh, W.-Y. (2003), "Classification Trees with Bivariate Linear Discriminant Node Models," Journal
of Computational and Graphical Statistics, 12, 512–530.</mixed-citation>
        </ref>
        <ref id="d706166e652a1310">
          
            <mixed-citation id="d706166e656" publication-type="other">
Läuter, J. (1992), Stabile Multivariate Verfahren: Diskriminanzanalyse-Regressionsanalyse-Faktoranalyse,
Berlin: Akademie Verlag.</mixed-citation>
        </ref>
        <ref id="d706166e666a1310">
          
            <mixed-citation id="d706166e670" publication-type="other">
Liaw, A., and Wiener, M. (2002), "Classification and Regression by randomForest, R News, 2, 18–22.</mixed-citation>
        </ref>
        <ref id="d706166e677a1310">
          
            <mixed-citation id="d706166e681" publication-type="other">
Lim, T.-S., Loh, W.-Y., and Shih, Y.-S. (2000), "A Comparison of Prediction Accuracy, Complexity, and Training
Time of Thirty-Three Old and New Classification Algorithms," Machine Learning, 40, 203–228.</mixed-citation>
        </ref>
        <ref id="d706166e691a1310">
          
            <mixed-citation id="d706166e695" publication-type="other">
Meyer, D. (2001), "Support Vector Machines," R News, 1, 23–26.</mixed-citation>
        </ref>
        <ref id="d706166e702a1310">
          
            <mixed-citation id="d706166e706" publication-type="other">
Meyer, D., Leisch, F., and Hornik, K. (2003), "The Support Vector Machine under Test," Neurocomputing, 55,
169–186.</mixed-citation>
        </ref>
        <ref id="d706166e717a1310">
          
            <mixed-citation id="d706166e721" publication-type="other">
Nadeau, C., and Bengio, Y. (2003), "Inference for the Generalization Error," Machine Learning, 52, 239–281.</mixed-citation>
        </ref>
        <ref id="d706166e728a1310">
          
            <mixed-citation id="d706166e732" publication-type="other">
Patterson, J. G. (1992), Benchmarking Basics, Menlo Park, CA: Crisp Publications Inc.</mixed-citation>
        </ref>
        <ref id="d706166e739a1310">
          
            <mixed-citation id="d706166e743" publication-type="other">
Pesarin, F. (2001), Multivariate Permutation Tests: With Applications to Biostatistics, Chichester: Wiley.</mixed-citation>
        </ref>
        <ref id="d706166e750a1310">
          
            <mixed-citation id="d706166e754" publication-type="other">
Peters, A., Hothorn, T., and Lausen, B. (2002), "ipred: Improved Predictors, R News, 2, 33–36.</mixed-citation>
        </ref>
        <ref id="d706166e761a1310">
          
            <mixed-citation id="d706166e765" publication-type="other">
Pittman, J. (2002), "Adaptive Splines and Genetic Algorithms," Journal of Computational and Graphical Statistics,
11,615–638.</mixed-citation>
        </ref>
        <ref id="d706166e775a1310">
          
            <mixed-citation id="d706166e779" publication-type="other">
Pizarro, J., Guerrero, E., and Galindo, P. L. (2002), "Multiple Comparison Procedures Applied to Model Selection,"
Neurocomputing, 48, 155–173.</mixed-citation>
        </ref>
        <ref id="d706166e790a1310">
          
            <mixed-citation id="d706166e794" publication-type="other">
R Development Core Team (2004), R: A Language and Environment for Statistical Computing, R Foundation for
Statistical Computing, Vienna, Austria, ISBN 3-900051-00-3.</mixed-citation>
        </ref>
        <ref id="d706166e804a1310">
          
            <mixed-citation id="d706166e808" publication-type="other">
Ripley, B. D. (1996), Pattern Recognition and Neural Networks, Cambridge, UK: Cambridge University Press.</mixed-citation>
        </ref>
        <ref id="d706166e815a1310">
          
            <mixed-citation id="d706166e819" publication-type="other">
Schiavo, R. A., and Hand, D. J. (2000), "Ten More Years of Error Rate Research," International Statistical Review,
68,295–310.</mixed-citation>
        </ref>
        <ref id="d706166e829a1310">
          
            <mixed-citation id="d706166e833" publication-type="other">
Stone, M. (1974), "Cross-Validatory Choice and Assessment of Statistical Predictions," Journal of the Royal
Statistical Society, Series B, 36, 111–147.</mixed-citation>
        </ref>
        <ref id="d706166e843a1310">
          
            <mixed-citation id="d706166e847" publication-type="other">
Therneau, T. M., and Atkinson, E. J. (1997), "An Introduction to Recursive Partitioning using the rpart Routine,
Technical Report 61, Section of Biostatistics, Mayo Clinic, Rochester, http://www.mayo.edu/hsr/techrpt/61.
pdf.</mixed-citation>
        </ref>
        <ref id="d706166e860a1310">
          
            <mixed-citation id="d706166e864" publication-type="other">
Vapnik, V. (1998), Statistical Learning Theory, New York: Wiley.</mixed-citation>
        </ref>
        <ref id="d706166e872a1310">
          
            <mixed-citation id="d706166e876" publication-type="other">
Vehtari, A., and Lampinen, J. (2002), "Bayesian Model Assessment and Comparison Using Cross-Validation
Predictive Densities," Neural Computation, 14, 2439–2468.</mixed-citation>
        </ref>
        <ref id="d706166e886a1310">
          
            <mixed-citation id="d706166e890" publication-type="other">
Venables, W. N., and Ripley, B. D. (2002), Modern Applied Statistics with S (4th ed.), New York: Springer,
http://www.stats.ox.ac.uk/pub/MASS4/.</mixed-citation>
        </ref>
        <ref id="d706166e900a1310">
          
            <mixed-citation id="d706166e904" publication-type="other">
Wolpert, D. H., and Macready, W. G. (1999), "An Efficient Method to Estimate Bagging's Generalization Error,"
Machine Learning, 35, 41–51.</mixed-citation>
        </ref>
      </ref-list>
    
  </back>
</article>


