<?xml version="1.0" encoding="UTF-8"?>


<article dtd-version="1.0" article-type="research-article">
  <front>
      <journal-meta>
         <journal-id xmlns:xlink="http://www.w3.org/1999/xlink" journal-id-type="jstor">jcompgrapstat</journal-id>
         <journal-id xmlns:xlink="http://www.w3.org/1999/xlink" journal-id-type="jstor">j100879</journal-id>
         <journal-title-group xmlns:xlink="http://www.w3.org/1999/xlink">
            <journal-title>Journal of Computational and Graphical Statistics</journal-title>
         </journal-title-group>
      
         <publisher>
            <publisher-name>American Statistical Association, Institute of Mathematical Statistics, and Interface Foundation of North America</publisher-name>
         </publisher>
         <issn xmlns:xlink="http://www.w3.org/1999/xlink" pub-type="ppub">10618600</issn>
         <issn xmlns:xlink="http://www.w3.org/1999/xlink" pub-type="epub">15372715</issn>
         <custom-meta-group xmlns:xlink="http://www.w3.org/1999/xlink"/>
      </journal-meta>
      <article-meta xmlns:xlink="http://www.w3.org/1999/xlink">
         <volume xmlns:mml="http://www.w3.org/1998/Math/MathML"
                 xmlns:oasis="http://docs.oasis-open.org/ns/oasis-exchange/table">24</volume>
         <issue xmlns:mml="http://www.w3.org/1998/Math/MathML"
                xmlns:oasis="http://docs.oasis-open.org/ns/oasis-exchange/table">2</issue>
         <issue-id>i24737208</issue-id>
         <article-id pub-id-type="doi">10.2307/24737281</article-id>
         <article-categories>
            <subj-group>
               <subject>Gaussian Processes</subject>
            </subj-group>
         </article-categories>
         <title-group>
            <article-title>Local Gaussian Process Approximation for Large Computer Experiments</article-title>
         </title-group>
         <contrib-group>
            <contrib>
               <string-name>
                  <given-names>Robert B.</given-names>
                  <surname>Gramacy</surname>
               </string-name>
            </contrib>
            <contrib>
               <string-name>
                  <given-names>Daniel W.</given-names>
                  <surname>Apley</surname>
               </string-name>
            </contrib>
         </contrib-group>
         <pub-date pub-type="ppub">
            <day>1</day>
            <month>6</month>
            <year>2015</year>
         </pub-date>
         <fpage>561</fpage>
         <lpage>578</lpage>
      
      
      
      
      
         <permissions>
            <copyright-statement>© 2015 American Statistical Association, the Institute of Mathematical Statistics, and the Interface Foundation of North America</copyright-statement>
         </permissions>
         <self-uri xlink:href="https://www.jstor.org/stable/24737281"/>
      
      
         <abstract>
            <p>We provide a new approach to approximate emulation of large computer experiments. By focusing expressly on desirable properties of the predictive equations, we derive a family of local sequential design schemes that dynamically define the support of a Gaussian process predictor based on a local subset of the data. We further derive expressions for fast sequential updating of all needed quantities as the local designs are built up iteratively. Then we show how independent application of our local design strategy across the elements of a vast predictive grid facilitates a trivially parallel implementation. The end result is a global predictor able to take advantage of modern multicore architectures, providing a nonstationary modeling feature as a bonus. We demonstrate our method on two examples using designs with thousands of data points, and compare to the method of compactly supported covariances. Supplementary materials for this article are available online.</p>
         </abstract>
         <custom-meta-group>
            <custom-meta>
               <meta-name>lang</meta-name>
               <meta-value>eng</meta-value>
            </custom-meta>
         </custom-meta-group>
      </article-meta>
  </front>
  <back>
    
      <ref-list>
        <title>REFERENCES</title>
        <ref id="d1472e202a1310">
          
            <mixed-citation id="d1472e206" publication-type="other">
Anagnostopoulos, C, and Gramacy, R. B. (2013), "Information-Theoretic Data Discarding for Dynamic Trees on
Data Streams," Entropy, 15, 5510-5535. [567]</mixed-citation>
        </ref>
        <ref id="d1472e216a1310">
          
            <mixed-citation id="d1472e220" publication-type="other">
Berger, J., De Oliveira, V., and Sanso, B. (2001), "Objective Bayesian Analysis of Spatially Correlated Data,"
Journal of the American Statistical Association, 96, 1361-1374. [563]</mixed-citation>
        </ref>
        <ref id="d1472e230a1310">
          
            <mixed-citation id="d1472e234" publication-type="other">
Cohn, D. A. (1996), "Neural Network Exploration Using Optimal Experimental Design," Neural Networks, 9,
1071-1083. [562,567]</mixed-citation>
        </ref>
        <ref id="d1472e244a1310">
          
            <mixed-citation id="d1472e248" publication-type="other">
Cressie, N. (1991), Statistics for Spatial Data (revised edition), New York: Wiley. [562]</mixed-citation>
        </ref>
        <ref id="d1472e256a1310">
          
            <mixed-citation id="d1472e260" publication-type="other">
Cressie, N., and Johannesson, G. (2008), "Fixed Rank Kriging for Very Large Data Sets," Journal of the Royal
Statistical Society, Series B, 70, 209-226, [562]</mixed-citation>
        </ref>
        <ref id="d1472e270a1310">
          
            <mixed-citation id="d1472e274" publication-type="other">
Datta, A., Banetjee, S., Finley, A. O., and Gelfand, A. E. (2014), "Hierarchical Nearest-Neighbor Gaussian Process
Models for Large Geostatistical Datasets," Tech. rep., University of Minnesota. ArXiv: 1406.7343. [575,577]</mixed-citation>
        </ref>
        <ref id="d1472e284a1310">
          
            <mixed-citation id="d1472e288" publication-type="other">
Emory, X. (2009), "The Kriging Update Equations and Their Application to the Selection of Neighboring Data,"
Computational Geosciences, 13, 269-280. [575]</mixed-citation>
        </ref>
        <ref id="d1472e298a1310">
          
            <mixed-citation id="d1472e302" publication-type="other">
Gramacy, R. B. (2013), laGP: Local Approximate Gaussian Process Regression, R package version 1.0. [563]</mixed-citation>
        </ref>
        <ref id="d1472e309a1310">
          
            <mixed-citation id="d1472e313" publication-type="other">
Gramacy, R. B., and Lee, H. K. H. (2009), "Adaptive Design and Analysis of Supercomputer Experiments,"
Technometrics, 51,130-145. [562,567]</mixed-citation>
        </ref>
        <ref id="d1472e323a1310">
          
            <mixed-citation id="d1472e327" publication-type="other">
—— (2011), "Optimization Under Unknown Constraints," in Bayesian Statistics 9, eds. J. Bernardo, S. Bayarri,
J. Berger, A. Dawid, D. Heckerman, A. Smith, and M. West, New York: Oxford University Press Inc., pp.
229-256. [568]</mixed-citation>
        </ref>
        <ref id="d1472e341a1310">
          
            <mixed-citation id="d1472e345" publication-type="other">
Gramacy, R. B., Bingham, D., Holloway, J. P., Grosskopf, M. J., Kuranz, C. C., Rutter, E., Trantham, M.,
and Drake, P. R. (2014), "Calibrating a Large Computer Experiment Simulating Radiative Shock Hydro-
dynamics," arXiv: 1410.3293. [575,577]</mixed-citation>
        </ref>
        <ref id="d1472e358a1310">
          
            <mixed-citation id="d1472e362" publication-type="other">
Gramacy, R., Niemi, J., and Weiss, R. (2014), "Massively Parallel Approximate Gaussian Process Regression,"
Journal of Uncertainty Quantification, 2, 564-584. [577]</mixed-citation>
        </ref>
        <ref id="d1472e372a1310">
          
            <mixed-citation id="d1472e376" publication-type="other">
Gramacy, R., and Poison, N. (2011), "Particle Learning of Gaussian Process Models for Sequential Design and
Optimization," Journal of Computational and Graphical Statistics, 20, 1,102-118. [562]</mixed-citation>
        </ref>
        <ref id="d1472e386a1310">
          
            <mixed-citation id="d1472e390" publication-type="other">
Haaland, B., and Qian, P. (2011), "Accurate Emulators for Large-Scale Computer Experiments," The Annals of
Statistics, 39, 2974-3002. [562]</mixed-citation>
        </ref>
        <ref id="d1472e400a1310">
          
            <mixed-citation id="d1472e404" publication-type="other">
Kaufman, C., Bingham, D., Habib, S., Heitmann, K., and Frieman, J. (2012), "Efficient Emulators of Computer
Experiments Using Compactly Supported Correlation Functions, With An Application to Cosmology," Annals
of Applied Statistics, 5,2470-2492. [562,574,576]</mixed-citation>
        </ref>
        <ref id="d1472e417a1310">
          
            <mixed-citation id="d1472e421" publication-type="other">
Morris, D., Mitchell, T., and Ylvisaker, D. (1993), "Bayesian Design and Analysis of Computer Experiments:
Use of Derivatives in Surface Prediction," Technometrics, 35, 243-255. [573]</mixed-citation>
        </ref>
        <ref id="d1472e432a1310">
          
            <mixed-citation id="d1472e436" publication-type="other">
Paciorek, C. J., and Schervish, M. J. (2006), "Spatial Modelling Using a New Class of Nonstationary Covariance
Functions," Envimnmetrics, 17,483-506. [562]</mixed-citation>
        </ref>
        <ref id="d1472e446a1310">
          
            <mixed-citation id="d1472e450" publication-type="other">
Santner, T. J., Williams, B. J., and Notz, W. I. (2003), The Design and Analysis of Computer Experiments, New
York: Springer-Verlag. [561]</mixed-citation>
        </ref>
        <ref id="d1472e460a1310">
          
            <mixed-citation id="d1472e464" publication-type="other">
Schmidt, A. M., and O'Hagan, A. (2003), "Bayesian Inference for Nonstationary Spatial Covariance Structure
via Spatial Deformations," Journal of the Royal Statistical Society, Series B, 65,745-758. [561]</mixed-citation>
        </ref>
        <ref id="d1472e474a1310">
          
            <mixed-citation id="d1472e478" publication-type="other">
Seo, S., Wallat, M., Graepel, T., and Obermayer, K. (2000), "Gaussian Process Regression: Active Data Selection
and Test Point Rejection," in Proceedings of the IEEE International Joint Conference on Neural Networks
(Vol. Ill), pp. 241-246. [567]</mixed-citation>
        </ref>
        <ref id="d1472e491a1310">
          
            <mixed-citation id="d1472e495" publication-type="other">
Snelson, E., and Ghahramani, Z. (2006), "Sparse Gaussian Processes Using Pseudo-Inputs," in Advances in Neural
Information Processing Systems, Cambridge, MA: MIT Press, pp. 1257-1264. [562]</mixed-citation>
        </ref>
        <ref id="d1472e505a1310">
          
            <mixed-citation id="d1472e509" publication-type="other">
Stein, M. L., Chi, Z., and Welty, L. J. (2004), "Approximating Likelihoods for Large Spatial Data Sets," Journal
of the Royal Statistical Society, Series B, 66, 275-296. [562,564]</mixed-citation>
        </ref>
        <ref id="d1472e520a1310">
          
            <mixed-citation id="d1472e524" publication-type="other">
Vecchia, A. (1988), "Estimation and Model Identification for Continuous Spatial Processes," Journal of the Royal
Statistical Society, Series B, 50,297-312. [564]</mixed-citation>
        </ref>
        <ref id="d1472e534a1310">
          
            <mixed-citation id="d1472e538" publication-type="other">
Worley, B. (1987), "Deterministic Uncertainty Analysis," Technical Report ORN-0628, National Technical Infor-
mation Service, Springfield, VA. [573]</mixed-citation>
        </ref>
      </ref-list>
    
  </back>
</article>


