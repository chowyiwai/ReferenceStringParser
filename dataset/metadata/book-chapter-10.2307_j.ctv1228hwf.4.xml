

<book xmlns:oasis="http://docs.oasis-open.org/ns/oasis-exchange/table"
      xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
      xmlns:xlink="http://www.w3.org/1999/xlink"
      xmlns:mml="http://www.w3.org/1998/Math/MathML"
      dtd-version="0.2"
      xml:lang="spa">
   <collection-meta>
      <collection-id collection-id-type="jstor">j.ctv1228fqw</collection-id>
   </collection-meta>
   <book-meta>
      <book-id book-id-type="doi">10.2307/j.ctv1228hwf</book-id>
      <subj-group>
         <subject content-type="lcsh">Inteligencia artificial</subject>
      </subj-group>
      <subj-group>
         <subject content-type="lcsh">Redes neurales (Informática)</subject>
      </subj-group>
      <subj-group subj-group-type="discipline">
         <subject>Engineering</subject>
         <subject>Computer Science</subject>
      </subj-group>
      <book-title-group>
         <book-title>Una aproximación práctica a las redes neuronales artificiales</book-title>
      </book-title-group>
      <contrib-group>
         <contrib contrib-type="author" id="contrib1">
            <name name-style="western">
               <surname>Bravo</surname>
               <given-names>Francisco Caicedo</given-names>
            </name>
         </contrib>
         <contrib contrib-type="author" id="contrib2">
            <name name-style="western">
               <surname>Sotelo</surname>
               <given-names>Jesús Alfonso López</given-names>
            </name>
         </contrib>
      </contrib-group>
      <pub-date>
         <day>09</day>
         <month>12</month>
         <year>2009</year>
      </pub-date>
      <isbn content-type="ppub">9789586707671</isbn>
      <isbn content-type="epub">9789587655100</isbn>
      <publisher>
         <publisher-name>Programa Editorial Universidad del Valle</publisher-name>
         <publisher-loc>Cali, Colombia</publisher-loc>
      </publisher>
      <edition>1</edition>
      <permissions>
         <copyright-year>2009</copyright-year>
         <copyright-holder>Universidad del valle</copyright-holder>
         <copyright-holder>Eduardo Francisco Caicedo Bravo</copyright-holder>
         <copyright-holder>Jesús Alfonso López Sotelo</copyright-holder>
      </permissions>
      <self-uri xlink:href="https://www.jstor.org/stable/j.ctv1228hwf"/>
      <abstract abstract-type="short">
         <p>El propósito general de este libro es ser una guía para que el lector interesado en trabajar con redes neuronales artificiales (RNA), esté en capacidad de solucionar problemas propios de su disciplina usando esta técnica de la inteligencia computacional. La estructura del libro se concibe desde los tipos de aprendizaje, ya que es la característica más importante que poseen las redes neuronales artificiales y en ella radica su principal fortaleza para solucionar y adaptarse a diversos problemas. En este libro se encuentran contenidos teóricos básicos que lo dejarán preparado para afrontar el estudio de libros y artículos de carácter avanzado, acompañado de problemas resueltos que afianzan el saber y el saber hacer.</p>
      </abstract>
      <counts>
         <page-count count="218"/>
      </counts>
      <custom-meta-group>
         <custom-meta>
            <meta-name>
                    lang
                </meta-name>
            <meta-value>spa</meta-value>
         </custom-meta>
      </custom-meta-group>
   </book-meta>
   <body>
      <book-part book-part-type="book-toc-page-order" indexed="yes">
         <body>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctv1228hwf.1</book-part-id>
                  <title-group>
                     <title>Front Matter</title>
                  </title-group>
                  <fpage>1</fpage>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctv1228hwf.2</book-part-id>
                  <title-group>
                     <title>Table of Contents</title>
                  </title-group>
                  <fpage>5</fpage>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctv1228hwf.3</book-part-id>
                  <title-group>
                     <title>INTRODUCCIÓN</title>
                  </title-group>
                  <fpage>9</fpage>
                  <abstract>
                     <p>El propósito general de este libro es ser una guía para que el lector interesado en trabajar con Redes Neuronales Artificiales (RNA), esté en capacidad de solucionar problemas propios de su disciplina usando esta técnica de la Inteligencia Computacional. Es imposible que un único libro cubra todos los posibles tipos de redes neuronales que existen en la literatura, por esta razón, llevaremos a cabo una revisión de las principales arquitecturas de red y de sus características generales con el fin de que el lector quede en capacidad de comprender y utilizar no solo las redes que vamos a presentar, sino</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctv1228hwf.4</book-part-id>
                  <title-group>
                     <label>Capítulo 1</label>
                     <title>GENERALIDADES SOBRE REDES NEURONALES ARTIFICIALES</title>
                  </title-group>
                  <fpage>13</fpage>
                  <abstract>
                     <p>Muchos de los desarrollos del hombre se deben a su capacidad para explicar y emular funciones que son realizadas por seres vivos, por ejemplo, se puede citar el radar, el cual surge como una emulación de la forma como un murciélago es capaz de detectar los objetos que están en su camino, sin necesidad de verlos, gracias a la emisión de una onda ultrasónica, su posterior recepción de la señal de eco y procesamiento, con el fin de detectar obstáculos en su vuelo con una rapidez y precisión sorprendentes. Como el mencionado, existen muchos ejemplos más en la naturaleza que</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctv1228hwf.5</book-part-id>
                  <title-group>
                     <label>Capítulo 2</label>
                     <title>REDES NEURONALES PERCEPTRON Y ADALINE</title>
                  </title-group>
                  <fpage>37</fpage>
                  <abstract>
                     <p>El Perceptron fue el primer modelo de RNA presentado a la comunidad científica por el psicólogo Frank Rosenblatt en 1958. Como es natural despertó un enorme interés en la década de los años sesenta, debido a su capacidad para aprender a reconocer patrones sencillos con una superficie de separación li-neal, razón por la cual fue también objeto de severas críticas que terminaron por dejar en el olvido la propuesta de Rosenblatt. La estructura del Perceptron es supremamente sencilla: en su entrada posee varias neuronas lineales que se encargan de recibir el estímulo externo de la red y a la salida</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctv1228hwf.6</book-part-id>
                  <title-group>
                     <label>Capítulo 3</label>
                     <title>PERCEPTRON MULTICAPA Y ALGORITMO BACKPROPAGATION</title>
                  </title-group>
                  <fpage>75</fpage>
                  <abstract>
                     <p>Debido a la imposibilidad de solucionar problemas de clasificación no lineales que presenta el Perceptron propuesto por Rosenblatt, y redes algo más evolucionadas como el Adaline, el interés inicial que las redes neuronales artificiales habían despertado, decayó fuertemente y sólo quedaron unos pocos investigadores trabajando en el desarrollo de arquitecturas y algoritmos de aprendizaje capaces de solucionar problemas de alta comple jidad. Esta situación fue ampliamente divulgada por Misky y Papert en su libro <italic>Perceptrons</italic>; lo que significó prácticamente el olvido científico de la propuesta de Rosenblatt.</p>
                     <p>Ronsenblatt, sin embargo, ya intuía la manera de solucionarlo, el autor del Perceptron,</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctv1228hwf.7</book-part-id>
                  <title-group>
                     <label>Capítulo 4</label>
                     <title>RED NEURONAL DE HOPFIELD</title>
                  </title-group>
                  <fpage>137</fpage>
                  <abstract>
                     <p>En este capítulo veremos un tipo de red neuronal dinámica, considerada así porque en esencia corresponde a un sistema cuyos estados dependen de la variable tiempo. Iniciaremos con una breve revisión a las memorias asociativas bidireccionales con el fin de dejar las bases necesarias para comprender el modelo de red dinámica propuesto, en 1982, por Hopfield. Abordaremos los modelos discretos y continuos propuestos por Hopfield, iniciando con la arquitectura de este tipo de red, continuaremos con el procesamiento de los datos y los respectivos algoritmos de aprendizaje.</p>
                     <p>Al final, mostraremos algunas aplicaciones en optimización de sistemas y reconocimiento y clasificación</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctv1228hwf.8</book-part-id>
                  <title-group>
                     <label>Capítulo 5</label>
                     <title>MAPAS AUTO-ORGANIZADOS DE KOHONEN</title>
                  </title-group>
                  <fpage>157</fpage>
                  <abstract>
                     <p>Los Mapas Auto-organizados (SOM por su nombre en inglés Self-Organizing Maps) fueron presentados por Teuvo Kohonen en 1982, por lo que también reciben el nombre de Mapas Auto-organizados de Kohonen o Redes Neuronales de Kohonen, estos mapas están inspirados en la capacidad del cerebro humano de reconocer y extraer rasgos y características relevantes del mundo que los rodea. En la década de los ochenta, el profesor Kohonen propuso una red neuronal artificial capaz de aprender la estructura topológica de un conjunto de datos a través de un proceso de autoorga nización de las neuronas de la red.</p>
                     <p>Desde el punto</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctv1228hwf.9</book-part-id>
                  <title-group>
                     <label>Capítulo 6</label>
                     <title>RED DE BASE RADIAL (RBF)</title>
                  </title-group>
                  <fpage>187</fpage>
                  <abstract>
                     <p>En este capítulo nos vamos a enfrentar a un nuevo tipo de redes neuronales que fueron introducidas en 1985. Desde el punto de vista de su arquitectura es una red multicapa unidireccional con aprendizaje híbrido, pues en la capa oculta se sigue un algoritmo No-Supervisado y en la de salida el aprendizaje es Supervisado.</p>
                     <p>Debido a su simplicidad y velocidad en el proceso de aprendizaje, y el alto grado de generalización, esta red ha sido utilizada en diversas aplicaciones prácticas, sobre todo en reconocimiento y clasificación de patrones. Otro campo de aplicación que ha presentado resultados promisorios es la identificación</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctv1228hwf.10</book-part-id>
                  <title-group>
                     <title>BIBLIOGRAFÍA</title>
                  </title-group>
                  <fpage>213</fpage>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctv1228hwf.11</book-part-id>
                  <title-group>
                     <title>Back Matter</title>
                  </title-group>
                  <fpage>218</fpage>
               </book-part-meta>
            </book-part>
         </body>
      </book-part>
   </body>
</book>
