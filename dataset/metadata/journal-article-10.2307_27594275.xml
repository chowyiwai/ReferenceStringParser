<?xml version="1.0" encoding="UTF-8"?>


<article dtd-version="1.0" article-type="research-article">
  <front>
      <journal-meta>
         <journal-id xmlns:xlink="http://www.w3.org/1999/xlink" journal-id-type="jstor">jcompgrapstat</journal-id>
         <journal-id xmlns:xlink="http://www.w3.org/1999/xlink" journal-id-type="jstor">j100879</journal-id>
         <journal-title-group xmlns:xlink="http://www.w3.org/1999/xlink">
            <journal-title>Journal of Computational and Graphical Statistics</journal-title>
         </journal-title-group>
      
         <publisher>
            <publisher-name>American Statistical Association, Institute of Mathematical Statistics, and Interface Foundation of North America</publisher-name>
         </publisher>
         <issn xmlns:xlink="http://www.w3.org/1999/xlink" pub-type="ppub">10618600</issn>
         <custom-meta-group xmlns:xlink="http://www.w3.org/1999/xlink"/>
      </journal-meta>
      <article-meta xmlns:xlink="http://www.w3.org/1999/xlink">
         <volume xmlns:mml="http://www.w3.org/1998/Math/MathML"
                 xmlns:oasis="http://docs.oasis-open.org/ns/oasis-exchange/table">16</volume>
         <issue xmlns:mml="http://www.w3.org/1998/Math/MathML"
                xmlns:oasis="http://docs.oasis-open.org/ns/oasis-exchange/table">4</issue>
         <issue-id>i27594271</issue-id>
         <article-id pub-id-type="jstor">27594275</article-id>
         <article-id pub-id-type="pub-doi">10.1198/106186007X255676</article-id>
         <title-group>
            <article-title>Variable Selection via a Combination of the L0 and L1 Penalties</article-title>
         </title-group>
         <contrib-group>
            <contrib>
               <string-name>
                  <given-names>Yufeng</given-names>
                  <surname>Liu</surname>
               </string-name>
            </contrib>
            <contrib>
               <string-name>
                  <given-names>Yichao</given-names>
                  <surname>Wu</surname>
               </string-name>
            </contrib>
         </contrib-group>
         <pub-date pub-type="ppub">
            <day>1</day>
            <month>12</month>
            <year>2007</year>
         </pub-date>
         <fpage>782</fpage>
         <lpage>798</lpage>
      
         <permissions>
            <copyright-statement>Copyright 2007 American Statistical Association, the Institute of Mathematical Statistics, and the Interface Foundation of North America</copyright-statement>
         </permissions>
      
         <self-uri xlink:href="https://www.jstor.org/stable/27594275"/>
      
      
         <abstract>
            <p>Variable selection is an important aspect of high-dimensional statistical modeling, particularly in regression and classification. In the regularization framework, various penalty functions are used to perform variable selection by putting relatively large penalties on small coefficients. The L1 penalty is a popular choice because of its convexity, but it produces biased estimates for the large coefficients. The L0 penalty is attractive for variable selection because it directly penalizes the number of nonzero coefficients. However, the optimization involved is discontinuous and nonconvex, and therefore it is very challenging to implement. Moreover, its solution may not be stable. In this article, we propose a new penalty that combines the L0 and L1 penalties. We implement this new penalty by developing a global optimization algorithm using mixed integer programming (MIP). We compare this combined penalty with several other penalties via simulated examples as well as real applications. The results show that the new penalty outperforms both the L0 and L1 penalties in terms of variable selection while maintaining good prediction accuracy.</p>
         </abstract>
         <kwd-group>
            <kwd>Mixed integer programming</kwd>
            <kwd>Regression</kwd>
            <kwd>Regularization</kwd>
            <kwd>SVM</kwd>
            <kwd>Variable selection</kwd>
         </kwd-group>
         <custom-meta-group>
            <custom-meta>
               <meta-name>lang</meta-name>
               <meta-value>eng</meta-value>
            </custom-meta>
         </custom-meta-group>
      </article-meta>
  </front>
  <back>
    
      <ref-list>
        <title>References</title>
        <ref id="d201216e161a1310">
          
            <mixed-citation id="d201216e165" publication-type="other">
Boyd, S., and Vandenberghe, L. (2004), Convex Optimization, New York: Cambridge University Press.</mixed-citation>
        </ref>
        <ref id="d201216e172a1310">
          
            <mixed-citation id="d201216e176" publication-type="other">
Bradley, P., and Mangasarian, O. (1998), "Feature Selection via Concave Minimization and Support Vector Ma-
chines," in ICML '98, ed. J. Shavlik, San Francisco: Morgan Kaufmann.</mixed-citation>
        </ref>
        <ref id="d201216e186a1310">
          
            <mixed-citation id="d201216e190" publication-type="other">
Cristianini, N., and Shawe-Taylor, J. (1999), "An Introduction to Support Vector Machines and Other Kernel-
Based Learning Methods," New York: Cambridge University Press.</mixed-citation>
        </ref>
        <ref id="d201216e200a1310">
          
            <mixed-citation id="d201216e204" publication-type="other">
Donoho, D. L., and Johnstone, I. (1994), "Ideal Spatial Adaptation by Wavelet Shrinkage," Biometrika, 81, 425–
455.</mixed-citation>
        </ref>
        <ref id="d201216e215a1310">
          
            <mixed-citation id="d201216e219" publication-type="other">
Donoho, D. L., Johnstone, I. M., Kerkyacharian, G., and Picard, D. (1995), "Wavelet Shrinkage; Asymptopia?"
Journal of the Royal Statistical Society, Ser. B, 35, 109–148.</mixed-citation>
        </ref>
        <ref id="d201216e229a1310">
          
            <mixed-citation id="d201216e233" publication-type="other">
Fan, J., and Li, R. (2001), "Variable Selection via Nonconcave Penalized Likelihood and its Oracle Properties,"
Journal of the American Statistical Association, 96, 1348-1360.</mixed-citation>
        </ref>
        <ref id="d201216e243a1310">
          
            <mixed-citation id="d201216e247" publication-type="other">
Frank, I. E., and Friedman, J. H. (1993), "A Statistical View of Some Chemometrics Regression Tools," Techno-
metrics, 35, 109–135.</mixed-citation>
        </ref>
        <ref id="d201216e257a1310">
          
            <mixed-citation id="d201216e261" publication-type="other">
Fourer, R., Gay, D.M., and Kernighan, B.W. (2003), AMPL: A Modeling Language for Mathematical Program-
ming, Belmont, CA: Duxbury Press.</mixed-citation>
        </ref>
        <ref id="d201216e271a1310">
          
            <mixed-citation id="d201216e275" publication-type="other">
Garfinkel, R. S., and Nemhauser, G. L. (1972), Integer Programming, New York: Wiley.</mixed-citation>
        </ref>
        <ref id="d201216e282a1310">
          
            <mixed-citation id="d201216e286" publication-type="other">
Hoerl, A. E., and Kennard, R. W. (1970), "Ridge Regression: Biased Estimation for Nonorthogonal Problems,"
Technometrics, 12, 55–67.</mixed-citation>
        </ref>
        <ref id="d201216e297a1310">
          
            <mixed-citation id="d201216e301" publication-type="other">
Kim, J., and Pollard, D. (1990), "Cube Root Asymptotics," The Annals of Statistics, 18, 191-219.</mixed-citation>
        </ref>
        <ref id="d201216e308a1310">
          
            <mixed-citation id="d201216e312" publication-type="other">
Knight, K., and Fu, W. J. (2000), "Asymptotics for Lasso-Type Estimators," The Annals of Statistics, 28, 1356–
1378.</mixed-citation>
        </ref>
        <ref id="d201216e322a1310">
          
            <mixed-citation id="d201216e326" publication-type="other">
Liu, Y., Shen, X., and Doss, H. (2005), "Multicategory Ψ-Learning and Support Vector Machine: Computational
Tools," Journal of Computational and Graphical Statistics, 14, 219–236.</mixed-citation>
        </ref>
        <ref id="d201216e336a1310">
          
            <mixed-citation id="d201216e340" publication-type="other">
Liu, Y., and Wu, Y. (2006), "Optimizing Ψ-Learning via Mixed Integer Programming," Statistica Sinica, 16, 2,
441–457.</mixed-citation>
        </ref>
        <ref id="d201216e350a1310">
          
            <mixed-citation id="d201216e354" publication-type="other">
Nemhauser, G.L., and Wolsey, L.A. (1999), Integer and Combinatorial Optimization, New York: Wiley.</mixed-citation>
        </ref>
        <ref id="d201216e361a1310">
          
            <mixed-citation id="d201216e365" publication-type="other">
Sigillito, V. G., Wing, S. P., Hutton, L. V., and Baker, K. B. (1989), "Classification of Radar Returns from the
Ionosphere Using Neural Networks," Johns Hopkins APL Technical Digest, 10, 262–266.</mixed-citation>
        </ref>
        <ref id="d201216e376a1310">
          
            <mixed-citation id="d201216e380" publication-type="other">
Tibshirani, R. J. (1996), "Regression Shrinkage and Selection via the Lasso," Journal of the Royal Statistical
Society, Ser. B, 58, 267–288.</mixed-citation>
        </ref>
        <ref id="d201216e390a1310">
          
            <mixed-citation id="d201216e394" publication-type="other">
Vapnik, V. (1998), Statistical Learning Theory, New York: Wiley.</mixed-citation>
        </ref>
        <ref id="d201216e401a1310">
          
            <mixed-citation id="d201216e405" publication-type="other">
Zhu, J., Hastie, T., Rosset, S., and Tibshirani, R. (2003), "1-norm Support Vector Machines," Neural Information
Processing Systems, 16.</mixed-citation>
        </ref>
      </ref-list>
    
  </back>
</article>


