<?xml version="1.0" encoding="UTF-8"?>


<article dtd-version="1.0" article-type="research-article">
  <front>
      <journal-meta>
         <journal-id xmlns:xlink="http://www.w3.org/1999/xlink" journal-id-type="jstor">revifinastud</journal-id>
         <journal-id xmlns:xlink="http://www.w3.org/1999/xlink" journal-id-type="jstor">j100802</journal-id>
         <journal-title-group xmlns:xlink="http://www.w3.org/1999/xlink">
            <journal-title>The Review of Financial Studies</journal-title>
         </journal-title-group>
      
         <publisher>
            <publisher-name>Oxford University Press</publisher-name>
         </publisher>
         <issn xmlns:xlink="http://www.w3.org/1999/xlink" pub-type="ppub">08939454</issn>
         <issn xmlns:xlink="http://www.w3.org/1999/xlink" pub-type="epub">14657368</issn>
         <custom-meta-group xmlns:xlink="http://www.w3.org/1999/xlink"/>
      </journal-meta>
      <article-meta xmlns:xlink="http://www.w3.org/1999/xlink">
         <volume xmlns:mml="http://www.w3.org/1998/Math/MathML"
                 xmlns:oasis="http://docs.oasis-open.org/ns/oasis-exchange/table">28</volume>
         <issue xmlns:mml="http://www.w3.org/1998/Math/MathML"
                xmlns:oasis="http://docs.oasis-open.org/ns/oasis-exchange/table">7</issue>
         <issue-id>i24466894</issue-id>
         <article-id pub-id-type="jstor">24466897</article-id>
         <title-group>
            <article-title>Learning About Unstable, Publicly Unobservable Payoffs</article-title>
         </title-group>
         <contrib-group>
            <contrib>
               <string-name>
                  <given-names>Elise</given-names>
                  <surname>Payzan-LeNestour</surname>
               </string-name>
            </contrib>
            <contrib>
               <string-name>
                  <given-names>Peter</given-names>
                  <surname>Bossaerts</surname>
               </string-name>
            </contrib>
         </contrib-group>
         <pub-date pub-type="ppub">
            <day>1</day>
            <month>7</month>
            <year>2015</year>
         </pub-date>
         <fpage>1874</fpage>
         <lpage>1913</lpage>
      
      
      
      
      
      
      
      
      
         <permissions>
            <copyright-statement>Copyright © 2015 The Society for Financial Studies</copyright-statement>
         </permissions>
         <self-uri xlink:href="https://www.jstor.org/stable/24466897"/>
      
      
         <abstract>
            <p>Neoclassical finance assumes that investors are Bayesian. In many realistic situations, Bayesian learning is challenging. Here, we consider investment opportunities that change randomly, while payoffs are observable only when invested. In a stylized version of the task, we wondered whether performance would be affected if one were to follow reinforcement learning principles instead. The answer is a definite yes. When asked to perform our task, participants overwhelmingly learned in a Bayesian way. They stopped being Bayesians, though, when not nudged into paying attention to contingency shifts. This raises an issue for financial markets: who has the incentive to nudge investors?</p>
         </abstract>
         <custom-meta-group>
            <custom-meta>
               <meta-name>lang</meta-name>
               <meta-value>eng</meta-value>
            </custom-meta>
         </custom-meta-group>
      </article-meta>
  </front>
  <back>
    
      <fn-group xmlns:xlink="http://www.w3.org/1999/xlink">
        <title>[Footnotes]</title>
        <fn id="d1305517e208a1310">
            <label>1</label>
          
            <p>
               <mixed-citation id="d1305517e215" publication-type="other">
Such instability is thought to be at the origin of fat tails in return distributions; e.g., Mandelbrot (1957) and
Gabaix et al. (2003).</mixed-citation>
            </p>
        </fn>
        <fn id="d1305517e225a1310">
            <label>2</label>
          
            <p>
               <mixed-citation id="d1305517e232" publication-type="other">
One could conjecture that choice in the standard bandit is the same as in the restless bandit because subjects do
not believe that contingencies will never change and, hence, perceive that bandit as possibly restless.</mixed-citation>
            </p>
        </fn>
        <fn id="d1305517e242a1310">
            <label>3</label>
          
            <p>
               <mixed-citation id="d1305517e249" publication-type="other">
When investors only observe relevant information at the moment they decide to invest, information cascades
may ensue. This occurs when the information investors receive concerns the moves of others (whether others
invested). See Chari and Kehoe (2004). In our setting, all information will be produced exogenously; the agent's
decision only concerns whether to collect the (exogenous) information through investing.</mixed-citation>
            </p>
        </fn>
        <fn id="d1305517e265a1310">
            <label>4</label>
          
            <p>
               <mixed-citation id="d1305517e272" publication-type="other">
E.g., Simon (1955,1987), Kahneman (1973), Huberman and Regev (2001), Hirshleifer et al. (2009), DeliaVigna
and Pollet (2009), and Gao et al. (2011).</mixed-citation>
            </p>
        </fn>
        <fn id="d1305517e283a1310">
            <label>5</label>
          
            <p>
               <mixed-citation id="d1305517e290" publication-type="other">
See The Official Journal of the European Union, Commission Regulation (EU) No 583/2010 of 1 July 2010,
Paragraph 12 (p.2), Paragraph 16 (p.3), and last but not least, Section 5, p. 12.</mixed-citation>
            </p>
        </fn>
        <fn id="d1305517e300a1310">
            <label>6</label>
          
            <p>
               <mixed-citation id="d1305517e307" publication-type="other">
See, e.g., OCC Bulletin 97-24, May 20, 1997.</mixed-citation>
            </p>
        </fn>
        <fn id="d1305517e314a1310">
            <label>7</label>
          
            <p>
               <mixed-citation id="d1305517e321" publication-type="other">
The entropy of a location measures how much its outcome probabilities differ; it is highest when all three outcome
probabilities are equal, in which case the location is completely unpredictable or "random."</mixed-citation>
            </p>
        </fn>
        <fn id="d1305517e331a1310">
            <label>8</label>
          
            <p>
               <mixed-citation id="d1305517e338" publication-type="other">
We did not use the term "skewed" in the instructions (available in Appendix A.5); we said "biased" instead. We
avoided any technical term, so the task was arguably accessible to subjects without scientific background. We
also wanted to avoid framing effects.</mixed-citation>
            </p>
        </fn>
        <fn id="d1305517e351a1310">
            <label>9</label>
          
            <p>
               <mixed-citation id="d1305517e358" publication-type="other">
In this paper, by "model" we mean a learning algorithm (either Bayesian or reinforcement learning) along with
a decision rule, which is always the logit rule unless stated otherwise below.</mixed-citation>
            </p>
        </fn>
        <fn id="d1305517e368a1310">
            <label>10</label>
          
            <p>
               <mixed-citation id="d1305517e375" publication-type="other">
The expressions in quotation marks are taken from subjects' own reports on their play during the experiment.</mixed-citation>
            </p>
        </fn>
        <fn id="d1305517e383a1310">
            <label>11</label>
          
            <p>
               <mixed-citation id="d1305517e390" publication-type="other">
Specifically, a key feature of Bayesian learning in a restless bandit task is that it involves the combined perception
of three kinds of uncertainty: estimation uncertainty or ambiguity (uncertainty regarding the true values of the
payoff probabilities), standard risk (uncertainty left even if the decision maker knows the payoff probabilities),
and jump risk (the chance that a jump has occurred, which the agent assesses at each trial). To investigate where
and how these three levels of uncertainty are encoded in the human brain, one needs to obtain independent
variation of the three levels, and for this six arms are needed.</mixed-citation>
            </p>
        </fn>
        <fn id="d1305517e413a1310">
            <label>12</label>
          
            <p>
               <mixed-citation id="d1305517e420" publication-type="other">
Specifically, the logit rule maximizes the expected utility from one's actions subject to a constraint on the entropy
of the choice rule:
£ß(/,r-1) P7T(l,T)--J2pn(l&gt;T) lnPn(l,T).
Intuitively, if there is a clear winner in the choice among locations, low entropy is allowed for, which means that
the decision maker can choose the optimal location with high probability. Conversely, if all locations are estimated
to be equally valuable, the policy has to exhibit high entropy—which means all locations will be visited with
approximately equal probability. The inverse of the parameter ß captures the importance of acquiring information.</mixed-citation>
            </p>
        </fn>
        <fn id="d1305517e446a1310">
            <label>13</label>
          
            <p>
               <mixed-citation id="d1305517e453" publication-type="other">
This is the Jeffreys prior, which is commonly used in Bayesian statistics. We tried different values for vq, and
the results of the horse race between the Bayesian and reinforcement learning models were always the same (see
Section 3). So this particular specification of the prior is not pivotal for our purpose in this study. Note that we
refrained from fitting vq to the data to minimize the number of free parameters in the estimation procedure.</mixed-citation>
            </p>
        </fn>
        <fn id="d1305517e469a1310">
            <label>14</label>
          
            <p>
               <mixed-citation id="d1305517e476" publication-type="other">
Mathematical details on the augmented FB model, along with the results of the optimization procedure and
Monte Carlo simulations when using it, are available on request.</mixed-citation>
            </p>
        </fn>
        <fn id="d1305517e486a1310">
            <label>15</label>
          
            <p>
               <mixed-citation id="d1305517e493" publication-type="other">
In particular, we used different choices for the intervals of the uniform distribution, and we also replaced the
uniform distribution with different functional forms for the prior. In each case the results reported in Section 3
were unchanged.</mixed-citation>
            </p>
        </fn>
        <fn id="d1305517e506a1310">
            <label>16</label>
          
            <p>
               <mixed-citation id="d1305517e513" publication-type="other">
For instance, Brosnan (2008) documents that capuchin monkeys choose tools after inferring their functional
characteristics, rather than merely remembering past success and failure with the tools. Inferring the hidden
functional characteristics of tools is akin to inferring the hidden outcome probabilities of options in the current
task.</mixed-citation>
            </p>
        </fn>
        <fn id="d1305517e530a1310">
            <label>17</label>
          
            <p>
               <mixed-citation id="d1305517e537" publication-type="other">
In all the simulations reported in this paper, we set the values of the free parameters entering the behavioral
models equal to the mean maximum-likelihood estimates from the estimation procedure reported in Section 3.</mixed-citation>
            </p>
        </fn>
        <fn id="d1305517e547a1310">
            <label>18</label>
          
            <p>
               <mixed-citation id="d1305517e554" publication-type="other">
The results obtained with the other models are available on request. The worst model did markedly better than
random choice—according to a pseudo-/?2.</mixed-citation>
            </p>
        </fn>
        <fn id="d1305517e564a1310">
            <label>19</label>
          
            <p>
               <mixed-citation id="d1305517e571" publication-type="other">
Subject answers are available on request in a hard-copy format.</mixed-citation>
            </p>
        </fn>
        <fn id="d1305517e578a1310">
            <label>20</label>
          
            <p>
               <mixed-citation id="d1305517e585" publication-type="other">
Johnson et al. (2002) make similar conjecture to explain that their subjects did not use backward induction in a
simple three-round bargaining game. They argue that backward induction was "useless" in primitive environments
(inasmuch as games in the real world do not have a definite terminal point).</mixed-citation>
            </p>
        </fn>
        <fn id="d1305517e598a1310">
            <label>21</label>
          
            <p>
               <mixed-citation id="d1305517e605" publication-type="other">
Importantly, the subjects in those sessions were motivated to do well inasmuch as they performed the task for
course credit. So absence of monetary incentives was not merely a proxy for lack of motivation or random choice.</mixed-citation>
            </p>
        </fn>
        <fn id="d1305517e615a1310">
            <label>22</label>
          
            <p>
               <mixed-citation id="d1305517e622" publication-type="other">
The prevalence of Bayesian learning in one treatment, and of reinforcement learning in the other, cannot simply
be attributed to a framing effect. The instructions were exactly the same in the original and follow-up treatments,
except the latter did not explicitly mention that the outcome probabilities would jump.</mixed-citation>
            </p>
        </fn>
        <fn id="d1305517e636a1310">
            <label>23</label>
          
            <p>
               <mixed-citation id="d1305517e643" publication-type="other">
See Basel Committee on Banking Supervision—Revisions to the Basel II market risk framework, February 2011,
available at www.bis.org.</mixed-citation>
            </p>
        </fn>
      </fn-group>
    
    
      <ref-list>
        <title>References</title>
        <ref id="d1305517e662a1310">
          
            <mixed-citation id="d1305517e666" publication-type="other">
Ang, A., and A. G Timmermann. 2011. Regime changes and financial markets. Netspar Discussion Paper No.
06/2011-068.</mixed-citation>
        </ref>
        <ref id="d1305517e676a1310">
          
            <mixed-citation id="d1305517e680" publication-type="other">
Aoki, M. 1987. State space modeling of time series. Berlin: Springer-Verlag.</mixed-citation>
        </ref>
        <ref id="d1305517e687a1310">
          
            <mixed-citation id="d1305517e691" publication-type="other">
Behrens, T. E. J., M. W. Woolrich, M. E. Walton, and M. F. S. Rushworth. 2007. Learning the value of information
in an uncertain world. Nature Neuroscience 10:1214—21.</mixed-citation>
        </ref>
        <ref id="d1305517e701a1310">
          
            <mixed-citation id="d1305517e705" publication-type="other">
Berger, J. O. 1980. Statistical decision theory and Bayesian analysis. New York: Springer.</mixed-citation>
        </ref>
        <ref id="d1305517e713a1310">
          
            <mixed-citation id="d1305517e717" publication-type="other">
Berger, J. O., and T. Sellke. 1987. Testing a point null hypothesis: the irreconciliability of p values and evidence.
Journal of the American Statistical Association 82:112-22.</mixed-citation>
        </ref>
        <ref id="d1305517e727a1310">
          
            <mixed-citation id="d1305517e731" publication-type="other">
Berk, J., and E. N. Hughson. 2009. Can boundedly rational agents make optimal decisions? A natural experiment.
Robert Day School of Economics and Finance Research Paper No. 2008-7.</mixed-citation>
        </ref>
        <ref id="d1305517e741a1310">
          
            <mixed-citation id="d1305517e745" publication-type="other">
Bernheim, D. 1995. Do households appreciate their financial vulnerabilities? An analysis of actions, perceptions,
and public policy. In Tax policy and economic growth: Proceedings of a symposium sponsored by the American
Council for Capital Formation, Center for Policy Research (pp. 1-30). Washington, DC: Center for Policy
Research.</mixed-citation>
        </ref>
        <ref id="d1305517e761a1310">
          
            <mixed-citation id="d1305517e765" publication-type="other">
Brennan, T. J., and A. W. Lo. 2011. The origin of behavior. Quarterly Journal of Finance 1:55-108.</mixed-citation>
        </ref>
        <ref id="d1305517e772a1310">
          
            <mixed-citation id="d1305517e776" publication-type="other">
Brosnan, S. F. 2008. Animal behavior: The right tool for the job. Current Biology 19:R124—25.</mixed-citation>
        </ref>
        <ref id="d1305517e783a1310">
          
            <mixed-citation id="d1305517e787" publication-type="other">
Brunnermeier, M. K., and M. Oehmke. 2009. Complexity in financial markets. Princeton University.</mixed-citation>
        </ref>
        <ref id="d1305517e795a1310">
          
            <mixed-citation id="d1305517e799" publication-type="other">
Camerer, C. F., andT.-H. Ho. 1999. Experience-weighted attraction learning in normal form games. Econometrica
67:827-74.</mixed-citation>
        </ref>
        <ref id="d1305517e809a1310">
          
            <mixed-citation id="d1305517e813" publication-type="other">
Carlin, B. I. 2009. Strategic price complexity in retail financial markets. Journal of Financial Economics
91:278-87.</mixed-citation>
        </ref>
        <ref id="d1305517e823a1310">
          
            <mixed-citation id="d1305517e827" publication-type="other">
Carlin, B. I., S. Kogan, and R. Lowery. 2013. Trading complex assets. Journal of Finance 68:1937-60.</mixed-citation>
        </ref>
        <ref id="d1305517e834a1310">
          
            <mixed-citation id="d1305517e838" publication-type="other">
Carlin, B. I., and G Manso. 2011. Obfuscation, learning, and the evolution of investor sophistication. Review of
Financial Studies 24:754—85.</mixed-citation>
        </ref>
        <ref id="d1305517e848a1310">
          
            <mixed-citation id="d1305517e852" publication-type="other">
Chari, V. V., and P. J. Kehoe. 2004. Financial crisis as herds: Overturning the critiques. Journal of Economic
Theory 119:128-50.</mixed-citation>
        </ref>
        <ref id="d1305517e862a1310">
          
            <mixed-citation id="d1305517e866" publication-type="other">
Charness, G, E. Kami, and D. Levin. 2010. On the conjunction fallacy in probability judgment: New experimental
evidence regarding Linda. Games and Economic Behavior 68:551-56.</mixed-citation>
        </ref>
        <ref id="d1305517e877a1310">
          
            <mixed-citation id="d1305517e881" publication-type="other">
Charness, G, and D. Levin. 2005. When optimal choices feel wrong: A laboratory study of Bayesian updating,
complexity and affect. American Economic Review 95:1300-09.</mixed-citation>
        </ref>
        <ref id="d1305517e891a1310">
          
            <mixed-citation id="d1305517e895" publication-type="other">
Courville, A. C., N. D. Daw, and D. S. Touretzky. 2006. Bayesian theories of conditioning in a changing world.
Trends in Cognitive Sciences 10:294—300.</mixed-citation>
        </ref>
        <ref id="d1305517e905a1310">
          
            <mixed-citation id="d1305517e909" publication-type="other">
Daw, N. D., Y. Niv, and P. Dayan. 2005. Uncertainty-based competition between prefrontal and dorsolateral
striatal systems for behavioral control. Nature Neuroscience 8:1704-11.</mixed-citation>
        </ref>
        <ref id="d1305517e919a1310">
          
            <mixed-citation id="d1305517e923" publication-type="other">
Daw, N. D., J. O'Doherty, P. Dayan, B. Seymour, and R. J. Dolan. 2006. Cortical substrates for exploratory
decisions in humans. Nature 441:876-79.</mixed-citation>
        </ref>
        <ref id="d1305517e933a1310">
          
            <mixed-citation id="d1305517e937" publication-type="other">
DeliaVigna, S., and J. M. Pollet. 2009. Investor inattention and Friday earnings announcements. Journal of
Finance 64:109-49.</mixed-citation>
        </ref>
        <ref id="d1305517e947a1310">
          
            <mixed-citation id="d1305517e951" publication-type="other">
Draper, D. 1995. Assessment and propagation of model uncertainty. Journal of the Royal Statistical Society.
Series B (Methodological) 57:45-97.</mixed-citation>
        </ref>
        <ref id="d1305517e962a1310">
          
            <mixed-citation id="d1305517e966" publication-type="other">
Erev, I., and A. E. Roth. 1998. Predicting how people play games: Reinforcement learning in experimental games
with unique, mixed strategy equilibria. American Economic Review 88:848-81.</mixed-citation>
        </ref>
        <ref id="d1305517e976a1310">
          
            <mixed-citation id="d1305517e980" publication-type="other">
Estes, W. K. 1984. Global and local control of choice behavior by cyclically varying outcome probabilities.
Journal of Experimental Psychology 10:258-70.</mixed-citation>
        </ref>
        <ref id="d1305517e990a1310">
          
            <mixed-citation id="d1305517e994" publication-type="other">
Evans, G W., and S. Honkapohja. 2001. Learning and expectations in macroeconomics. Princeton, NJ: Princeton
University Press.</mixed-citation>
        </ref>
        <ref id="d1305517e1004a1310">
          
            <mixed-citation id="d1305517e1008" publication-type="other">
Frydman, C., C. Camerer, P. Bossaerts, and A. Rangel. 2011. MAOA-L carriers are better at making optimal
financial decisions under risk. Proceedings of the Royal Society B 1714:2053-59.</mixed-citation>
        </ref>
        <ref id="d1305517e1018a1310">
          
            <mixed-citation id="d1305517e1022" publication-type="other">
Gabaix, X., P. Gopikrishnan, V. Plerou, and H. E. Stanley. 2003. A theory of power-law distributions in financial
market fluctuations. Nature 423:267-70.</mixed-citation>
        </ref>
        <ref id="d1305517e1032a1310">
          
            <mixed-citation id="d1305517e1036" publication-type="other">
Gabaix, X., D. Laibson, G Moloche, and S. Weinberg. 2006. Costly information acquisition: Experimental
analysis of a boundedly rational model. American Economic Review 96:1043-68.</mixed-citation>
        </ref>
        <ref id="d1305517e1047a1310">
          
            <mixed-citation id="d1305517e1051" publication-type="other">
Gans, N., G Knox, and R. Croson. 2007. Simple models of discrete choice and their performance in bandit
experiments. Manufacturing and Service Operations Management 9:383-408.</mixed-citation>
        </ref>
        <ref id="d1305517e1061a1310">
          
            <mixed-citation id="d1305517e1065" publication-type="other">
Gao, P., Z. Da, and J. Engelberg. 2011. In search of attention. Journal of Finance 66:1466-91.</mixed-citation>
        </ref>
        <ref id="d1305517e1072a1310">
          
            <mixed-citation id="d1305517e1076" publication-type="other">
Gigerenzer, G, and U. Hoffrage. 1995. How to improve Bayesian reasoning without instructions: Frequency
formats. Psychological Review 102:684-704.</mixed-citation>
        </ref>
        <ref id="d1305517e1086a1310">
          
            <mixed-citation id="d1305517e1090" publication-type="other">
Gigerenzer, G, and R. Selten (eds.). 2001. Bounded rationality: The adaptive toolbox. Cambridge, MA: MIT
Press.</mixed-citation>
        </ref>
        <ref id="d1305517e1100a1310">
          
            <mixed-citation id="d1305517e1104" publication-type="other">
Gittins, J., and D. M. Jones. 1974. Progress in statistics. Amsterdam: North-Holland.</mixed-citation>
        </ref>
        <ref id="d1305517e1111a1310">
          
            <mixed-citation id="d1305517e1115" publication-type="other">
Glascher, J., N. Daw, P. Dayan, and J. P. O'Doherty. 2010. States versus rewards: Dissociable
neural prediction error signals underlying model-based and model-free reinforcement learning. Neuron
66:585-95.</mixed-citation>
        </ref>
        <ref id="d1305517e1129a1310">
          
            <mixed-citation id="d1305517e1133" publication-type="other">
Grether, D. M. 1992. Testing Bayes rule as a descriptive model: The representativeness heuristic. Quarterly
Journal of Economics 95:537-57.</mixed-citation>
        </ref>
        <ref id="d1305517e1143a1310">
          
            <mixed-citation id="d1305517e1147" publication-type="other">
Griffiths, T. L., and J. B. Tenenbaum. 2006. Optimal predictions in everyday cognition. Psychological Science
17:767-73.</mixed-citation>
        </ref>
        <ref id="d1305517e1157a1310">
          
            <mixed-citation id="d1305517e1161" publication-type="other">
Hertwig, R., and A. Ortmann. 2001. Experimental practices in economics: A methodological challenge for
psychologists. Behavioral and Brain Sciences 24:383-451.</mixed-citation>
        </ref>
        <ref id="d1305517e1171a1310">
          
            <mixed-citation id="d1305517e1175" publication-type="other">
Hirshleifer, D., S. S. Lim, and S. H. Teoh. 2009. Driven to distraction: Extraneous events and underreaction to
earnings news. Journal of Finance 64:2289-325.</mixed-citation>
        </ref>
        <ref id="d1305517e1185a1310">
          
            <mixed-citation id="d1305517e1189" publication-type="other">
Huberman, G, and T. Rege v. 2001. Contagious speculation and a cure for cancer: A none vent that made stock
prices soar. Journal of Finance 56:387-96.</mixed-citation>
        </ref>
        <ref id="d1305517e1199a1310">
          
            <mixed-citation id="d1305517e1203" publication-type="other">
Ishii, S., W. Yoshida, and J. Yoshimoto. 2002. Control of exploitation-exploration meta-parameter in
reinforcement learning. Neural Networks 15:665-87.</mixed-citation>
        </ref>
        <ref id="d1305517e1214a1310">
          
            <mixed-citation id="d1305517e1218" publication-type="other">
Jeffreys, H. 1961. Theory of probability. Oxford: Oxford University Press.</mixed-citation>
        </ref>
        <ref id="d1305517e1225a1310">
          
            <mixed-citation id="d1305517e1229" publication-type="other">
Jepma, M., and S. Nieuwenhuis. 2011. Pupil diameter predicts changes in the exploration-exploitation trade-off:
Evidence for the adaptive gain theory. Journal of Cognitive Neuroscience 23:1587-96.</mixed-citation>
        </ref>
        <ref id="d1305517e1239a1310">
          
            <mixed-citation id="d1305517e1243" publication-type="other">
Johnson, E. J., C. Camerer, S. Sen, and T. Rymon. 2002. Detecting failures of backward induction: Monitoring
information search in sequential bargaining. Journal of Economic Theory 104:16-47.</mixed-citation>
        </ref>
        <ref id="d1305517e1253a1310">
          
            <mixed-citation id="d1305517e1257" publication-type="other">
Kable, J. W., and P. W. Glimcher. 2009. The neurobiology of decision: Consensus and controversy. Neuron
63:733-45.</mixed-citation>
        </ref>
        <ref id="d1305517e1267a1310">
          
            <mixed-citation id="d1305517e1271" publication-type="other">
Kacperczyk, M., and P. Damien. 2011. Asset allocation under distribution uncertainty. McCombs Research Paper
Series No. IROM-01-11.</mixed-citation>
        </ref>
        <ref id="d1305517e1281a1310">
          
            <mixed-citation id="d1305517e1285" publication-type="other">
Kahneman, D. 1973. Attention and effort. Englewood Cliffs, NJ: Prentice-Hall.</mixed-citation>
        </ref>
        <ref id="d1305517e1293a1310">
          
            <mixed-citation id="d1305517e1297" publication-type="other">
Kahneman, D., and A. Tversky. 1972. Subjective probability: A judgment of representativeness. Cognitive
Psychology 3:430-54.</mixed-citation>
        </ref>
        <ref id="d1305517e1307a1310">
          
            <mixed-citation id="d1305517e1311" publication-type="other">
Kluger, B.D., and S. B. Wyatt. 2004. Are judgment errors reflected in market prices and allocations? Experimental
evidence based on the Monty Hall problem. Journal of Finance 59:969-97.</mixed-citation>
        </ref>
        <ref id="d1305517e1321a1310">
          
            <mixed-citation id="d1305517e1325" publication-type="other">
Körding, K. P., and D. M. Wolpert. 2004. Bayesian integration in sensorimotor learning. Nature
427:244-47.</mixed-citation>
        </ref>
        <ref id="d1305517e1335a1310">
          
            <mixed-citation id="d1305517e1339" publication-type="other">
Kuhnen, C. M. Forthcoming. Asymmetric learning from financial information. Journal of Finance.</mixed-citation>
        </ref>
        <ref id="d1305517e1346a1310">
          
            <mixed-citation id="d1305517e1350" publication-type="other">
Kuhnen, C. M., and B. Knutson. 2005. The neural basis of financial risk taking. Neuron 47:763-70.</mixed-citation>
        </ref>
        <ref id="d1305517e1357a1310">
          
            <mixed-citation id="d1305517e1361" publication-type="other">
Kulhavy, R., and M. B. Zarrop. 1993. On a general concept of forgetting. International Journal of Control
58:905-24.</mixed-citation>
        </ref>
        <ref id="d1305517e1372a1310">
          
            <mixed-citation id="d1305517e1376" publication-type="other">
Lusardi, A., and O. S. Mitchell. 2007. Baby boomer retirement security: The role of planning, financial literacy,
and housing wealth. Journal of Monetary Economics 54:205-24.</mixed-citation>
        </ref>
        <ref id="d1305517e1386a1310">
          
            <mixed-citation id="d1305517e1390" publication-type="other">
Mandelbrot, B. B. 1957. Fractales, Hasard et Finance. Paris: Flammarion.</mixed-citation>
        </ref>
        <ref id="d1305517e1397a1310">
          
            <mixed-citation id="d1305517e1401" publication-type="other">
Newell, B. R. 2005. Re-visions of rationality. Trends in Cognitive Sciences 9:11-15.</mixed-citation>
        </ref>
        <ref id="d1305517e1408a1310">
          
            <mixed-citation id="d1305517e1412" publication-type="other">
O'Doherty, J. P., P. Dayan, J. Schultz, R. Deichmann, K. Friston, and R. J. Dolan. 2004. Dissociable roles of
ventral and dorsal striatum in instrumental conditioning. Science 304:452-54.</mixed-citation>
        </ref>
        <ref id="d1305517e1422a1310">
          
            <mixed-citation id="d1305517e1426" publication-type="other">
Orbân, G, J. Fiser, R. N. Aslin, and M. Lengyel. 2008. Bayesian learning of visual chunks by human observers.
Proceedings of the National Academy of Sciences of the United States of America 105:2745-50.</mixed-citation>
        </ref>
        <ref id="d1305517e1436a1310">
          
            <mixed-citation id="d1305517e1440" publication-type="other">
Parco, J. E., A. Rapoport, and W. E. Stein. 2002. Effects of financial incentives on the breakdown of mutual trust.
Psychological Science 13:292-97.</mixed-citation>
        </ref>
        <ref id="d1305517e1451a1310">
          
            <mixed-citation id="d1305517e1455" publication-type="other">
Pastor, L., and P. Veronesi. 2009. Learning in financial markets. National Bureau of Economic Research Working
Paper 14646.</mixed-citation>
        </ref>
        <ref id="d1305517e1465a1310">
          
            <mixed-citation id="d1305517e1469" publication-type="other">
Pearce, J. M., and G Hall. 1980. A model for pavlovian learning: Variations in the effectiveness of conditioned
but not of unconditioned stimuli. Psychological Review 87:532-52.</mixed-citation>
        </ref>
        <ref id="d1305517e1479a1310">
          
            <mixed-citation id="d1305517e1483" publication-type="other">
Pérignon, C., and B. Vallée. 2014. Political incentives and financial innovation: The strategic use of toxic loans
by local governments. HEC Paris Research Paper No. FIN-2013-1017.</mixed-citation>
        </ref>
        <ref id="d1305517e1493a1310">
          
            <mixed-citation id="d1305517e1497" publication-type="other">
Pouget, S. 2007. Adaptive traders and the design of financial markets. Journal of Finance 62:2835-63.</mixed-citation>
        </ref>
        <ref id="d1305517e1504a1310">
          
            <mixed-citation id="d1305517e1508" publication-type="other">
Prelec, D. 1998. The probability weighting function. Econometrica 66:497-527.</mixed-citation>
        </ref>
        <ref id="d1305517e1515a1310">
          
            <mixed-citation id="d1305517e1519" publication-type="other">
Quinn, A., and M. Karny. 2007. Learning for non-stationary Dirichlet processes. International Journal of Adaptive
Control and Signal Processing 21:827-55.</mixed-citation>
        </ref>
        <ref id="d1305517e1530a1310">
          
            <mixed-citation id="d1305517e1534" publication-type="other">
Rangel, A., C. Camerer, and P. R. Montague. 2008. A framework for studying the neurobiology of value-based
decision making. Nature Neuroscience 9:545-56.</mixed-citation>
        </ref>
        <ref id="d1305517e1544a1310">
          
            <mixed-citation id="d1305517e1548" publication-type="other">
Rolls, E. T., F. Grabenhorst, and G Deco. 2010. Decision-making, errors, and confidence in the brain. Journal
of Neurophysiology 104:2359-74.</mixed-citation>
        </ref>
        <ref id="d1305517e1558a1310">
          
            <mixed-citation id="d1305517e1562" publication-type="other">
Rothschild, M. 1974. A two-armed bandit theory of market pricing. Journal of Economic Theory 9:185-202.</mixed-citation>
        </ref>
        <ref id="d1305517e1569a1310">
          
            <mixed-citation id="d1305517e1573" publication-type="other">
Schultz, W., P. Dayan, and P. R. Montague. 1997. A neural substrate of prediction and reward. Science
275:1593-99.</mixed-citation>
        </ref>
        <ref id="d1305517e1583a1310">
          
            <mixed-citation id="d1305517e1587" publication-type="other">
Siegel, S., and J. M. Andrews. 1962. Magnitude of reinforcement and choice behavior in children. Journal of
Experimental Psychology 63:337-41.</mixed-citation>
        </ref>
        <ref id="d1305517e1597a1310">
          
            <mixed-citation id="d1305517e1601" publication-type="other">
Siegel, S., and D. A. Goldstein. 1959. Decision-making behavior in a two-choice uncertain outcome situation.
Journal of Experimental Psychology 57:37-42.</mixed-citation>
        </ref>
        <ref id="d1305517e1612a1310">
          
            <mixed-citation id="d1305517e1616" publication-type="other">
Simon, H. A. 1955. Behavioral model of rational choice. Quarterly Journal of Economics 49:99-118.</mixed-citation>
        </ref>
        <ref id="d1305517e1623a1310">
          
            <mixed-citation id="d1305517e1627" publication-type="other">
Simon, H. A. 1987. Bounded rationality. In J. Eatwell, M. Milgate, and P. Newman (eds.), The new Palgrave: A
dictionary of economics (pp. 266-68). London: Macmillan.</mixed-citation>
        </ref>
        <ref id="d1305517e1637a1310">
          
            <mixed-citation id="d1305517e1641" publication-type="other">
Sims, C. A. 2003. Implications of rational inattention. Journal of Monetary Economics 50:258-70.</mixed-citation>
        </ref>
        <ref id="d1305517e1648a1310">
          
            <mixed-citation id="d1305517e1652" publication-type="other">
Sims, C. A. 2006. Rational inattention: Beyond the linear-quadratic case. American Economic Review 96:158-63.</mixed-citation>
        </ref>
        <ref id="d1305517e1659a1310">
          
            <mixed-citation id="d1305517e1663" publication-type="other">
Sugrue, L. P., G S. Corrado, and W. T. Newsome. 2004. Matching behavior and the representation of value in
the parietal cortex. Science 304:1782-87.</mixed-citation>
        </ref>
        <ref id="d1305517e1673a1310">
          
            <mixed-citation id="d1305517e1677" publication-type="other">
Thaler, R. H., and C. R. Sunstein. 2009. Nudge: Improving decisions about health, wealth, and happiness.
New York: Penguin.</mixed-citation>
        </ref>
        <ref id="d1305517e1688a1310">
          
            <mixed-citation id="d1305517e1692" publication-type="other">
Tversky, A., and D. Kahneman. 1971. Belief in the law of small numbers. Psychological Bulletin 76:105-10.</mixed-citation>
        </ref>
        <ref id="d1305517e1699a1310">
          
            <mixed-citation id="d1305517e1703" publication-type="other">
Whittle, P. 1988. Restless bandits: Activity allocation in a changing world. Journal of Applied Probability
25:287-98.</mixed-citation>
        </ref>
        <ref id="d1305517e1713a1310">
          
            <mixed-citation id="d1305517e1717" publication-type="other">
Wilcox, N. T. 1993. Lottery choice: Incentives, complexity and decision time. Economic Journal 103:1397-417.</mixed-citation>
        </ref>
        <ref id="d1305517e1724a1310">
          
            <mixed-citation id="d1305517e1728" publication-type="other">
Xu, F., and J. B. Tenenbaum. 2007. Word learning as Bayesian inference. Psychological Review 114:245-72.</mixed-citation>
        </ref>
        <ref id="d1305517e1735a1310">
          
            <mixed-citation id="d1305517e1739" publication-type="other">
Yi, S. K. M., M. Steyvers, and M. Lee. 2009. Modeling human performance in restless bandits with particle
filters. Journal of Problem Solving 2:81-101.</mixed-citation>
        </ref>
        <ref id="d1305517e1749a1310">
          
            <mixed-citation id="d1305517e1753" publication-type="other">
Yu, A. J., and J. D. Cohen. 2009. Sequential effects: Superstition or rational behavior. In M. I. Jordan, Y. LeCun,
and S. A. Solla (eds.), Advances in neural information processing systems, vol.21 (pp. 1873-80). Cambridge,
MA: MIT Press.</mixed-citation>
        </ref>
      </ref-list>
    
  </back>
</article>


