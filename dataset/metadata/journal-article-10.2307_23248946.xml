<?xml version="1.0" encoding="UTF-8"?>


<article dtd-version="1.0" article-type="research-article">
  <front>
      <journal-meta>
         <journal-id xmlns:xlink="http://www.w3.org/1999/xlink" journal-id-type="jstor">jcompgrapstat</journal-id>
         <journal-id xmlns:xlink="http://www.w3.org/1999/xlink" journal-id-type="jstor">j100879</journal-id>
         <journal-title-group xmlns:xlink="http://www.w3.org/1999/xlink">
            <journal-title>Journal of Computational and Graphical Statistics</journal-title>
         </journal-title-group>
      
         <publisher>
            <publisher-name>JCGS Management Committee of the American Statistical Association, Institute of Mathematical Statistics, and Interface Foundation of North America</publisher-name>
         </publisher>
         <issn xmlns:xlink="http://www.w3.org/1999/xlink" pub-type="ppub">10618600</issn>
         <custom-meta-group xmlns:xlink="http://www.w3.org/1999/xlink"/>
      </journal-meta>
      <article-meta xmlns:xlink="http://www.w3.org/1999/xlink">
         <volume xmlns:mml="http://www.w3.org/1998/Math/MathML"
                 xmlns:oasis="http://docs.oasis-open.org/ns/oasis-exchange/table">20</volume>
         <issue xmlns:mml="http://www.w3.org/1998/Math/MathML"
                xmlns:oasis="http://docs.oasis-open.org/ns/oasis-exchange/table">4</issue>
         <issue-id>i23241032</issue-id>
         <article-id pub-id-type="jstor">23248946</article-id>
         <article-categories>
            <subj-group>
               <subject>High-Dimensional Visualization Methods</subject>
            </subj-group>
         </article-categories>
         <title-group>
            <article-title>Partition Maps</article-title>
         </title-group>
         <contrib-group>
            <contrib>
               <string-name>
                  <given-names>Nicolai</given-names>
                  <surname>Meinshausen</surname>
               </string-name>
            </contrib>
         </contrib-group>
         <pub-date pub-type="ppub">
            <day>1</day>
            <month>12</month>
            <year>2011</year>
         </pub-date>
         <fpage>1007</fpage>
         <lpage>1028</lpage>
      
      
      
      
      
      
      
      
      
      
      
      
      
         <permissions>
            <copyright-statement>© 2011 American Statistical Association, the Institute of Mathematical Statistics, and the Interface Foundation of North America</copyright-statement>
         </permissions>
      
         <self-uri xlink:href="https://www.jstor.org/stable/23248946"/>
      
      
         <abstract>
            <p>Tree ensembles, notably Random Forests, have been shown to deliver very accurate predictions on a wide range of regression and classification tasks. A common, yet maybe unjustified, criticism is that they operate as black boxes and provide very little understanding of the data beyond accurate predictions. We focus on multiclass classification and show that Homogeneity Analysis, a technique mostly used in psychometrics, can be leveraged to provide interesting and meaningful visualizations of tree ensemble predictions. Observations and nodes of the tree ensemble are placed in a bipartite graph, connecting each observation to all nodes it belongs to. The graph layout is then chosen by minimizing the sum of the squared edge lengths under certain constraints. We propose a variation of Homogeneity Analysis, called Partition Maps, and analyze advantages and shortcomings compared with multidimensional scaling of proximity matrices. Partition Maps have as potential advantages that (a) the influence of the original nodes and variables is visible in the low-dimensional embedding, similar to biplots, (b) new test observations can be added very easily, and (c) the test error is very similar to the original tree ensemble when using simple nearest-neighbor classification in the two-dimensional Partition Map embedding. Class boundaries, as found by the original tree ensemble algorithm, are thus reflected accurately in Partition Maps. Subgroups and outliers can furthermore be identified in the low-dimensional visualizations, allowing meaningful exploratory analysis of tree ensembles. An R-package partitionMap is provided as a supplementary material.</p>
         </abstract>
         <custom-meta-group>
            <custom-meta>
               <meta-name>lang</meta-name>
               <meta-value>eng</meta-value>
            </custom-meta>
         </custom-meta-group>
      </article-meta>
  </front>
  <back>
    
      <ref-list>
        <title>REFERENCES</title>
        <ref id="d979858e244a1310">
          
            <mixed-citation id="d979858e248" publication-type="other">
Asuncion, A., and Newman, D. (2007), "UCI Machine Learning Repository." [1013,1024]</mixed-citation>
        </ref>
        <ref id="d979858e255a1310">
          
            <mixed-citation id="d979858e259" publication-type="other">
Borg, I., and Groenen, P. (1997), Modern Multidimensional Scaling: Theory and Applications, New York:
Springer. [1008,1015]</mixed-citation>
        </ref>
        <ref id="d979858e269a1310">
          
            <mixed-citation id="d979858e273" publication-type="other">
Breiman, L. (1996), "Bagging Predictors," Machine Learning, 24, 123-140. [1008]</mixed-citation>
        </ref>
        <ref id="d979858e280a1310">
          
            <mixed-citation id="d979858e284" publication-type="other">
— (2001), "Random Forests," Machine Learning, 45, 5-32. [1008,1013,1015,1024]</mixed-citation>
        </ref>
        <ref id="d979858e292a1310">
          
            <mixed-citation id="d979858e296" publication-type="other">
Breiman, L., Friedman, J., Olshen, R., and Stone, C. (1984), Classification and Regression Trees, Belmont:
Wadsworth. [1008]</mixed-citation>
        </ref>
        <ref id="d979858e306a1310">
          
            <mixed-citation id="d979858e310" publication-type="other">
De Leeuw, J. (1988), "Convergence of the Majorization Method for Multidimensional Scaling," Journal of Clas-
sification, 5, 163-180. [1008]</mixed-citation>
        </ref>
        <ref id="d979858e320a1310">
          
            <mixed-citation id="d979858e324" publication-type="other">
— (2009), "Beyond Homogeneity Analysis," technical report, UCLA. [1010,1019]</mixed-citation>
        </ref>
        <ref id="d979858e331a1310">
          
            <mixed-citation id="d979858e335" publication-type="other">
De Leeuw, J., and Mair, P. (2008), "Homogeneity Analysis in R: The Package Homals," Journal of Statistical
Software, 31, 1-21. [1011]</mixed-citation>
        </ref>
        <ref id="d979858e345a1310">
          
            <mixed-citation id="d979858e349" publication-type="other">
Di Battista, G., Eades, P., Tamassia, R., and Tollis, I. (1998), Graph Drawing: Algorithms for the Visualization of
Graphs, Upper Saddle River, NJ: Prentice Hall. [1020]</mixed-citation>
        </ref>
        <ref id="d979858e359a1310">
          
            <mixed-citation id="d979858e363" publication-type="other">
Friedman, J., and Popescu, B. (2008), "Predictive Learning via Rule Ensembles," The Annals of Applied Statistics,
2,916-954. [1008,1009,1013]</mixed-citation>
        </ref>
        <ref id="d979858e374a1310">
          
            <mixed-citation id="d979858e378" publication-type="other">
Fruchterman, T., and Reingold, E. (1991), "Graph Drawing by Force-Directed Placement," Software—Practice
and Experience, 21, 1129-1164. [1020]</mixed-citation>
        </ref>
        <ref id="d979858e388a1310">
          
            <mixed-citation id="d979858e392" publication-type="other">
Fry, B., and Reas, C. (2007), "Processing," available at http://www.processing.org. [1022]</mixed-citation>
        </ref>
        <ref id="d979858e399a1310">
          
            <mixed-citation id="d979858e403" publication-type="other">
Goldberger, J., Roweis, S., Hinton, G., and Salakhutdinov, R. (2005), "Neighbourhood Components Analysis,"
in Advances in Neural Information Processing Systems, Vol. 17, Neural Information Processing Systems
Foundation, pp. 513-520. [1008]</mixed-citation>
        </ref>
        <ref id="d979858e416a1310">
          
            <mixed-citation id="d979858e420" publication-type="other">
Gower, J., and Hand, D. (1996), Biplots, Chapman &amp; Hall/CRC. (1008]</mixed-citation>
        </ref>
        <ref id="d979858e427a1310">
          
            <mixed-citation id="d979858e431" publication-type="other">
Greenacre, M., and Hastie, T. (1987), "The Geometric Interpretation of Correspondence Analysis," Journal of the
American Statistical Association, 82, 437-447. [1009]</mixed-citation>
        </ref>
        <ref id="d979858e441a1310">
          
            <mixed-citation id="d979858e445" publication-type="other">
Hix, S., Noury, A„ and Roland, G. (2006), "Dimensions of Politics in the European Parliament," American Jour-
nal of Political Science, 50, 494-511. [1014]</mixed-citation>
        </ref>
        <ref id="d979858e456a1310">
          
            <mixed-citation id="d979858e460" publication-type="other">
Kamada, T., and Kawai, S. (1989), "An Algorithm for Drawing General Undirected Graphs," Information Pro-
cessing Letters, 31, 7-15. [1020]</mixed-citation>
        </ref>
        <ref id="d979858e470a1310">
          
            <mixed-citation id="d979858e474" publication-type="other">
Kruskal, J. (1964), "Nonmetric Multidimensional Scaling: A Numerical Method," Psychometrika, 29, 115-129.
[1008,1015]</mixed-citation>
        </ref>
        <ref id="d979858e484a1310">
          
            <mixed-citation id="d979858e488" publication-type="other">
Kruskal, J., and Wish, M. (1978), Multidimensional Scaling, Beverly Hills: Sage Publications. [1015]</mixed-citation>
        </ref>
        <ref id="d979858e495a1310">
          
            <mixed-citation id="d979858e499" publication-type="other">
Liaw, A., and Wiener, M. (2002), "Classication and Regression by RandomForest," R News, 2, 18-22. [1008,
1015,1023]</mixed-citation>
        </ref>
        <ref id="d979858e509a1310">
          
            <mixed-citation id="d979858e513" publication-type="other">
Lin, Y„ and Jeon, Y. (2006), "Random Forests and Adaptive Nearest Neighbors," Journal of the American Statis-
tical Association, 101, 578-590. [1008]</mixed-citation>
        </ref>
        <ref id="d979858e523a1310">
          
            <mixed-citation id="d979858e527" publication-type="other">
Meinshausen, N. (2010), "Node Harvest," The Annals of Applied Statistics, 4 (4), 2049-2072. [1013]</mixed-citation>
        </ref>
        <ref id="d979858e535a1310">
          
            <mixed-citation id="d979858e539" publication-type="other">
Meulman, J. (1982), Homogeneity Analysis of Incomplete Data, Leiden: DSWO Press. [1008,1009]</mixed-citation>
        </ref>
        <ref id="d979858e546a1310">
          
            <mixed-citation id="d979858e550" publication-type="other">
Michailidis, G., and De Leeuw, J. (1998), "The Gifi System of Descriptive Multivariate Analysis," Statistical
Science, 13 (4), 307-336. [1008,1009,1011,1019]</mixed-citation>
        </ref>
        <ref id="d979858e560a1310">
          
            <mixed-citation id="d979858e564" publication-type="other">
R Development Core Team (2005), R: A Language and Environment for Statistical Computing, Vienna, Austria:
R Foundation for Statistical Computing. ISBN 3-900051-07-0. [1022,1027]</mixed-citation>
        </ref>
        <ref id="d979858e574a1310">
          
            <mixed-citation id="d979858e578" publication-type="other">
Roweis, S., and Saul, L. (2000), "Nonlinear Dimensionality Reduction by Locally Linear Embedding," Science,
290, 2323. [1007]</mixed-citation>
        </ref>
        <ref id="d979858e588a1310">
          
            <mixed-citation id="d979858e592" publication-type="other">
Shi, T., and Horvath, S. (2006), "Unsupervised Learning With Random Forest Predictors," Journal of Computa-
tional and Graphical Statistics, 15, 118-138. [1008,1015,1027]</mixed-citation>
        </ref>
        <ref id="d979858e602a1310">
          
            <mixed-citation id="d979858e606" publication-type="other">
Sugiyama, M. (2007), "Dimensionality Reduction of Multimodal Labeled Data by Local Fisher Discriminant
Analysis," The Journal of Machine Learning Research, 8, 1061. [1008]</mixed-citation>
        </ref>
        <ref id="d979858e617a1310">
          
            <mixed-citation id="d979858e621" publication-type="other">
Tenenhaus, M., and Young, F. (1985), "An Analysis and Synthesis of Multiple Correspondence Analysis, Optimal
Scaling, Dual Scaling, Homogeneity Analysis and Other Methods for Quantifying Categorical Multivariate
Data," Psychometrika, 50. 91-119. [1008,1009]</mixed-citation>
        </ref>
        <ref id="d979858e634a1310">
          
            <mixed-citation id="d979858e638" publication-type="other">
Tenenbaum, J., Silva, V., and Langford, J. (2000), "A Global Geometric Framework for Nonlinear Dimensionality
Reduction," Science, 290, 2319. [1007]</mixed-citation>
        </ref>
        <ref id="d979858e648a1310">
          
            <mixed-citation id="d979858e652" publication-type="other">
Urbanek, S. (2008), "Visualizing Trees and Forests," in Handbook of Data Visualization, Berlin, Heidelberg:
Spinger, pp. 243-264. [1008]</mixed-citation>
        </ref>
        <ref id="d979858e662a1310">
          
            <mixed-citation id="d979858e666" publication-type="other">
Weinberger, K.. and Saul, L. (2009), "Distance Metric Learning for Large Margin Nearest Neighbor Classifica-
tion," The Journal of Machine Learning Research, 10, 207-244. [1008]</mixed-citation>
        </ref>
      </ref-list>
    
  </back>
</article>


