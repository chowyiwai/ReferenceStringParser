<?xml version="1.0" encoding="UTF-8"?>


<article dtd-version="1.0" article-type="research-article">
  <front>
      <journal-meta>
         <journal-id xmlns:xlink="http://www.w3.org/1999/xlink" journal-id-type="jstor">jcompgrapstat</journal-id>
         <journal-id xmlns:xlink="http://www.w3.org/1999/xlink" journal-id-type="jstor">j100879</journal-id>
         <journal-title-group xmlns:xlink="http://www.w3.org/1999/xlink">
            <journal-title>Journal of Computational and Graphical Statistics</journal-title>
         </journal-title-group>
      
         <publisher>
            <publisher-name>American Statistical Association, Institute of Mathematical Statistics, and Interface Foundation of North America</publisher-name>
         </publisher>
         <issn xmlns:xlink="http://www.w3.org/1999/xlink" pub-type="ppub">10618600</issn>
         <custom-meta-group xmlns:xlink="http://www.w3.org/1999/xlink"/>
      </journal-meta>
      <article-meta xmlns:xlink="http://www.w3.org/1999/xlink">
         <volume xmlns:mml="http://www.w3.org/1998/Math/MathML"
                 xmlns:oasis="http://docs.oasis-open.org/ns/oasis-exchange/table">17</volume>
         <issue xmlns:mml="http://www.w3.org/1998/Math/MathML"
                xmlns:oasis="http://docs.oasis-open.org/ns/oasis-exchange/table">1</issue>
         <issue-id>i27594287</issue-id>
         <article-id pub-id-type="jstor">27594294</article-id>
         <article-id pub-id-type="pub-doi">10.1198/106186008X287337</article-id>
         <title-group>
            <article-title>Using Redundant Parameterizations to Fit Hierarchical Models</article-title>
         </title-group>
         <contrib-group>
            <contrib>
               <string-name>
                  <given-names>Andrew</given-names>
                  <surname>Gelman</surname>
               </string-name>
            </contrib>
            <contrib>
               <string-name>
                  <given-names>David A.</given-names>
                  <surname>van Dyk</surname>
               </string-name>
            </contrib>
            <contrib>
               <string-name>
                  <given-names>Zaiying</given-names>
                  <surname>Huang</surname>
               </string-name>
            </contrib>
            <contrib>
               <string-name>
                  <given-names>W. John</given-names>
                  <surname>Boscardin</surname>
               </string-name>
            </contrib>
         </contrib-group>
         <pub-date pub-type="ppub">
            <day>1</day>
            <month>3</month>
            <year>2008</year>
         </pub-date>
         <fpage>95</fpage>
         <lpage>122</lpage>
         <permissions>
            <copyright-statement>Copyright 2008 American Statistical Association, the Institute of Mathematical Statistics, and the Interface Foundation of North America</copyright-statement>
         </permissions>
      
         <self-uri xlink:href="https://www.jstor.org/stable/27594294"/>
      
      
         <abstract>
            <p>Hierarchical linear and generalized linear models can be fit using Gibbs samplers and Metropolis algorithms; these models, however, often have many parameters, and convergence of the seemingly most natural Gibbs and Metropolis algorithms can sometimes be slow. We examine solutions that involve reparameterization and over-parameterization. We begin with parameter expansion using working parameters, a strategy developed for the EM algorithm. This strategy can lead to algorithms that are much less susceptible to becoming stuck near zero values of the variance parameters than are more standard algorithms. Second, we consider a simple rotation of the regression coefficients based on an estimate of their posterior covariance matrix. This leads to a Gibbs algorithm based on updating the transformed parameters one at a time or a Metropolis algorithm with vector jumps; either of these algorithms can perform much better (in terms of total CPU time) than the two standard algorithms: one-at-a-time updating of untransformed parameters or vector updating using a linear regression at each step. We present an innovative evaluation of the algorithms in terms of how quickly they can get away from remote areas of parameter space, along with some more standard evaluation of computation and convergence speeds. We illustrate our methods with examples from our applied work. Our ultimate goal is to develop a fast and reliable method for fitting a hierarchical linear model as easily as one can now fit a nonhierarchical model, and to increase understanding of Gibbs samplers for hierarchical models in general.</p>
         </abstract>
         <kwd-group>
            <kwd>Bayesian computation</kwd>
            <kwd>Blessing of dimensionality</kwd>
            <kwd>Markov chain Monte Carlo</kwd>
            <kwd>Multilevel modeling</kwd>
            <kwd>Mixed effects models</kwd>
            <kwd>PX-EM algorithm</kwd>
            <kwd>Random effects regression</kwd>
            <kwd>Redundant parameterization</kwd>
            <kwd>Working parameters</kwd>
         </kwd-group>
         <custom-meta-group>
            <custom-meta>
               <meta-name>lang</meta-name>
               <meta-value>eng</meta-value>
            </custom-meta>
         </custom-meta-group>
      </article-meta>
  </front>
  <back>
    
      <ref-list>
        <title>References</title>
        <ref id="d1449548e186a1310">
          
            <mixed-citation id="d1449548e190" publication-type="other">
Barnard, J., McCulloch, R., and Meng, X. L. (1996), "Modeling Covariance Matrices in Terms of Standard
Deviations and Correlations, with Application to Shrinkage," Statistica Sinica, 10, 1281–1311.</mixed-citation>
        </ref>
        <ref id="d1449548e200a1310">
          
            <mixed-citation id="d1449548e204" publication-type="other">
Besag, J. (1974), "Spatial Interaction and the Statistical Analysis of Lattice Systems" (with discussion), Journal
of the Royal Statistical Society, Ser. B, 36, 192–236.</mixed-citation>
        </ref>
        <ref id="d1449548e214a1310">
          
            <mixed-citation id="d1449548e218" publication-type="other">
Besag, J., and Green, P. J. (1993), "Spatial Statistics and Bayesian Computation" (with discussion), Journal of
the Royal Statistical Society, Ser. B, 55, 25–102.</mixed-citation>
        </ref>
        <ref id="d1449548e228a1310">
          
            <mixed-citation id="d1449548e232" publication-type="other">
Boscardin, W. J. (1996), "Bayesian Analysis for Some Hierarchical Linear Models," unpublished Ph.D. thesis,
Department of Statistics, University of California, Berkeley.</mixed-citation>
        </ref>
        <ref id="d1449548e243a1310">
          
            <mixed-citation id="d1449548e247" publication-type="other">
Boscardin, W. J., and Gelman, A. (1996), "Bayesian Regression with Parametric Models for Heteroscedasticity,"
Advances in Econometrics, 11 A, 87–109.</mixed-citation>
        </ref>
        <ref id="d1449548e257a1310">
          
            <mixed-citation id="d1449548e261" publication-type="other">
Carlin, B. P., and Louis, T. A. (2000), Bayes and Empirical Bayes Methods for Data Analysis (2nd ed.), London:
Chapman and Hall.</mixed-citation>
        </ref>
        <ref id="d1449548e271a1310">
          
            <mixed-citation id="d1449548e275" publication-type="other">
Daniels, M. J., and Kass, R. E. (1999), "Nonconjugate Bayesian Estimation of Covariance Matrices and its use in
Hierarchical Models," Journal of the American Statistical Association, 94, 1254–1263.</mixed-citation>
        </ref>
        <ref id="d1449548e285a1310">
          
            <mixed-citation id="d1449548e289" publication-type="other">
Dempster, A. P., Laird, N. M., and Rubin, D. B. (1977), "Maximum Likelihood from Incomplete Data via the EM
Algorithm" (with discussion), Journal of the Royal Statistical Society, Ser. B, 39, 1–38.</mixed-citation>
        </ref>
        <ref id="d1449548e299a1310">
          
            <mixed-citation id="d1449548e303" publication-type="other">
Dempster, A. P., Rubin, D. B., and Tsutakawa, R. K. (1981), "Estimation in Covariance Components Models,"
Journal of the American Statistical Association, 76, 341–353.</mixed-citation>
        </ref>
        <ref id="d1449548e313a1310">
          
            <mixed-citation id="d1449548e317" publication-type="other">
Gelfand, A. E., and Smith, A. F. M. (1990), "Sampling-Based Approaches to Calculating Marginal Densities,"
Journal of the American Statistical Association, 85, 398–409.</mixed-citation>
        </ref>
        <ref id="d1449548e328a1310">
          
            <mixed-citation id="d1449548e332" publication-type="other">
Gelfand, A. E., Sahu, S. K., and Carlin, B. P. (1995), "Efficient Parameterization for Normal Linear Mixed
Models," Biometrika, 82, 479–488.</mixed-citation>
        </ref>
        <ref id="d1449548e342a1310">
          
            <mixed-citation id="d1449548e346" publication-type="other">
Gelman, A. (2004), "Parameterization and Bayesian Modeling," Journal of the American Statistical Association,
99, 537–545.</mixed-citation>
        </ref>
        <ref id="d1449548e356a1310">
          
            <mixed-citation id="d1449548e360" publication-type="other">
—(2005), "Analysis of Variance: Why it is More Important than Ever" (with discussion), The Annals of
Statistics, 33, 1–53.</mixed-citation>
        </ref>
        <ref id="d1449548e370a1310">
          
            <mixed-citation id="d1449548e374" publication-type="other">
—(2006), "Prior Distributions for Variance Parameters in Hierarchical Models," Bayesian Analysis, 1, 515–
533.</mixed-citation>
        </ref>
        <ref id="d1449548e384a1310">
          
            <mixed-citation id="d1449548e388" publication-type="other">
Gelman, A., Carlin, J. B., Stern, H. S., and Rubin, D. B. (1995), Bayesian Data Analysis (1st ed.), London:
Chapman and Hall.</mixed-citation>
        </ref>
        <ref id="d1449548e398a1310">
          
            <mixed-citation id="d1449548e402" publication-type="other">
Gelman, A., and Hill, J. (2007), Data Analysis Using Regression and Multilevel/Hierarchical Models, New York:
Cambridge University Press.</mixed-citation>
        </ref>
        <ref id="d1449548e413a1310">
          
            <mixed-citation id="d1449548e417" publication-type="other">
Gelman, A., and Little, T. C. (1997), "Poststratification into Many Categories using Hierarchical Logistic Regres-
sion," Survey Methodology, 23, 127–135.</mixed-citation>
        </ref>
        <ref id="d1449548e427a1310">
          
            <mixed-citation id="d1449548e431" publication-type="other">
Gelman, A., and Rubin, D. B. (1992), "Inference from Iterative Simulation Using Multiple Sequences" (with
discussion), Statistical Science, 7, 457–511.</mixed-citation>
        </ref>
        <ref id="d1449548e441a1310">
          
            <mixed-citation id="d1449548e445" publication-type="other">
Gilks, W. R., Best, N., and Tan, K. K. C. (1995), "Adaptive Rejection Metropolis Sampling Within Gibbs Sam-
pling," Applied Statistics, 44, A55–A12.</mixed-citation>
        </ref>
        <ref id="d1449548e455a1310">
          
            <mixed-citation id="d1449548e459" publication-type="other">
Gilks, W. R., Richardson, S., and Spiegelhalter, D. (eds.) (1996), Practical Markov Chain Monte Carlo, London:
Chapman and Hall.</mixed-citation>
        </ref>
        <ref id="d1449548e469a1310">
          
            <mixed-citation id="d1449548e473" publication-type="other">
Gilks, W. R., and Roberts, G. O. (1996), "Strategies for Improving MCMC," in Practical Markov Chain Monte
Carlo, eds. W. Gilks, S. Richardson, and D. Spiegelhalter, London: Chapman and Hall, pp. 89–114.</mixed-citation>
        </ref>
        <ref id="d1449548e483a1310">
          
            <mixed-citation id="d1449548e487" publication-type="other">
Goldstein, H. (1995), Multilevel Statistical Models, London: Edward Arnold.</mixed-citation>
        </ref>
        <ref id="d1449548e495a1310">
          
            <mixed-citation id="d1449548e499" publication-type="other">
Golub, G. H., and van Loan, C. F. (1983), Matrix Computations, Baltimore, MD: Johns Hopkins University Press.</mixed-citation>
        </ref>
        <ref id="d1449548e506a1310">
          
            <mixed-citation id="d1449548e510" publication-type="other">
Green, P. J. (1995), "Reversible Jump Markov Chain Monte Carlo Computation and Bayesian Model Determina-
tion," Biometrika, 82, 711–732.</mixed-citation>
        </ref>
        <ref id="d1449548e520a1310">
          
            <mixed-citation id="d1449548e524" publication-type="other">
Hills, S. E., and Smith, A. F. M. (1992), "Parametrization Issues in Bayesian Inference" (with discussion), in
Bayesian Statistics 4, eds. J. M. Bernado, J. O. Berger, A. P. Dawid, and A. F. M. Smith, New York: Oxford
University Press, pp. 227–246.</mixed-citation>
        </ref>
        <ref id="d1449548e537a1310">
          
            <mixed-citation id="d1449548e541" publication-type="other">
Hodges, J. H. (1998), "Some Algebra and Geometry for Hierarchical Models, Applied to Diagnostics" (with
discussion), Journal of the Royal Statistical Society, Ser. B, 60, 497–536.</mixed-citation>
        </ref>
        <ref id="d1449548e551a1310">
          
            <mixed-citation id="d1449548e555" publication-type="other">
Laird, N. M., and Ware, J. H. (1982), "Random-Effects Models for Longitudinal Data," Biometrics, 38, 963–974.</mixed-citation>
        </ref>
        <ref id="d1449548e562a1310">
          
            <mixed-citation id="d1449548e566" publication-type="other">
Lindley, D. V., and Smith, A. F. M. (1972), "Bayes Estimates for the Linear Model," Journal of the Royal Statis-
tical Society, Ser. B, 34, 1–41.</mixed-citation>
        </ref>
        <ref id="d1449548e577a1310">
          
            <mixed-citation id="d1449548e581" publication-type="other">
Liu, C. (2003), "Alternating Subspace-Spanning Resampling to Accelerate Markov Chain Monte Carlo Simula-
tion," Journal of the American Statistical Association, 98, 110–117.</mixed-citation>
        </ref>
        <ref id="d1449548e591a1310">
          
            <mixed-citation id="d1449548e595" publication-type="other">
Liu, C., Rubin, D. B., and Wu, Y. N. (1998), "Parameter Expansion to Accelerate EM: The PX-EM Algorithm,"
Biometrika, 85, 755–770.</mixed-citation>
        </ref>
        <ref id="d1449548e605a1310">
          
            <mixed-citation id="d1449548e609" publication-type="other">
Liu, J. S. (1994), "The Fraction of Missing Information and Convergence Rate for Data Augmentation," Comput-
ing Science and Statistics, 26, 490–497.</mixed-citation>
        </ref>
        <ref id="d1449548e619a1310">
          
            <mixed-citation id="d1449548e623" publication-type="other">
Liu, J., and Wu, Y. N. (1999), "Parameter Expansion for Data Augmentation," Journal of the American Statistical
Association, 94, 1264–1274.</mixed-citation>
        </ref>
        <ref id="d1449548e633a1310">
          
            <mixed-citation id="d1449548e637" publication-type="other">
Longford, N. (1993), Random Coefficient Models, Oxford: Clarendon Press.</mixed-citation>
        </ref>
        <ref id="d1449548e644a1310">
          
            <mixed-citation id="d1449548e648" publication-type="other">
MacLehose, R. F., Dunson, D. B., Herring, A., and Hoppin, J. A. (2007), "Bayesian Methods for Highly Corre-
lated Exposure Data," Epidemiology 18, 199–207.</mixed-citation>
        </ref>
        <ref id="d1449548e659a1310">
          
            <mixed-citation id="d1449548e663" publication-type="other">
McCullagh, P., and Neider, J. A. (1989), Generalized Linear Models (2nd ed.), London: Chapman and Hall.</mixed-citation>
        </ref>
        <ref id="d1449548e670a1310">
          
            <mixed-citation id="d1449548e674" publication-type="other">
Meng, X. L., and van Dyk, D. (1997), "The EM Algorithm—An Old Folk Song Sung to a Fast New Tune" (with
discussion), Journal of the Royal Statistical Society, Ser. B, 59, 511–567.</mixed-citation>
        </ref>
        <ref id="d1449548e684a1310">
          
            <mixed-citation id="d1449548e688" publication-type="other">
O'Malley, A. J., and Zaslavsky, A. M. (2005), "Cluster-Level Covariance Analysis for Survey Data with Struc-
tured Nonresponse," technical report, Department of Health Care Policy, Harvard Medical School.</mixed-citation>
        </ref>
        <ref id="d1449548e698a1310">
          
            <mixed-citation id="d1449548e702" publication-type="other">
Raftery, A. E. (1996), "Hypothesis Testing and Model Selection via Posterior Simulation," in Practical Markov
Chain Monte Carlo, eds. W. Gilks, S. Richardson, and D. Spiegelhalter, New York: Chapman and Hall,
163–187.</mixed-citation>
        </ref>
        <ref id="d1449548e715a1310">
          
            <mixed-citation id="d1449548e719" publication-type="other">
Robinson, G. K. (1991), "That BLUP is a Good Thing: The Estimation of Random Effects" (with discussion),
Statistical Science, 6, 15–51.</mixed-citation>
        </ref>
        <ref id="d1449548e729a1310">
          
            <mixed-citation id="d1449548e733" publication-type="other">
Rosenthal, J. S. (1995), "Minorization Conditions and Convergence Rates for Markov Chain Monte Carlo," Jour-
nal of the American Statistical Association, 90, 558–566.</mixed-citation>
        </ref>
        <ref id="d1449548e744a1310">
          
            <mixed-citation id="d1449548e748" publication-type="other">
Rubin, D. B. (1981), "Estimation in Parallel Randomized Experiments," Journal of Educational Statistics, 6,
377–401.</mixed-citation>
        </ref>
        <ref id="d1449548e758a1310">
          
            <mixed-citation id="d1449548e762" publication-type="other">
Sargent, D. J., Hodges, J. S., and Carlin, B. P. (2000), "Structured Markov Chain Monte Carlo," Journal of
Computational and Graphical Statistics, 9, 217–234.</mixed-citation>
        </ref>
        <ref id="d1449548e772a1310">
          
            <mixed-citation id="d1449548e776" publication-type="other">
van Dyk, D. A., and Meng, X. L. (2001), "The Art of Data Augmentation" (with discussion), Journal of Compu-
tational and Graphical Statistics, 10, 1–111.</mixed-citation>
        </ref>
      </ref-list>
    
  </back>
</article>


