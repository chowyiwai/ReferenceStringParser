

<book xmlns:oasis="http://docs.oasis-open.org/ns/oasis-exchange/table"
      xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
      xmlns:xlink="http://www.w3.org/1999/xlink"
      xmlns:mml="http://www.w3.org/1998/Math/MathML"
      dtd-version="0.2"
      xml:lang="eng">
   <collection-meta>
      <collection-id collection-id-type="jstor">j.ctt4z61v</collection-id>
      <volume>1</volume>
   </collection-meta>
   <book-meta>
      <book-id book-id-type="doi">10.2307/j.ctvs32rpn</book-id>
      <subj-group subj-group-type="discipline">
         <subject>Mathematics</subject>
         <subject>Computer Science</subject>
      </subj-group>
      <book-title-group>
         <book-title>Pseudorandomness and Cryptographic Applications</book-title>
      </book-title-group>
      <contrib-group>
         <contrib contrib-type="author" id="contrib1">
            <name name-style="western">
               <surname>Luby</surname>
               <given-names>Michael</given-names>
            </name>
         </contrib>
      </contrib-group>
      <pub-date>
         <day>31</day>
         <month>12</month>
         <year>2019</year>
      </pub-date>
      <isbn content-type="ppub">9780691025469</isbn>
      <isbn content-type="epub">9780691206844</isbn>
      <isbn content-type="epub">0691206848</isbn>
      <publisher>
         <publisher-name>Princeton University Press</publisher-name>
         <publisher-loc>PRINCETON, NEW JERSEY</publisher-loc>
      </publisher>
      <permissions>
         <copyright-year>1996</copyright-year>
         <copyright-holder>Princeton University Press</copyright-holder>
      </permissions>
      <self-uri xlink:href="https://www.jstor.org/stable/j.ctvs32rpn"/>
      <abstract abstract-type="short">
         <p> &lt;p&gt;A pseudorandom generator is an easy-to-compute function that stretches a short random string into a much longer string that "looks" just like a random string to any efficient adversary. One immediate application of a pseudorandom generator is the construction of a private key cryptosystem that is secure against chosen plaintext attack.    &lt;p&gt;There do not seem to be natural examples of functions that are pseudorandom generators. On the other hand, there do seem to be a variety of natural examples of another basic primitive: the one-way function. A function is one-way if it is easy to compute but hard for any efficient adversary to invert on average.    &lt;p&gt;The first half of the book shows how to construct a pseudorandom generator from any one-way function. Building on this, the second half of the book shows how to construct other useful cryptographic primitives, such as private key cryptosystems, pseudorandom function generators, pseudorandom permutation generators, digital signature schemes, bit commitment protocols, and zero-knowledge interactive proof systems. The book stresses rigorous definitions and proofs.  </p>
      </abstract>
      <custom-meta-group>
         <custom-meta>
            <meta-name>
                    lang
                </meta-name>
            <meta-value>eng</meta-value>
         </custom-meta>
      </custom-meta-group>
   </book-meta>
   <body>
      <book-part book-part-type="book-toc-page-order" indexed="yes">
         <body>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctvs32rpn.1</book-part-id>
                  <title-group>
                     <title>Front Matter</title>
                  </title-group>
                  <fpage>i</fpage>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctvs32rpn.2</book-part-id>
                  <title-group>
                     <title>Table of Contents</title>
                  </title-group>
                  <fpage>v</fpage>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctvs32rpn.3</book-part-id>
                  <title-group>
                     <title>Overview and Usage Guide</title>
                  </title-group>
                  <fpage>ix</fpage>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctvs32rpn.4</book-part-id>
                  <title-group>
                     <title>Mini-Courses</title>
                  </title-group>
                  <fpage>xiii</fpage>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctvs32rpn.5</book-part-id>
                  <title-group>
                     <title>Acknowledgments</title>
                  </title-group>
                  <contrib-group>
                     <contrib contrib-type="author" id="contrib1" xlink:type="simple">
                        <name name-style="western">
                           <surname>Luby</surname>
                           <given-names>Michael</given-names>
                        </name>
                     </contrib>
                  </contrib-group>
                  <fpage>xv</fpage>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctvs32rpn.6</book-part-id>
                  <title-group>
                     <title>Preliminaries</title>
                  </title-group>
                  <fpage>3</fpage>
                  <abstract>
                     <p>We introduce some basic notation for bits, sets, strings, matrices, functions, numbers and probability. We review some standard computational complexity classes and probability facts.</p>
                     <p>In this section, we introduce much of the notation that will be used in subsequent lectures.</p>
                     <p>
                        <tex-math>$\mathcal{N}$</tex-math> is the set of natural numbers, and <tex-math>$n\in \mathcal{N}.\mathcal{R}$</tex-math> is the set of real numbers.</p>
                     <p>Set Notation : We let {0, 1}<sup>
                           <italic>n</italic>
                        </sup> be the set of all <italic>n</italic> bit strings, and we let {0, 1}<sup>≤<italic>n</italic>
                        </sup> be the set of all bit strings of length at most <italic>n</italic>. If <italic>S</italic> is a set then #<italic>S</italic> is the number of elements in</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctvs32rpn.7</book-part-id>
                  <title-group>
                     <title>Lecture 1</title>
                  </title-group>
                  <fpage>13</fpage>
                  <abstract>
                     <p>We describe a cryptosystem for sending a private message with the restriction that the message is at most as long as a previously established private key. We introduce the notion of a pseudorandom generator, and show how to use one to send messages much longer than the private key. In subsequent lectures, we show how to construct a pseudorandom generator from a one-way function. In this lecture, we informally introduce and give conjectured examples of one-way functions.</p>
                     <p>The first few lectures develop solutions to the following basic problem in cryptography: Alice and Bob are together now but soon they will</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctvs32rpn.8</book-part-id>
                  <title-group>
                     <title>Lecture 2</title>
                  </title-group>
                  <fpage>21</fpage>
                  <abstract>
                     <p>We discuss security issues associated with the computing environment of a party, and define the security parameter of a primitive based on this discussion. Adversaries that try to break primitives are introduced, together with the notion of time-success ratio, and the security of a primitive is defined. Definitions of one-way functions and one-way permutations are given, and cryptographic reduction is defined.</p>
                     <p>The definition of a primitive includes the description of the interaction between the parties that implement the primitive and the allowable behavior of adversaries trying to break it. As an informal example, a function <italic>f</italic> is said to be</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctvs32rpn.9</book-part-id>
                  <title-group>
                     <title>Lecture 3</title>
                  </title-group>
                  <fpage>35</fpage>
                  <abstract>
                     <p>We define a weak one-way function and describe a weak-preserving reduction from a weak one-way function to a one-way function. We then describe several increasingly intricate linear-preserving reductions from a weak one-way permutation to a one-way permutation, where each subsequent reduction uses fewer public random bits than the previous.</p>
                     <p>Intuitively, <italic>f</italic> is a weak one-way function if it is hard to find an inverse of <italic>f</italic>(<italic>x</italic>) for some significant but perhaps not very large fraction <italic>x</italic> ϵ {{0, 1}<sup>
                           <italic>n</italic>
                        </sup>. (In contrast, for a one-way function it is hard to find an inverse of <italic>f</italic>(<italic>x</italic>) for all but an insignificant fraction</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctvs32rpn.10</book-part-id>
                  <title-group>
                     <title>Lecture 4</title>
                  </title-group>
                  <fpage>49</fpage>
                  <abstract>
                     <p>Using the random self-reducibility property of the discrete log problem, we show that if it is easy to invert a significant fraction of its inputs then it is easy to invert all its inputs. The definition of a pseudorandom generator and a definition of pseudorandomness based on the next bit test are given, and the two definitions are shown to be equivalent. A construction of a pseudorandom generator that produces a long output from a pseudorandom generator that produces an output one bit longer than its input is given.</p>
                     <p>Partially justified by the example on page 26, we introduced the</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctvs32rpn.11</book-part-id>
                  <title-group>
                     <title>Lecture 5</title>
                  </title-group>
                  <fpage>56</fpage>
                  <abstract>
                     <p>We introduce a paradigm for derandomizing probabilistic algorithms for a variety of problems. This approach is of central importance for many of the constructions introduced in subsequent lectures.</p>
                     <p>The paradigm consists of two complementary parts. The first part is to design a probabilistic algorithm described by a sequence of random variables so that the analysis is valid assuming limited independence between the random variables. The second part is the design of a small probability space for the random variables such that they are somewhat independent of each other. Thus, the random variables used by the algorithm can be generated according</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctvs32rpn.12</book-part-id>
                  <title-group>
                     <title>Lecture 6</title>
                  </title-group>
                  <fpage>64</fpage>
                  <abstract>
                     <p>We give the definition of the inner product bit for a function and define what it means for this bit to be hidden. We prove that the inner product bit is hidden for a one-way function. One immediate application is a simple construction of a pseudorandom generator from any one-way permutation.</p>
                     <p>In this lecture, we introduce and prove the Hidden Bit Theorem. There are several technical parts in the reduction from any one-way function <italic>f</italic> to a pseudorandom generator <italic>g</italic>. Intuitively, the Hidden Bit Theorem is the part that transforms the one-wayness of <italic>f</italic> into a bit <italic>b</italic> such that:</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctvs32rpn.13</book-part-id>
                  <title-group>
                     <title>Lecture 7</title>
                  </title-group>
                  <fpage>70</fpage>
                  <abstract>
                     <p>We describe statistical measures of distance between probability distributions and define what it means for two distributions to be computationally indistinguishable. We prove that many inner product bit are hidden for a one-way function.</p>
                     <p>For the following definitions and exercises, let <tex-math>$\mathcal{D}_{n}:\left \{ 0, \right1 \}^{n}$</tex-math> and <tex-math>$\mathcal{E}_{n}:\left \{ 0, \right1 \}^{n}$</tex-math> be distributions, and let <tex-math>$X\in \mathcal{D}_{n}\left \{ 0, \right1 \}^{n}$</tex-math> and <tex-math>$Y\in \varepsilon _{n}\left \{ 0, \right1 \}^{n}$</tex-math>.</p>
                     <p>Definition (statistically distinguishable): <italic>The statistical distance</italic> between <tex-math>$\mathcal{D}_{n}$</tex-math> and <tex-math>$\mathcal{E}_{n}$</tex-math> is</p>
                     <p>
                        <tex-math>\[\mathrm{dist}(\mathcal{D}_{n},\mathcal{E}_{n})=1/2.\sum_{z\in \left \{ 0, 1 \right \}^{n}}\left | \underset{X}{\mathrm{Pr}}\left [ X=z \right ]-\underset{Y}{\mathrm{Pr}} \left [ Y=z \right ]\right |.\]</tex-math>
                     </p>
                     <p>Equivalently,</p>
                     <p>
                        <tex-math>\[\mathrm{dist}(\mathcal{D}_{n},\mathcal{E}_{n})=\mathrm{max}\left \{ \underset{X}{Pr}[X\in S]-\underset{Y}{Pr}[Y\in S]:S\subseteq \left \{ 0,1 \right \}^{n} \right \}.\]</tex-math>
                     </p>
                     <p>We use dist(<italic>X, Y</italic>) and <tex-math>$\mathrm{dist}(\mathcal{D}_{n},\mathcal{E}_{n})$</tex-math> interchangeably. We say \mathcal{D}_{n} and \mathcal{E}_{n} are at most <italic>ϵ</italic>(<italic>n</italic>)-statistically distinguishable if dist <tex-math>$(\mathcal{D}_{n},\mathcal{E}_{n})\leq \epsilon (n).$</tex-math>
                     </p>
                     <p>Definition (statistical test): A <italic>statistical test t</italic> for <tex-math>$\mathcal{D}_{n}$</tex-math> and <tex-math>$\mathcal{E}_{n}$</tex-math> is a function</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctvs32rpn.14</book-part-id>
                  <title-group>
                     <title>Lecture 8</title>
                  </title-group>
                  <fpage>79</fpage>
                  <abstract>
                     <p>We introduce notions of statistical and computational entropy. We introduce universal hash functions and show how entropy can be smoothed using hashing.</p>
                     <p>Definition (Shannon entropy): Let <tex-math>$\mathcal{D}_{n}$</tex-math> be a distribution on {0, 1}<sup>
                           <italic>n</italic>
                        </sup> and let <tex-math>$X\in \mathcal{D}_{n}\left \{ 0, \right1 \}^{n}$</tex-math>. For all <tex-math>$x\in \left \{ 0, \right1 \}^{n}$</tex-math>, the <italic>information</italic> of <italic>x</italic> with respect to <italic>X</italic> is defined as</p>
                     <p>
                        <tex-math>\[infor_{X}(x)=\mathrm{log}(1/\underset{X}{\mathrm{Pr}}[X=x])=-\mathrm{log}(\underset{X}{\mathrm{Pr}}[X=x]).\]</tex-math>
                     </p>
                     <p>We can view infor<sub>
                           <italic>X</italic>
                        </sub>(<italic>X</italic>) as a random variable defined in terms of <italic>X</italic>. The <italic>entropy</italic> of <italic>X</italic> is defined as the expected information of <italic>X</italic>, i.e.,</p>
                     <p>
                        <tex-math>\[\mathrm{ent}(X)=E_{X}[\mathrm{infor}_{X}(X)]=\sum_{x\in \left \{ 0,1 \right \}^{n}}\underset{X}{\mathrm{Pr}}[X=x]\cdot \mathrm{infor}_{X}(x).\]</tex-math>
                     </p>
                     <p>We use <tex-math>$\mathrm{ent}(\mathcal{D}_{n})$</tex-math> and ent(<italic>X</italic>) interchangeably.</p>
                     <p>Note that if Pr[<italic>X</italic> = <italic>x</italic>] = 0 then infor<sub>
                           <italic>x</italic>
                        </sub>(<italic>x</italic>) = ∞. The correct default in this</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctvs32rpn.15</book-part-id>
                  <title-group>
                     <title>Lecture 9</title>
                  </title-group>
                  <fpage>88</fpage>
                  <abstract>
                     <p>We describe two reductions from a one-way one-to-one function to a pseudorandom generator: The first is a weak-preserving reduction and the second is a poly-preserving reduction. We describe a poly-preserving reduction from a one-way regular function to a pseudorandom generator.</p>
                     <p>We give two reductions from a one-way one-to-one function <italic>f</italic> to a pseudorandom generator <italic>g</italic>. The first reduction is only weak-preserving, whereas the second is poly-preserving. The first reduction is an immediate application of the Smoothing Entropy Theorem (page 86).</p>
                     <p>Definition (diagonal entries of a matrix): If $a\in \left \{ 0, \right1 \}^{n\times n}$ then <tex-math>$\mathrm{diag}(a)=\left \langle a_{1,1,}a_{2,2,...,}a_{n,n}\rangle$</tex-math>.</p>
                     <p>weak-preserving construction for</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctvs32rpn.16</book-part-id>
                  <title-group>
                     <title>Lecture 10</title>
                  </title-group>
                  <fpage>95</fpage>
                  <abstract>
                     <p>We define a false entropy generator, show how to construct a false entropy generator from any one-way function in the non-uniform sense, and show how to construct a pseudorandom generator from a false entropy generator. Together, this yields a non-uniform reduction from any one-way function to a pseudorandom generator.</p>
                     <p>As shown in Theorem 9.2 (page 90), there is a poly-preserving reduction from a one-way one-to-one function to a pseudorandom generator. The intuitive idea of the reduction from any one-way function to a pseudorandom generator is to construct an almost one-to-one one-way function from any one-way function and then apply result</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctvs32rpn.17</book-part-id>
                  <title-group>
                     <title>Lecture 11</title>
                  </title-group>
                  <fpage>105</fpage>
                  <abstract>
                     <p>We define a stream private key cryptosystem, define several notions of security, including passive attack and chosen plaintext attack, and design a stream private key cryptosystem that is secure against these attacks based on a pseudorandom generator.</p>
                     <p>We now consider the basic scenario described in Lecture 1 that was our initial motivation for constructing a pseudorandom generator. Parties <italic>P</italic>
                        <sub>1,</sub> and <italic>P</italic>
                        <sub>2</sub> initially establish a shared random private key <italic>x</italic> of length <italic>n</italic> using a private line, and then afterwards <italic>P</italic>
                        <sub>1</sub> is able to send messages privately on a public line to <italic>P</italic>
                        <sub>2</sub> of total length <italic>p</italic>(<italic>n</italic>), where <italic>p</italic>(<italic>n</italic>) &gt; <italic>n</italic>.</p>
                     <p>In</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctvs32rpn.18</book-part-id>
                  <title-group>
                     <title>Lecture 12</title>
                  </title-group>
                  <fpage>117</fpage>
                  <abstract>
                     <p>We define a block cryptosystem and security against chosen plaintext attack. We show how to construct a pseudorandom function generator from a pseudorandom generator, and show how a pseudorandom function generator can be used to construct a block private key cryptosystem secure against chosen plaintext attack.</p>
                     <p>There are some practical problems with using a stream cryptosystem. First of all, because of the implicit indexing, both parties have to stay in lock step forever, and if transmissions get garbled at some point then they have to resynchronize somehow. One way to get around this problem is to send the index of</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctvs32rpn.19</book-part-id>
                  <title-group>
                     <title>Lecture 13</title>
                  </title-group>
                  <fpage>128</fpage>
                  <abstract>
                     <p>We define the notion of a pseudorandom invertible permutation generator and discuss applications to the construction of a block private key cryptosystem secure against chosen plaintext attack. We introduce a construction of a perfect random permutation based on a perfect random function.</p>
                     <p>The Data Encryption Standard (DES) is a standard private key cryptosystem used in the United States by the business community. DES is the motivation for both the definition of a pseudorandom invertible permutation generator and the construction of a pseudorandom invertible permutation generator from a pseudorandom function generator. DES can be thought of as</p>
                     <p>
                        <tex-math>\[g^{64}\subset \mathbf{Perm}:\left \{ 0, \right1 \}^{^{64}}\rightarrow \left \{ 0, \right1 \}^{64},\]</tex-math>
                     </p>
                     <p>where each function</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctvs32rpn.20</book-part-id>
                  <title-group>
                     <title>Lecture 14</title>
                  </title-group>
                  <fpage>138</fpage>
                  <abstract>
                     <p>We show how to construct a pseudorandom invertible permutation generator. We define and construct a super pseudorandom invertible permutation generator. We use these constructions to design secure block private key cryptosystems.</p>
                     <p>We show how to construct a pseudorandom invertible permutation generator from a pseudorandom function generator. Let</p>
                     <p>
                        <tex-math>\[f:\left \{ 0, \right1 \}^{n}\times \left \{ 0, \right1 \}^{n}\rightarrow \left \{ 0, \right1 \}^{n}\]</tex-math>
                     </p>
                     <p>be a pseudorandom function generator and let <tex-math>$\left \langle g^{(3)},\bar{g}^{(3)}\rangle$</tex-math> be the invertible permutation generator constructed from <italic>f</italic> as described on page 129.</p>
                     <p>Permutation Theorem : If <italic>f</italic> is a pseudorandom function generator then <tex-math>$\left \langle g^{(3)},\bar{g}^{(3)}\rangle$</tex-math> is a pseudorandom invertible permutation generator. The reduction is linear-preserving.</p>
                     <p>PROOF: Let</p>
                     <p>
                        <tex-math>\[F_{0}\; \; \in_{u} \mathrm{Fnc}:\left \{ 0, \right1 \}^{2n}\rightarrow \left \{ 0, \right1 \}^{2n},\]</tex-math>
                     </p>
                     <p>
                        <tex-math>\[F_{1},F_{2},F_{3}\; \; \in _{u}\mathrm{Fnc:}\left \{ 0, \right1 \}^{n}\rightarrow \left \{ 0, \right1 \}^{n}\; \; \mathrm{and}\]</tex-math>
                     </p>
                     <p>
                        <tex-math>\[X\; \; \in _{u}\left \{ 0, \right 1\}^{3\times n}.\]</tex-math>
                     </p>
                     <p>Suppose <italic>A</italic> is</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctvs32rpn.21</book-part-id>
                  <title-group>
                     <title>Lecture 15</title>
                  </title-group>
                  <fpage>146</fpage>
                  <abstract>
                     <p>We introduce trapdoor one-way functions, one-way predicates and trapdoor one-way predicate, and based on this design cryptosystems without an initial communication using a private line.</p>
                     <p>We now introduce a stronger form of a one-way function that has additional useful properties.</p>
                     <p>Definition (trapdoor one-way function): Let <tex-math>$\mathcal{D}_{n}:\left \{ 0, \right1 \}^{r(n)}\rightarrow \left \{ 0, \right1 \}^{m(n)+l(n)}$</tex-math> be a P-samplable probability ensemble. We call <tex-math>$\mathcal{D}_{n}$</tex-math> the <italic>key generation distribution</italic>. Let <tex-math>$\left \langle x,z \right \rangle\in \left \{ 0, \right1 \}^{m(n)}\times \left \{ 0, \right1 \}^{l(n)}$</tex-math> be a possible output of <tex-math>$\mathcal{D}_{n}$</tex-math>. We call <italic>x</italic> the <italic>trapdoor key</italic> and <italic>z</italic> the <italic>public key</italic>. Let <tex-math>$f:\left \{ 0, \right1 \}^{l(n)}\times \left \{ 0, \right1 \}^{n}\rightarrow \left \{ 0, \right1 \}^{k(n)}$</tex-math> be a P-time function ensemble, where the first input is the public key and the second input is private. For</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctvs32rpn.22</book-part-id>
                  <title-group>
                     <title>Lecture 16</title>
                  </title-group>
                  <fpage>154</fpage>
                  <abstract>
                     <p>We give the definition and a construction of a universal one-way hash function. One of the main technical tools we use to construct a secure digital signature scheme in the next lecture is a universal one-way hash function. A universal one-way hash function is also interesting in its own right.</p>
                     <p>Intuitively, a universal one-way hash function is like a universal hash function (page 84) with security properties. As described in the next lecture, a universal one-way hash function is a useful tool in the construction of secure digital signature schemes.</p>
                     <p>Definition (universal one-way hash function): Let <tex-math>$g:\left \{ 0, \right1 \}^{n}\times \left \{ 0, \right1 \}^{d(n)}\rightarrow \left \{ 0, \right1 \}^{r(n)}$</tex-math> be a P-time</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctvs32rpn.23</book-part-id>
                  <title-group>
                     <title>Lecture 17</title>
                  </title-group>
                  <fpage>162</fpage>
                  <abstract>
                     <p>We give the definition and the construction of a signature scheme based on a universal one-way hash function.</p>
                     <p>A one message signature scheme is a way for a party <italic>S</italic> (called the signer) to create a signature <italic>σ</italic> of a message <italic>m</italic>, and send the pair <tex-math>$\left \langle m, \right\sigma \rangle$</tex-math> to another party <italic>V</italic> (called the verifier). Intuitively, the scheme is secure if <italic>S</italic> is the only party that can convince <italic>V</italic> that <italic>S</italic> signed <italic>m</italic>, even in the case when <italic>V</italic> cannot be sure whether it is an adversary or <italic>S</italic> that sends <tex-math>$\left \langle m, \right\sigma \rangle$</tex-math>.</p>
                     <p>There are three phases to the scheme,</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctvs32rpn.24</book-part-id>
                  <title-group>
                     <title>Lecture 18</title>
                  </title-group>
                  <fpage>174</fpage>
                  <abstract>
                     <p>We define interactive proof systems. We give examples of languages which have IP proofs but which are not known to be in NP. We define and give a construction for a hidden bit commitment scheme. We define zero knowledge interactive proofs and describe a computational secure zero knowledge interactive proof for all languages in NP based on a hidden bit commitment scheme.</p>
                     <p>IP, which stands for interactive proof, is a complexity class that is a generalization of NP. To compare the two complexity classes, we first briefly review some properties of NP. If a language <italic>L</italic> ϵ NP then there</p>
                  </abstract>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctvs32rpn.25</book-part-id>
                  <title-group>
                     <title>List of Exercises and Research Problems</title>
                  </title-group>
                  <fpage>185</fpage>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctvs32rpn.26</book-part-id>
                  <title-group>
                     <title>List of Primary Results</title>
                  </title-group>
                  <fpage>195</fpage>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctvs32rpn.27</book-part-id>
                  <title-group>
                     <title>Credits and History</title>
                  </title-group>
                  <fpage>199</fpage>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctvs32rpn.28</book-part-id>
                  <title-group>
                     <title>References</title>
                  </title-group>
                  <fpage>211</fpage>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctvs32rpn.29</book-part-id>
                  <title-group>
                     <title>Notation</title>
                  </title-group>
                  <fpage>221</fpage>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctvs32rpn.30</book-part-id>
                  <title-group>
                     <title>Index</title>
                  </title-group>
                  <fpage>225</fpage>
               </book-part-meta>
            </book-part>
            <book-part>
               <book-part-meta>
                  <book-part-id book-part-id-type="jstor">j.ctvs32rpn.31</book-part-id>
                  <title-group>
                     <title>Back Matter</title>
                  </title-group>
                  <fpage>238</fpage>
               </book-part-meta>
            </book-part>
         </body>
      </book-part>
   </body>
</book>
